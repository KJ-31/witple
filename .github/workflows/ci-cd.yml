name: CI/CD Pipeline - Full Stack

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION: ap-northeast-2
  ECR_REPOSITORY_BACKEND: witple-backend
  ECR_REPOSITORY_FRONTEND: witple-frontend
  EKS_CLUSTER_NAME: witple-cluster
  EKS_NAMESPACE: witple

permissions:
  id-token: write   # OIDC 토큰 생성 권한
  contents: read    # 코드 읽기 권한

jobs:
  # 백엔드 테스트
  test-backend:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: test_db
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
    
    - name: Install Dependencies
      run: |
        cd backend
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run Tests
      env:
        DATABASE_URL: postgresql://test_user:test_password@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379
        SECRET_KEY: test-secret-key
      run: |
        cd backend
        echo "Running backend tests..."
        pytest

  # 프론트엔드 테스트
  test-frontend:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
    
    - name: Cache npm dependencies
      uses: actions/cache@v3
      with:
        path: ~/.npm
        key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}
    
    - name: Install Dependencies
      run: |
        cd frontend
        npm ci
    
    - name: Run Tests
      run: |
        cd frontend
        npm run lint
        # npm run test (테스트 파일 추가 시)

  # 백엔드 빌드 및 푸시
  build-backend:
    needs: test-backend
    if: ${{ github.ref == 'refs/heads/main' }}
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    # AWS 자격 증명 구성 (OIDC 방식)
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-actions-role
        aws-region: ${{ env.AWS_REGION }}
        role-session-name: github-actions-backend-${{ github.run_id }}
        role-duration-seconds: 3600
    
    # ECR 로그인
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
    
    # 백엔드 빌드 및 푸시
    - name: Build and push Backend image
      run: |
        cd backend
        docker build -t witple-backend .
        docker tag witple-backend:latest ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY_BACKEND }}:latest
        docker tag witple-backend:latest ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY_BACKEND }}:${{ github.sha }}
        docker push ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY_BACKEND }}:latest
        docker push ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY_BACKEND }}:${{ github.sha }}

  # 프론트엔드 빌드 및 푸시
  build-frontend:
    needs: test-frontend
    if: ${{ github.ref == 'refs/heads/main' }}
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    # AWS 자격 증명 구성 (OIDC 방식)
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-actions-role
        aws-region: ${{ env.AWS_REGION }}
        role-session-name: github-actions-frontend-${{ github.run_id }}
        role-duration-seconds: 3600
    
    # ECR 로그인
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
    
    # 프론트엔드 빌드 및 푸시
    - name: Build and push Frontend image
      run: |
        cd frontend
        docker build -t witple-frontend .
        docker tag witple-frontend:latest ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY_FRONTEND }}:latest
        docker tag witple-frontend:latest ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY_FRONTEND }}:${{ github.sha }}
        docker push ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY_FRONTEND }}:latest
        docker push ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY_FRONTEND }}:${{ github.sha }}

  # 통합 배포
  deploy:
    needs: [build-backend, build-frontend]
    if: ${{ github.ref == 'refs/heads/main' && always() && !cancelled() && !failure() }}
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    # AWS 자격 증명 구성 (OIDC 방식)
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-actions-role
        aws-region: ${{ env.AWS_REGION }}
        role-session-name: github-actions-deploy-${{ github.run_id }}
        role-duration-seconds: 3600
    
    # ECR 로그인
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
    
    # EKS 설정 및 Access Entries 적용
    - name: Configure EKS access
      run: |
        aws eks update-kubeconfig --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }}
        aws sts get-caller-identity
        
        # Check if EKS cluster is accessible via AWS CLI
        echo "Checking EKS cluster accessibility..."
        if aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }} > /dev/null 2>&1; then
          echo "EKS cluster is accessible via AWS CLI"
        else
          echo "Cannot access EKS cluster via AWS CLI"
          exit 1
        fi
        
        # Get current AWS identity
        CURRENT_ARN=$(aws sts get-caller-identity --query 'Arn' --output text)
        echo "Current AWS identity: $CURRENT_ARN"
        
        # Create EKS Access Entry for GitHub Actions role (if not exists)
        echo "Creating EKS Access Entry for GitHub Actions role..."
        aws eks create-access-entry \
          --cluster-name ${{ env.EKS_CLUSTER_NAME }} \
          --region ${{ env.AWS_REGION }} \
          --principal-arn "arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-actions-role" \
          --type STANDARD || {
          echo "Access entry creation failed or already exists"
        }
        
        # Associate access policy to the access entry
        echo "Associating cluster admin policy to access entry..."
        aws eks associate-access-policy \
          --cluster-name ${{ env.EKS_CLUSTER_NAME }} \
          --region ${{ env.AWS_REGION }} \
          --principal-arn "arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-actions-role" \
          --policy-arn arn:aws:eks::aws:cluster-access-policy/AmazonEKSClusterAdminPolicy \
          --access-scope type=cluster || {
          echo "Policy association failed or already exists"
        }
        
        # Configure kubectl authentication with AWS CLI
        echo "Configuring kubectl authentication..."
        aws eks get-token --cluster-name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }}
        
        # Test kubectl access
        echo "Testing kubectl access..."
        kubectl get nodes
    
    # AWS Load Balancer Controller ServiceAccount 생성
    - name: Create AWS Load Balancer Controller ServiceAccount
      run: |
        cat > aws-load-balancer-controller-sa.yaml << EOF
        apiVersion: v1
        kind: ServiceAccount
        metadata:
          name: aws-load-balancer-controller
          namespace: kube-system
          annotations:
            eks.amazonaws.com/role-arn: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/aws-load-balancer-controller
        EOF
        kubectl apply -f aws-load-balancer-controller-sa.yaml --validate=false
    
    # Helm 설치
    - name: Install Helm
      run: |
        curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
        helm version
    
    # AWS Load Balancer Controller 설치
    - name: Install AWS Load Balancer Controller
      run: |
        # Helm을 사용하여 AWS Load Balancer Controller 설치
        helm repo add eks https://aws.github.io/eks-charts
        helm repo update
        
        # VPC ID 가져오기
        VPC_ID=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --query 'cluster.resourcesVpcConfig.vpcId' --output text)
        echo "VPC ID: $VPC_ID"
        
        # AWS Load Balancer Controller 설치 (기존 설치가 있다면 업그레이드)
        helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
          -n kube-system \
          --set clusterName=${{ env.EKS_CLUSTER_NAME }} \
          --set serviceAccount.create=false \
          --set serviceAccount.name=aws-load-balancer-controller \
          --set region=${{ env.AWS_REGION }} \
          --set vpcId=$VPC_ID \
          --wait --timeout=300s || echo "ALB Controller might already be installed"
        
        # Controller가 준비될 때까지 대기
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=aws-load-balancer-controller -n kube-system --timeout=300s || echo "ALB Controller pods might already be ready"
    
    # 환경 변수 설정
    - name: Set environment variables
      run: |
        echo "ECR_REGISTRY=${{ steps.login-ecr.outputs.registry }}" >> $GITHUB_ENV
        echo "ECR_REPOSITORY_BACKEND=${{ env.ECR_REPOSITORY_BACKEND }}" >> $GITHUB_ENV
        echo "ECR_REPOSITORY_FRONTEND=${{ env.ECR_REPOSITORY_FRONTEND }}" >> $GITHUB_ENV
        echo "SECRET_KEY=${{ secrets.SECRET_KEY }}" >> $GITHUB_ENV
        
        # DOMAIN_NAME 처리 (비어있으면 ALB DNS만 사용)
        DOMAIN_NAME="${{ secrets.DOMAIN_NAME }}"
        if [ -z "$DOMAIN_NAME" ] || [ "$DOMAIN_NAME" = "" ]; then
          echo "DOMAIN_NAME is empty, will use ALB DNS only"
          echo "USE_DOMAIN=false" >> $GITHUB_ENV
          echo "DOMAIN_NAME=" >> $GITHUB_ENV
        else
          echo "DOMAIN_NAME=$DOMAIN_NAME" >> $GITHUB_ENV
          echo "USE_DOMAIN=true" >> $GITHUB_ENV
        fi
        
        # VPC 정보 가져오기 (Ingress용)
        VPC_ID=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --query 'cluster.resourcesVpcConfig.vpcId' --output text)
        PUBLIC_SUBNET_IDS=$(aws ec2 describe-subnets --filters "Name=tag:Name,Values=*public*" "Name=vpc-id,Values=$VPC_ID" --query 'Subnets[*].SubnetId' --output text | tr '\t' ',')
        ALB_SECURITY_GROUP_ID=$(aws ec2 describe-security-groups --filters "Name=group-name,Values=*alb*" "Name=vpc-id,Values=$VPC_ID" --query 'SecurityGroups[0].GroupId' --output text)
        
        echo "VPC_ID=$VPC_ID" >> $GITHUB_ENV
        echo "PUBLIC_SUBNET_IDS=$PUBLIC_SUBNET_IDS" >> $GITHUB_ENV
        echo "ALB_SECURITY_GROUP_ID=$ALB_SECURITY_GROUP_ID" >> $GITHUB_ENV
        
        # ACM 인증서 ARN 설정 (HTTPS용)
        echo "CERTIFICATE_ARN=${{ secrets.CERTIFICATE_ARN }}" >> $GITHUB_ENV
    
    # 네임스페이스 생성 및 데이터베이스 시크릿 생성
    - name: Create namespace and database secret
      run: |
        echo "Creating namespace..."
        kubectl apply -f k8s/namespace.yaml
        
        echo "Creating database secret..."
        
        # kubectl을 사용하여 직접 시크릿 생성 (기존 시크릿이 있으면 삭제 후 재생성)
        kubectl delete secret db-secret -n ${{ env.EKS_NAMESPACE }} --ignore-not-found=true
        kubectl delete secret app-secret -n ${{ env.EKS_NAMESPACE }} --ignore-not-found=true
        
        kubectl create secret generic db-secret \
          --namespace=${{ env.EKS_NAMESPACE }} \
          --from-literal=DATABASE_URL="${{ secrets.DATABASE_URL }}" \
          --from-literal=REDIS_URL="${{ secrets.REDIS_URL }}"
        
        kubectl create secret generic app-secret \
          --namespace=${{ env.EKS_NAMESPACE }} \
          --from-literal=SECRET_KEY="${{ secrets.SECRET_KEY }}"
        
        echo "Secrets created successfully"
        
        # ECR Pull Secret 생성 (이미지 Pull을 위해)
        echo "Creating ECR pull secret..."
        kubectl delete secret regcred -n ${{ env.EKS_NAMESPACE }} --ignore-not-found=true
        
        kubectl create secret docker-registry regcred \
          --namespace=${{ env.EKS_NAMESPACE }} \
          --docker-server=${{ steps.login-ecr.outputs.registry }} \
          --docker-username=AWS \
          --docker-password=$(aws ecr get-login-password --region ${{ env.AWS_REGION }})
        
        echo "ECR pull secret created successfully"
    
    # Kubernetes 매니페스트 적용
    - name: Deploy to EKS
      run: |
        # 환경 변수 치환
        envsubst < k8s/configmap.yaml > k8s/configmap-generated.yaml
        
        # 공통 리소스 배포
        echo "Applying shared resources..."
        kubectl apply -f k8s/namespace.yaml
        kubectl apply -f k8s/configmap-generated.yaml
        kubectl apply -f k8s/hpa.yaml
        
        # ServiceAccount 배포
        echo "Applying ServiceAccount..."
        kubectl apply -f k8s/backend/serviceaccount.yaml
        
        # Ingress 생성 (도메인 사용 여부에 따라 다르게 처리)
        echo "=== Ingress Generation ==="
        echo "USE_DOMAIN: $USE_DOMAIN"
        echo "DOMAIN_NAME: $DOMAIN_NAME"
        
        if [ "$USE_DOMAIN" = "true" ]; then
          echo "Creating Ingress with domain: $DOMAIN_NAME"
          envsubst < k8s/ingress.yaml > k8s/ingress-generated.yaml
        else
          echo "Creating Ingress without domain (ALB DNS only)"
          cat > k8s/ingress-generated.yaml << 'EOF'
        apiVersion: networking.k8s.io/v1
        kind: Ingress
        metadata:
          name: witple-ingress
          namespace: witple
          annotations:
            kubernetes.io/ingress.class: "alb"
            alb.ingress.kubernetes.io/scheme: "internet-facing"
            alb.ingress.kubernetes.io/target-type: "ip"
            alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}]'
        EOF
          # 환경 변수 치환으로 서브넷과 보안 그룹 추가
          cat >> k8s/ingress-generated.yaml << EOF
            alb.ingress.kubernetes.io/subnets: "${PUBLIC_SUBNET_IDS}"
            alb.ingress.kubernetes.io/security-groups: "${ALB_SECURITY_GROUP_ID}"
        spec:
          ingressClassName: alb
          rules:
          - http:
              paths:
              - path: /api
                pathType: Prefix
                backend:
                  service:
                    name: witple-backend-service
                    port:
                      number: 80
              - path: /
                pathType: Prefix
                backend:
                  service:
                    name: witple-frontend-service
                    port:
                      number: 80
        EOF
        fi
        
        # 배포 (각 단계별로 확인)
        echo "Applying ConfigMap..."
        kubectl apply -f k8s/configmap-generated.yaml
        
        # IMAGE_TAG 설정 (커밋 SHA 태그)
        export IMAGE_TAG=${GITHUB_SHA}

        # 백엔드 배포 (Rolling Update 사용)
        echo "Deploying backend (rolling update)..."
        
        # 백엔드 매니페스트 환경 변수 치환
        envsubst < k8s/backend/deployment.yaml > k8s/backend/deployment-generated.yaml
        envsubst < k8s/backend/service.yaml > k8s/backend/service-generated.yaml
        
        # 백엔드 배포 (Rolling Update)
        kubectl apply -f k8s/backend/deployment-generated.yaml
        kubectl apply -f k8s/backend/service-generated.yaml
        
        # 프론트엔드 배포
        echo "Deploying frontend..."
        
        # 프론트엔드 매니페스트 환경 변수 치환
        envsubst < k8s/frontend/deployment.yaml > k8s/frontend/deployment-generated.yaml
        envsubst < k8s/frontend/service.yaml > k8s/frontend/service-generated.yaml
        if [ "$USE_DOMAIN" = "true" ]; then
          echo "Creating frontend Ingress with HTTPS (domain mode)"
          envsubst < k8s/frontend/ingress.yaml > k8s/frontend/ingress-generated.yaml
        else
          echo "Creating frontend Ingress with HTTP only (no domain mode)"
          # HTTP 전용 Ingress 생성 (도메인 없음)
          {
            echo "apiVersion: networking.k8s.io/v1"
            echo "kind: Ingress"
            echo "metadata:"
            echo "  name: witple-frontend-ingress"
            echo "  namespace: witple"
            echo "  annotations:"
            echo "    kubernetes.io/ingress.class: \"alb\""
            echo "    alb.ingress.kubernetes.io/scheme: \"internet-facing\""
            echo "    alb.ingress.kubernetes.io/target-type: \"ip\""
            echo "    alb.ingress.kubernetes.io/listen-ports: '[{\"HTTP\": 80}]'"
            echo "    alb.ingress.kubernetes.io/subnets: \"${PUBLIC_SUBNET_IDS}\""
            echo "    alb.ingress.kubernetes.io/security-groups: \"${ALB_SECURITY_GROUP_ID}\""
            echo "    alb.ingress.kubernetes.io/healthcheck-path: \"/\""
            echo "    alb.ingress.kubernetes.io/healthcheck-port: \"3000\""
            echo "    alb.ingress.kubernetes.io/healthcheck-protocol: \"HTTP\""
            echo "    alb.ingress.kubernetes.io/healthcheck-timeout-seconds: \"10\""
            echo "    alb.ingress.kubernetes.io/healthcheck-interval-seconds: \"15\""
            echo "    alb.ingress.kubernetes.io/healthy-threshold-count: \"2\""
            echo "    alb.ingress.kubernetes.io/unhealthy-threshold-count: \"5\""
            echo "    alb.ingress.kubernetes.io/success-codes: \"200\""
            echo "spec:"
            echo "  ingressClassName: alb"
            echo "  rules:"
            echo "  - http:"
            echo "      paths:"
            echo "      - path: /"
            echo "        pathType: Prefix"
            echo "        backend:"
            echo "          service:"
            echo "            name: witple-frontend-service"
            echo "            port:"
            echo "              number: 80"
          } > k8s/frontend/ingress-generated.yaml
        fi
        
        # 프론트엔드 배포
        kubectl apply -f k8s/frontend/deployment-generated.yaml
        kubectl apply -f k8s/frontend/service-generated.yaml
        kubectl apply -f k8s/frontend/ingress-generated.yaml
        
        # Ingress 상태 확인
        echo "Checking frontend Ingress status..."
        kubectl get ingress witple-frontend-ingress -n ${{ env.EKS_NAMESPACE }} || echo "Frontend Ingress not found"
        
        # 배포 상태 확인 (병렬로 체크)
        echo "Waiting for deployments to be ready..."
        
        # 백엔드 배포 상태 확인
        echo "Checking backend deployment..."
        if ! kubectl rollout status deployment/witple-backend -n ${{ env.EKS_NAMESPACE }} --timeout=300s; then
          echo "Backend deployment failed! Debugging..."
          kubectl describe deployment witple-backend -n ${{ env.EKS_NAMESPACE }}
          kubectl get pods -n ${{ env.EKS_NAMESPACE }} -l app=witple-backend
          for pod in $(kubectl get pods -n ${{ env.EKS_NAMESPACE }} -l app=witple-backend -o jsonpath='{.items[*].metadata.name}'); do
            echo "--- Pod: $pod ---"
            kubectl logs $pod -n ${{ env.EKS_NAMESPACE }} --tail=100 || echo "No logs available for $pod"
            kubectl describe pod $pod -n ${{ env.EKS_NAMESPACE }}
          done
          exit 1
        fi
        echo "✅ Backend deployment successful"
        
        # 프론트엔드 배포 상태 확인
        echo "Checking frontend deployment..."
        if ! kubectl rollout status deployment/witple-frontend -n ${{ env.EKS_NAMESPACE }} --timeout=300s; then
          echo "Frontend deployment failed! Debugging..."
          kubectl describe deployment witple-frontend -n ${{ env.EKS_NAMESPACE }}
          kubectl get pods -n ${{ env.EKS_NAMESPACE }} -l app=witple-frontend
          for pod in $(kubectl get pods -n ${{ env.EKS_NAMESPACE }} -l app=witple-frontend -o jsonpath='{.items[*].metadata.name}'); do
            echo "--- Pod: $pod ---"
            kubectl logs $pod -n ${{ env.EKS_NAMESPACE }} --tail=100 || echo "No logs available for $pod"
            kubectl describe pod $pod -n ${{ env.EKS_NAMESPACE }}
          done
          exit 1
        fi
        echo "✅ Frontend deployment successful"
        
        echo "Checking pods status..."
        kubectl get pods -n ${{ env.EKS_NAMESPACE }}
        
        # 프론트엔드 ALB DNS 확인
        echo "Waiting for frontend Ingress to be ready..."
        FRONTEND_ALB_DNS=""
        for i in {1..60}; do
          echo "Attempt $i/60: Checking frontend Ingress status..."
          FRONTEND_ALB_DNS=$(kubectl get ingress witple-frontend-ingress -n ${{ env.EKS_NAMESPACE }} -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "")
          if [ -n "$FRONTEND_ALB_DNS" ]; then
            echo "✅ Frontend Ingress is ready! ALB DNS: $FRONTEND_ALB_DNS"
            break
          fi
          if [ $i -eq 60 ]; then
            echo "❌ Frontend Ingress failed to become ready after 10 minutes"
            kubectl describe ingress witple-frontend-ingress -n ${{ env.EKS_NAMESPACE }}
            exit 1
          fi
          echo "⏳ Frontend Ingress not ready yet, waiting 10 seconds..."
          sleep 10
        done
        
        # 도메인 설정에 따른 URL 출력
        echo "=== Deployment URLs ==="
        
        if [ "$USE_DOMAIN" = "true" ]; then
          echo "🌐 Application URL: https://$DOMAIN_NAME"
          echo "🔗 Backend API URL: https://$DOMAIN_NAME/api (proxied through frontend)"
        else
          echo "🌐 Application URL: http://$FRONTEND_ALB_DNS"
          echo "🔗 Backend API URL: http://$FRONTEND_ALB_DNS/api (proxied through frontend)"
          echo "📝 Note: All traffic goes through frontend. Frontend proxies /api to backend internally."
        fi
        
        # 내부 서비스 정보
        echo ""
        echo "🏗️ Internal Services:"
        echo "🔧 Frontend Service: witple-frontend-service:80 (exposed via ALB)"
        echo "🔧 Backend Service: witple-backend-service:80 (ClusterIP only)"
        echo ""
        echo "📊 Load Balancer:"
        echo "⚡ Frontend ALB: $FRONTEND_ALB_DNS (handles all traffic)"
        
        echo ""
        echo "🎉 Deployment completed successfully!"
        echo "📊 Summary:"
        echo "- Backend: Deployed"
        echo "- Frontend: Deployed"
        echo "- K8s: Updated"
