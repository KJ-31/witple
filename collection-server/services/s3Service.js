const AWS = require('aws-sdk');
const { v4: uuidv4 } = require('uuid');
const zlib = require('zlib');
const { promisify } = require('util');

const gzip = promisify(zlib.gzip);

class S3Service {
  constructor() {
    // AWS S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
    this.s3 = new AWS.S3({
      region: process.env.AWS_REGION || 'ap-northeast-2',
      apiVersion: '2006-03-01',
      maxRetries: 3,
      retryDelayOptions: {
        customBackoff: function(retryCount) {
          return Math.pow(2, retryCount) * 100; // ì§€ìˆ˜ ë°±ì˜¤í”„
        }
      }
    });
    
    this.bucket = process.env.S3_EVENTS_BUCKET || 'user-actions-data';
    
    // S3 ì—°ê²° í…ŒìŠ¤íŠ¸
    this.testConnection();
  }

  async testConnection() {
    try {
      await this.s3.headBucket({ Bucket: this.bucket }).promise();
      console.log(`âœ… S3 connection successful: ${this.bucket}`);
    } catch (error) {
      console.error(`âŒ S3 connection failed: ${error.message}`);
      console.error('Please check AWS credentials and bucket name');
    }
  }

  /**
   * ì•¡ì…˜ ë°°ì¹˜ë¥¼ S3ì— ì—…ë¡œë“œ
   * @param {Array} actions - ì—…ë¡œë“œí•  ì•¡ì…˜ ë°°ì—´
   * @param {Object} options - ì—…ë¡œë“œ ì˜µì…˜
   * @returns {Promise<Object>} ì—…ë¡œë“œ ê²°ê³¼
   */
  async uploadBatch(actions, options = {}) {
    if (!actions || actions.length === 0) {
      return { success: false, message: 'No actions to upload' };
    }

    const timestamp = new Date();
    const batchId = uuidv4();
    
    try {
      // S3 í‚¤ ìƒì„± (íŒŒí‹°ì…˜ êµ¬ì¡°)
      const s3Key = this.generateS3Key(timestamp, actions.length, batchId);
      
      // ì—…ë¡œë“œí•  ë°ì´í„° êµ¬ì„±
      const batchData = {
        batch_id: batchId,
        timestamp: timestamp.toISOString(),
        count: actions.length,
        server_info: {
          hostname: require('os').hostname(),
          version: require('../package.json').version,
          node_version: process.version
        },
        actions: actions.map(action => ({
          ...action,
          batch_id: batchId,
          processed_at: timestamp.toISOString()
        }))
      };

      // JSON ì§ë ¬í™”
      const jsonData = JSON.stringify(batchData, null, 0);
      
      // GZIP ì••ì¶• (ì„ íƒì‚¬í•­ - ìš©ëŸ‰ ì ˆì•½)
      let bodyData = jsonData;
      let contentEncoding = undefined;
      
      if (options.compress !== false) {
        try {
          bodyData = await gzip(jsonData);
          contentEncoding = 'gzip';
        } catch (compressionError) {
          console.warn('Compression failed, uploading uncompressed:', compressionError.message);
        }
      }

      // S3 ì—…ë¡œë“œ íŒŒë¼ë¯¸í„°
      const uploadParams = {
        Bucket: this.bucket,
        Key: s3Key,
        Body: bodyData,
        ContentType: 'application/json',
        Metadata: {
          'batch-id': batchId,
          'action-count': actions.length.toString(),
          'upload-timestamp': timestamp.toISOString(),
          'server-version': require('../package.json').version
        }
      };

      if (contentEncoding) {
        uploadParams.ContentEncoding = contentEncoding;
      }

      // S3 ì—…ë¡œë“œ ì‹¤í–‰
      const uploadResult = await this.s3.upload(uploadParams).promise();
      
      console.log(`ğŸ“¦ S3 Upload successful: ${actions.length} actions -> ${s3Key}`);
      
      return {
        success: true,
        batch_id: batchId,
        s3_key: s3Key,
        s3_location: uploadResult.Location,
        action_count: actions.length,
        compressed: !!contentEncoding,
        upload_time: new Date() - timestamp
      };

    } catch (error) {
      console.error('âŒ S3 Upload failed:', error);
      
      // ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
      if (error.code === 'NoSuchBucket') {
        throw new Error(`S3 bucket not found: ${this.bucket}`);
      } else if (error.code === 'AccessDenied') {
        throw new Error('S3 access denied. Please check AWS credentials and permissions');
      } else if (error.code === 'NetworkingError') {
        throw new Error('S3 network error. Please check internet connection');
      }
      
      throw error;
    }
  }

  /**
   * S3 í‚¤ ìƒì„± (íŒŒí‹°ì…˜ êµ¬ì¡°)
   * @param {Date} timestamp - íƒ€ì„ìŠ¤íƒ¬í”„
   * @param {number} count - ì•¡ì…˜ ê°œìˆ˜
   * @param {string} batchId - ë°°ì¹˜ ID
   * @returns {string} S3 í‚¤
   */
  generateS3Key(timestamp, count, batchId) {
    const year = timestamp.getFullYear();
    const month = String(timestamp.getMonth() + 1).padStart(2, '0');
    const day = String(timestamp.getDate()).padStart(2, '0');
    const hour = String(timestamp.getHours()).padStart(2, '0');
    const minute = String(timestamp.getMinutes()).padStart(2, '0');
    
    // íŒŒí‹°ì…˜ êµ¬ì¡°: user-actions/year=2025/month=01/day=15/hour=14/
    const partitionPath = `user-actions/year=${year}/month=${month}/day=${day}/hour=${hour}`;
    
    // íŒŒì¼ëª…: batch-{timestamp}-{count}-{batchId}.json
    const fileName = `batch-${timestamp.getTime()}-${count}-${batchId.slice(0, 8)}.json`;
    
    return `${partitionPath}/${fileName}`;
  }

  /**
   * í…ŒìŠ¤íŠ¸ìš© ë‹¨ì¼ ì•¡ì…˜ ì—…ë¡œë“œ
   * @param {Object} action - ë‹¨ì¼ ì•¡ì…˜
   * @returns {Promise<Object>} ì—…ë¡œë“œ ê²°ê³¼
   */
  async uploadSingle(action) {
    return await this.uploadBatch([action], { compress: false });
  }

  /**
   * S3 ë²„í‚·ì˜ íŒŒì¼ ëª©ë¡ ì¡°íšŒ (ë””ë²„ê¹…ìš©)
   * @param {string} prefix - ê²€ìƒ‰í•  ì ‘ë‘ì‚¬
   * @param {number} maxKeys - ìµœëŒ€ ê²°ê³¼ ìˆ˜
   * @returns {Promise<Array>} íŒŒì¼ ëª©ë¡
   */
  async listFiles(prefix = 'user-actions/', maxKeys = 10) {
    try {
      const params = {
        Bucket: this.bucket,
        Prefix: prefix,
        MaxKeys: maxKeys
      };
      
      const result = await this.s3.listObjectsV2(params).promise();
      
      return result.Contents.map(obj => ({
        key: obj.Key,
        size: obj.Size,
        lastModified: obj.LastModified
      }));
      
    } catch (error) {
      console.error('S3 list files failed:', error);
      throw error;
    }
  }

  /**
   * íŠ¹ì • S3 ê°ì²´ ì‚­ì œ (í…ŒìŠ¤íŠ¸ìš©)
   * @param {string} key - ì‚­ì œí•  S3 í‚¤
   * @returns {Promise<Object>} ì‚­ì œ ê²°ê³¼
   */
  async deleteObject(key) {
    try {
      const params = {
        Bucket: this.bucket,
        Key: key
      };
      
      await this.s3.deleteObject(params).promise();
      console.log(`ğŸ—‘ï¸  S3 object deleted: ${key}`);
      
      return { success: true, deleted_key: key };
      
    } catch (error) {
      console.error(`âŒ S3 delete failed for ${key}:`, error);
      throw error;
    }
  }

  /**
   * S3 ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
   * @returns {Promise<Object>} ìƒíƒœ ì •ë³´
   */
  async getStatus() {
    try {
      // ë²„í‚· í—¤ë“œ ìš”ì²­ìœ¼ë¡œ ì—°ê²° ìƒíƒœ í™•ì¸
      await this.s3.headBucket({ Bucket: this.bucket }).promise();
      
      // ìµœê·¼ ì—…ë¡œë“œëœ íŒŒì¼ í™•ì¸
      const recentFiles = await this.listFiles('user-actions/', 1);
      
      return {
        connected: true,
        bucket: this.bucket,
        region: this.s3.config.region,
        recent_files: recentFiles.length,
        last_upload: recentFiles[0]?.lastModified || null
      };
      
    } catch (error) {
      return {
        connected: false,
        bucket: this.bucket,
        region: this.s3.config.region,
        error: error.message
      };
    }
  }
}

module.exports = { S3Service };