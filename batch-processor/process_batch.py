#!/usr/bin/env python3
"""
AWS Batch Î©îÏù∏ Ï≤òÎ¶¨ Ïä§ÌÅ¨Î¶ΩÌä∏
S3ÏóêÏÑú ÏÇ¨Ïö©Ïûê ÌñâÎèô Îç∞Ïù¥ÌÑ∞Î•º ÏùΩÏñ¥ÏÑú BERT Î≤°ÌÑ∞Î°ú Î≥ÄÌôòÌïòÍ≥† PostgreSQLÏóê Ï†ÄÏû•
"""
import os
import sys
import json
import logging
import traceback
from datetime import datetime
from typing import List, Dict, Any, Optional
import gzip

import boto3
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
import requests

# Î°úÍπÖ ÏÑ§Ï†ï
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('/tmp/batch_processing.log')
    ]
)
logger = logging.getLogger(__name__)

# ÌôòÍ≤Ω Î≥ÄÏàò ÏÑ§Ï†ï
AWS_REGION = os.getenv('AWS_REGION', 'ap-northeast-2')
S3_BUCKET = os.getenv('S3_BUCKET', 'user-actions-data')
S3_PREFIX = os.getenv('S3_PREFIX', 'user-actions/')
DATABASE_URL = os.getenv('DATABASE_URL')
WEBHOOK_URL = os.getenv('WEBHOOK_URL')  # Main EC2 webhook URL
BATCH_ID = os.getenv('BATCH_ID', f'batch_{int(datetime.now().timestamp())}')
JOB_NAME = os.getenv('AWS_BATCH_JOB_NAME', 'witple-vectorization-job')
JOB_ID = os.getenv('AWS_BATCH_JOB_ID', 'unknown')

# BERT Î™®Îç∏ ÏÑ§Ï†ï
BERT_MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'
VECTOR_DIMENSION = 384

class BatchProcessor:
    def __init__(self):
        logger.info("üöÄ Initializing Batch Processor")
        
        # AWS ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî
        self.s3_client = boto3.client('s3', region_name=AWS_REGION)
        
        # BERT Î™®Îç∏ Î°úÎìú (Ïª®ÌÖåÏù¥ÎÑà ÏãúÏûë Ïãú Îã§Ïö¥Î°úÎìúÎê®)
        logger.info(f"üì• Loading BERT model: {BERT_MODEL_NAME}")
        self.bert_model = SentenceTransformer(BERT_MODEL_NAME)
        logger.info("‚úÖ BERT model loaded successfully")
        
        # Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞
        if DATABASE_URL:
            self.engine = create_engine(DATABASE_URL)
            self.SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)
            logger.info("‚úÖ Database connection established")
        else:
            logger.warning("‚ö†Ô∏è DATABASE_URL not provided, database operations will be skipped")
            self.engine = None
            self.SessionLocal = None
        
        # ÌÜµÍ≥Ñ Ï†ïÎ≥¥ Ï¥àÍ∏∞Ìôî
        self.stats = {
            'processed_files': 0,
            'processed_actions': 0,
            'processed_users': 0,
            'processed_places': 0,
            'errors': 0,
            'start_time': datetime.now(),
            'end_time': None
        }
        
    def list_s3_files(self, max_files: int = 100) -> List[Dict[str, Any]]:
        """S3ÏóêÏÑú Ï≤òÎ¶¨Ìï† ÌååÏùº Î™©Î°ù Ï°∞Ìöå"""
        logger.info(f"üîç Searching for files in s3://{S3_BUCKET}/{S3_PREFIX}")
        
        files = []
        paginator = self.s3_client.get_paginator('list_objects_v2')
        
        try:
            for page in paginator.paginate(
                Bucket=S3_BUCKET,
                Prefix=S3_PREFIX,
                MaxKeys=1000
            ):
                if 'Contents' not in page:
                    continue
                    
                for obj in page['Contents']:
                    # .json ÌååÏùºÎßå Ï≤òÎ¶¨ (batch- Ï†ëÎëêÏÇ¨Í∞Ä ÏûàÎäî ÌååÏùºÎì§)
                    if obj['Key'].endswith('.json') and 'batch-' in obj['Key']:
                        files.append({
                            'key': obj['Key'],
                            'size': obj['Size'],
                            'last_modified': obj['LastModified']
                        })
                        
                        if len(files) >= max_files:
                            break
                            
                if len(files) >= max_files:
                    break
                    
        except Exception as e:
            logger.error(f"‚ùå Failed to list S3 files: {str(e)}")
            raise
            
        logger.info(f"üìã Found {len(files)} files to process")
        return sorted(files, key=lambda x: x['last_modified'])
    
    def download_and_parse_s3_file(self, s3_key: str) -> List[Dict[str, Any]]:
        """S3 ÌååÏùºÏùÑ Îã§Ïö¥Î°úÎìúÌïòÍ≥† ÌååÏã±"""
        logger.info(f"üì• Downloading {s3_key}")
        
        try:
            # S3 Í∞ùÏ≤¥ Îã§Ïö¥Î°úÎìú
            response = self.s3_client.get_object(Bucket=S3_BUCKET, Key=s3_key)
            content = response['Body'].read()
            
            # GZIP ÏïïÏ∂ï Ïó¨Î∂Ä ÌôïÏù∏
            if response.get('ContentEncoding') == 'gzip':
                content = gzip.decompress(content)
            
            # JSON ÌååÏã±
            data = json.loads(content.decode('utf-8'))
            
            # Î∞∞Ïπò Îç∞Ïù¥ÌÑ∞ Íµ¨Ï°∞ÏóêÏÑú actions Ï∂îÏ∂ú
            if 'actions' in data:
                actions = data['actions']
            else:
                # Îã®Ïùº Ïï°ÏÖò ÌååÏùºÏù∏ Í≤ΩÏö∞
                actions = [data] if isinstance(data, dict) else data
                
            logger.info(f"‚úÖ Parsed {len(actions)} actions from {s3_key}")
            return actions
            
        except Exception as e:
            logger.error(f"‚ùå Failed to download/parse {s3_key}: {str(e)}")
            self.stats['errors'] += 1
            return []
    
    def process_user_actions(self, actions: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
        """ÏÇ¨Ïö©ÏûêÎ≥Ñ ÌñâÎèô Îç∞Ïù¥ÌÑ∞Î•º Ï≤òÎ¶¨ÌïòÍ≥† Î≤°ÌÑ∞ ÏÉùÏÑ±"""
        logger.info(f"üß† Processing {len(actions)} actions for vectorization")
        
        user_data = {}
        place_data = {}
        
        # 1. ÏÇ¨Ïö©ÏûêÎ≥Ñ/Ïû•ÏÜåÎ≥Ñ ÌñâÎèô ÏßëÍ≥Ñ
        for action in actions:
            user_id = action.get('user_id')
            place_id = action.get('place_id')
            place_category = action.get('place_category')
            action_type = action.get('action_type')
            
            if not all([user_id, place_id, place_category, action_type]):
                continue
                
            # ÏÇ¨Ïö©Ïûê Îç∞Ïù¥ÌÑ∞ ÏßëÍ≥Ñ
            if user_id not in user_data:
                user_data[user_id] = {
                    'actions': [],
                    'total_likes': 0,
                    'total_bookmarks': 0,
                    'total_clicks': 0,
                    'places_visited': set(),
                    'categories_visited': set()
                }
            
            user_data[user_id]['actions'].append(action)
            user_data[user_id]['places_visited'].add(f"{place_category}:{place_id}")
            user_data[user_id]['categories_visited'].add(place_category)
            
            if action_type == 'like':
                user_data[user_id]['total_likes'] += 1
            elif action_type == 'bookmark':
                user_data[user_id]['total_bookmarks'] += 1
            elif action_type == 'click':
                user_data[user_id]['total_clicks'] += 1
            
            # Ïû•ÏÜå Îç∞Ïù¥ÌÑ∞ ÏßëÍ≥Ñ
            place_key = f"{place_category}:{place_id}"
            if place_key not in place_data:
                place_data[place_key] = {
                    'place_id': place_id,
                    'place_category': place_category,
                    'total_likes': 0,
                    'total_bookmarks': 0,
                    'total_clicks': 0,
                    'unique_users': set()
                }
            
            place_data[place_key]['unique_users'].add(user_id)
            
            if action_type == 'like':
                place_data[place_key]['total_likes'] += 1
            elif action_type == 'bookmark':
                place_data[place_key]['total_bookmarks'] += 1
            elif action_type == 'click':
                place_data[place_key]['total_clicks'] += 1
        
        # 2. ÏÇ¨Ïö©ÏûêÎ≥Ñ Î≤°ÌÑ∞ ÏÉùÏÑ±
        user_vectors = {}
        for user_id, data in user_data.items():
            try:
                # ÏÇ¨Ïö©Ïûê ÌñâÎèô Ìå®ÌÑ¥ÏùÑ ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò
                behavior_text = self.create_user_behavior_text(data)
                
                # BERT Î≤°ÌÑ∞ ÏÉùÏÑ±
                vector = self.bert_model.encode(behavior_text).tolist()
                
                # ÌñâÎèô Ï†êÏàò Í≥ÑÏÇ∞ (0-100 Ïä§ÏºÄÏùº)
                total_actions = len(data['actions'])
                like_score = min((data['total_likes'] / max(total_actions, 1)) * 100, 100)
                bookmark_score = min((data['total_bookmarks'] / max(total_actions, 1)) * 100, 100)
                click_score = min((data['total_clicks'] / max(total_actions, 1)) * 100, 100)
                
                # Îã§ÏñëÏÑ± Ï†êÏàò (Î∞©Î¨∏Ìïú Ïπ¥ÌÖåÍ≥†Î¶¨ Ïàò Í∏∞Î∞ò)
                diversity_score = min(len(data['categories_visited']) * 10, 100)
                
                user_vectors[user_id] = {
                    'user_id': user_id,
                    'behavior_vector': vector,
                    'like_score': round(like_score, 2),
                    'bookmark_score': round(bookmark_score, 2),
                    'click_score': round(click_score, 2),
                    'dwell_time_score': round(diversity_score, 2),  # Îã§ÏñëÏÑ±ÏùÑ Ï≤¥Î•òÏãúÍ∞Ñ Ï†êÏàòÎ°ú ÏÇ¨Ïö©
                    'total_actions': total_actions,
                    'total_likes': data['total_likes'],
                    'total_bookmarks': data['total_bookmarks'],
                    'total_clicks': data['total_clicks'],
                    'last_action_date': datetime.now()
                }
                
            except Exception as e:
                logger.error(f"‚ùå Failed to process user {user_id}: {str(e)}")
                self.stats['errors'] += 1
                continue
        
        # 3. Ïû•ÏÜåÎ≥Ñ Î≤°ÌÑ∞ ÏÉùÏÑ±
        place_vectors = {}
        for place_key, data in place_data.items():
            try:
                # Ïû•ÏÜå Ï†ïÎ≥¥Î•º ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò
                place_text = f"Place category: {data['place_category']} with {len(data['unique_users'])} visitors"
                
                # BERT Î≤°ÌÑ∞ ÏÉùÏÑ± (behavior_vectorÎ°ú ÏÇ¨Ïö©)
                vector = self.bert_model.encode(place_text).tolist()
                
                # Ïù∏Í∏∞ÎèÑ Ï†êÏàò Í≥ÑÏÇ∞
                total_interactions = data['total_likes'] + data['total_bookmarks'] + data['total_clicks']
                popularity_score = min(total_interactions * 2, 100)  # Í∞ÑÎã®Ìïú Ïù∏Í∏∞ÎèÑ Í≥µÏãù
                engagement_score = min((data['total_likes'] + data['total_bookmarks']) * 5, 100)
                
                # ============================================================================
                # üöÄ ENHANCED SCORING SYSTEM (ÌåÄ Í≤ÄÌÜ† ÌõÑ Ï†ÅÏö©)
                # ============================================================================
                """
                # Í∞úÏÑ†Îêú Í∞ÄÏ§ëÏπò Í∏∞Î∞ò Ï†êÏàò Í≥ÑÏÇ∞
                ACTION_WEIGHTS = {
                    'click': 1.0,      # Í∏∞Î≥∏ Í¥ÄÏã¨ÎèÑ
                    'like': 3.0,       # 3Î∞∞ Í∞ÄÏ§ëÏπò (Í∏çÏ†ïÏ†Å Î∞òÏùë)
                    'bookmark': 5.0    # 5Î∞∞ Í∞ÄÏ§ëÏπò (Í∞ïÌïú ÏÑ†Ìò∏)
                }
                
                # 1. Í∞ÄÏ§ëÏπò Í∏∞Î∞ò Ïù∏Í∏∞ÎèÑ Ï†êÏàò
                weighted_score = (
                    data['total_clicks'] * ACTION_WEIGHTS['click'] +
                    data['total_likes'] * ACTION_WEIGHTS['like'] + 
                    data['total_bookmarks'] * ACTION_WEIGHTS['bookmark']
                )
                
                # Ï†ïÍ∑úÌôî (0-100 Ïä§ÏºÄÏùº) - Í∏∞Ï§Ä: click 50Í∞ú + like 10Í∞ú + bookmark 5Í∞ú = 100Ï†ê
                max_reference_score = (50 * 1.0) + (10 * 3.0) + (5 * 5.0)  # = 105
                enhanced_popularity_score = min((weighted_score / max_reference_score) * 100, 100)
                
                # 2. Ï∞∏Ïó¨ÎèÑ Ï†êÏàò (Ïï°ÏÖòÏùò Ïßà Ï§ëÏã¨)
                if total_interactions > 0:
                    high_value_actions = data['total_likes'] + data['total_bookmarks'] 
                    engagement_ratio = high_value_actions / total_interactions
                    base_engagement = engagement_ratio * 100
                    # Ï†àÎåÄÍ∞í Î≥¥Ï†ï (ÏµúÏÜåÌïúÏùò like/bookmarkÏù¥ ÏûàÏñ¥Ïïº ÎÜíÏùÄ Ï†êÏàò)
                    min_threshold_bonus = min(high_value_actions * 5, 20)  # ÏµúÎåÄ 20Ï†ê Î≥¥ÎÑàÏä§
                    enhanced_engagement_score = min(base_engagement + min_threshold_bonus, 100)
                else:
                    enhanced_engagement_score = 0.0
                
                # Í∏∞Ï°¥ Ï†êÏàòÏôÄ Í∞úÏÑ†Îêú Ï†êÏàòÎ•º Î™®Îëê Ï†ÄÏû•ÌïòÏó¨ A/B ÌÖåÏä§Ìä∏ Í∞ÄÎä•
                # popularity_score = round(enhanced_popularity_score, 2)
                # engagement_score = round(enhanced_engagement_score, 2)
                """
                
                place_vectors[place_key] = {
                    'place_id': data['place_id'],
                    'place_category': data['place_category'],
                    'behavior_vector': vector,
                    'combined_vector': vector,  # ÎèôÏùºÌïú Î≤°ÌÑ∞ ÏÇ¨Ïö©
                    'total_likes': data['total_likes'],
                    'total_bookmarks': data['total_bookmarks'],
                    'total_clicks': data['total_clicks'],
                    'unique_users': len(data['unique_users']),
                    'popularity_score': round(popularity_score, 2),
                    'engagement_score': round(engagement_score, 2)
                }
                
            except Exception as e:
                logger.error(f"‚ùå Failed to process place {place_key}: {str(e)}")
                self.stats['errors'] += 1
                continue
        
        logger.info(f"‚úÖ Generated vectors for {len(user_vectors)} users and {len(place_vectors)} places")
        
        self.stats['processed_users'] = len(user_vectors)
        self.stats['processed_places'] = len(place_vectors)
        
        return {
            'user_vectors': user_vectors,
            'place_vectors': place_vectors
        }
    
    def create_user_behavior_text(self, user_data: Dict[str, Any]) -> str:
        """ÏÇ¨Ïö©Ïûê ÌñâÎèô Îç∞Ïù¥ÌÑ∞Î•º BERT ÏûÖÎ†•Ïö© ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò"""
        categories = list(user_data['categories_visited'])
        total_actions = len(user_data['actions'])
        
        # ÌñâÎèô Ìå®ÌÑ¥ÏùÑ ÏûêÏó∞Ïñ¥Î°ú ÌëúÌòÑ
        behavior_parts = []
        
        if user_data['total_likes'] > 0:
            behavior_parts.append(f"likes {user_data['total_likes']} places")
        if user_data['total_bookmarks'] > 0:
            behavior_parts.append(f"bookmarks {user_data['total_bookmarks']} places")
        if user_data['total_clicks'] > 0:
            behavior_parts.append(f"clicks {user_data['total_clicks']} places")
        
        behavior_text = f"User interested in {', '.join(categories)} categories, " + \
                       f"performed {total_actions} actions: " + \
                       ', '.join(behavior_parts)
        
        return behavior_text[:512]  # BERT ÏûÖÎ†• Í∏∏Ïù¥ Ï†úÌïú
    
    def save_to_database(self, vectors_data: Dict[str, Dict[str, Any]]) -> bool:
        """Î≤°ÌÑ∞ Îç∞Ïù¥ÌÑ∞Î•º Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê Ï†ÄÏû•"""
        if not self.SessionLocal:
            logger.warning("‚ö†Ô∏è Database not available, skipping database save")
            return False
            
        logger.info("üíæ Saving vectors to database")
        
        db = self.SessionLocal()
        try:
            user_vectors = vectors_data['user_vectors']
            place_vectors = vectors_data['place_vectors']
            
            # ÏÇ¨Ïö©Ïûê Î≤°ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏/ÏÇΩÏûÖ
            for user_id, data in user_vectors.items():
                try:
                    # UPSERT ÏøºÎ¶¨ Ïã§Ìñâ
                    db.execute(text("""
                        INSERT INTO user_behavior_vectors 
                        (user_id, behavior_vector, like_score, bookmark_score, click_score, dwell_time_score,
                         total_actions, total_likes, total_bookmarks, total_clicks, last_action_date, vector_updated_at)
                        VALUES (:user_id, :behavior_vector, :like_score, :bookmark_score, :click_score, :dwell_time_score,
                                :total_actions, :total_likes, :total_bookmarks, :total_clicks, :last_action_date, NOW())
                        ON CONFLICT (user_id) DO UPDATE SET
                            behavior_vector = EXCLUDED.behavior_vector,
                            like_score = EXCLUDED.like_score,
                            bookmark_score = EXCLUDED.bookmark_score,
                            click_score = EXCLUDED.click_score,
                            dwell_time_score = EXCLUDED.dwell_time_score,
                            total_actions = EXCLUDED.total_actions,
                            total_likes = EXCLUDED.total_likes,
                            total_bookmarks = EXCLUDED.total_bookmarks,
                            total_clicks = EXCLUDED.total_clicks,
                            last_action_date = EXCLUDED.last_action_date,
                            vector_updated_at = NOW()
                    """), {
                        'user_id': user_id,
                        'behavior_vector': data['behavior_vector'],
                        'like_score': data['like_score'],
                        'bookmark_score': data['bookmark_score'],
                        'click_score': data['click_score'],
                        'dwell_time_score': data['dwell_time_score'],
                        'total_actions': data['total_actions'],
                        'total_likes': data['total_likes'],
                        'total_bookmarks': data['total_bookmarks'],
                        'total_clicks': data['total_clicks'],
                        'last_action_date': data['last_action_date']
                    })
                except Exception as e:
                    logger.error(f"‚ùå Failed to save user vector {user_id}: {str(e)}")
                    continue
            
            # Ïû•ÏÜå Î≤°ÌÑ∞ ÏóÖÎç∞Ïù¥Ìä∏/ÏÇΩÏûÖ
            for place_key, data in place_vectors.items():
                try:
                    db.execute(text("""
                        INSERT INTO place_vectors 
                        (place_id, place_category, behavior_vector, combined_vector,
                         total_likes, total_bookmarks, total_clicks, unique_users,
                         popularity_score, engagement_score, vector_updated_at, stats_updated_at)
                        VALUES (:place_id, :place_category, :behavior_vector, :combined_vector,
                                :total_likes, :total_bookmarks, :total_clicks, :unique_users,
                                :popularity_score, :engagement_score, NOW(), NOW())
                        ON CONFLICT (place_id, place_category) DO UPDATE SET
                            behavior_vector = EXCLUDED.behavior_vector,
                            combined_vector = EXCLUDED.combined_vector,
                            total_likes = EXCLUDED.total_likes,
                            total_bookmarks = EXCLUDED.total_bookmarks,
                            total_clicks = EXCLUDED.total_clicks,
                            unique_users = EXCLUDED.unique_users,
                            popularity_score = EXCLUDED.popularity_score,
                            engagement_score = EXCLUDED.engagement_score,
                            vector_updated_at = NOW(),
                            stats_updated_at = NOW()
                    """), {
                        'place_id': data['place_id'],
                        'place_category': data['place_category'],
                        'behavior_vector': data['behavior_vector'],
                        'combined_vector': data['combined_vector'],
                        'total_likes': data['total_likes'],
                        'total_bookmarks': data['total_bookmarks'],
                        'total_clicks': data['total_clicks'],
                        'unique_users': data['unique_users'],
                        'popularity_score': data['popularity_score'],
                        'engagement_score': data['engagement_score']
                    })
                except Exception as e:
                    logger.error(f"‚ùå Failed to save place vector {place_key}: {str(e)}")
                    continue
            
            db.commit()
            logger.info(f"‚úÖ Saved {len(user_vectors)} user vectors and {len(place_vectors)} place vectors to database")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Database save failed: {str(e)}")
            db.rollback()
            return False
        finally:
            db.close()
    
    def send_webhook_notification(self, success: bool, error_message: Optional[str] = None):
        """Main EC2Ïóê Ï≤òÎ¶¨ ÏôÑÎ£å ÏïåÎ¶º Ï†ÑÏÜ°"""
        if not WEBHOOK_URL:
            logger.warning("‚ö†Ô∏è WEBHOOK_URL not provided, skipping webhook notification")
            return
            
        logger.info(f"üì° Sending webhook notification to {WEBHOOK_URL}")
        
        try:
            webhook_data = {
                'job_id': JOB_ID,
                'job_name': JOB_NAME,
                'job_status': 'SUCCEEDED' if success else 'FAILED',
                'batch_id': BATCH_ID,
                'processed_records': self.stats['processed_actions'],
                'processing_time_seconds': (self.stats['end_time'] - self.stats['start_time']).total_seconds(),
                's3_input_path': f's3://{S3_BUCKET}/{S3_PREFIX}',
                'error_message': error_message,
                'metadata': {
                    'processed_files': self.stats['processed_files'],
                    'processed_users': self.stats['processed_users'],
                    'processed_places': self.stats['processed_places'],
                    'errors': self.stats['errors']
                }
            }
            
            response = requests.post(
                WEBHOOK_URL,
                json=webhook_data,
                timeout=30,
                headers={'Content-Type': 'application/json'}
            )
            
            if response.status_code == 200:
                logger.info("‚úÖ Webhook notification sent successfully")
            else:
                logger.error(f"‚ùå Webhook notification failed: {response.status_code} - {response.text}")
                
        except Exception as e:
            logger.error(f"‚ùå Failed to send webhook: {str(e)}")
    
    def run(self):
        """Î©îÏù∏ Ï≤òÎ¶¨ Î°úÏßÅ Ïã§Ìñâ"""
        logger.info("üéØ Starting batch processing")
        
        try:
            # 1. S3 ÌååÏùº Î™©Î°ù Ï°∞Ìöå
            files = self.list_s3_files(max_files=50)  # ÌïúÎ≤àÏóê ÏµúÎåÄ 50Í∞ú ÌååÏùº Ï≤òÎ¶¨
            
            if not files:
                logger.info("‚úÖ No files to process")
                self.send_webhook_notification(success=True)
                return
            
            # 2. ÌååÏùºÎ≥ÑÎ°ú Ï≤òÎ¶¨
            all_actions = []
            
            for file_info in files:
                actions = self.download_and_parse_s3_file(file_info['key'])
                if actions:
                    all_actions.extend(actions)
                    self.stats['processed_files'] += 1
            
            if not all_actions:
                logger.info("‚úÖ No actions to process")
                self.send_webhook_notification(success=True)
                return
                
            self.stats['processed_actions'] = len(all_actions)
            logger.info(f"üìä Total actions to process: {len(all_actions)}")
            
            # 3. Î≤°ÌÑ∞Ìôî Ï≤òÎ¶¨
            vectors_data = self.process_user_actions(all_actions)
            
            # 4. Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê Ï†ÄÏû•
            db_success = self.save_to_database(vectors_data)
            
            # 5. Ï≤òÎ¶¨ ÏôÑÎ£å ÏïåÎ¶º
            self.stats['end_time'] = datetime.now()
            
            if db_success:
                logger.info("üéâ Batch processing completed successfully")
                self.send_webhook_notification(success=True)
            else:
                logger.error("‚ùå Database save failed")
                self.send_webhook_notification(success=False, error_message="Database save failed")
                
        except Exception as e:
            logger.error(f"‚ùå Batch processing failed: {str(e)}")
            logger.error(traceback.format_exc())
            
            self.stats['end_time'] = datetime.now()
            self.send_webhook_notification(success=False, error_message=str(e))
            raise

def main():
    """Î©îÏù∏ ÏóîÌä∏Î¶¨ Ìè¨Ïù∏Ìä∏"""
    logger.info("üöÄ Witple Batch Processor Starting")
    
    # ÌôòÍ≤Ω Î≥ÄÏàò Í≤ÄÏ¶ù
    required_env_vars = ['DATABASE_URL']
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]
    
    if missing_vars:
        logger.error(f"‚ùå Missing required environment variables: {missing_vars}")
        sys.exit(1)
    
    try:
        processor = BatchProcessor()
        processor.run()
        logger.info("üéâ Batch processing completed successfully")
        
    except Exception as e:
        logger.error(f"‚ùå Fatal error: {str(e)}")
        logger.error(traceback.format_exc())
        sys.exit(1)

if __name__ == "__main__":
    main()