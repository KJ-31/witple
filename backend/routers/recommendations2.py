# íŒŒì¼ëª…: recommendation2.py (ì™„ì„±ëœ ê°œì„  ë²„ì „)

from fastapi import APIRouter, HTTPException, Depends, Query
from typing import List, Optional, Dict, Any
import asyncio
import logging
from asyncio import Semaphore
import hashlib
import json

# í†µí•©ëœ ì„í¬íŠ¸ (backend í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)
try:
    # backend í™˜ê²½ì—ì„œì˜ ì„í¬íŠ¸
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))

    from vectorization2 import get_engine, close_engine
    from auth_utils import get_current_user_optional
    from recommendation_config import EXPLORE_REGIONS, EXPLORE_CATEGORIES, config
    from cache_utils import cache, cached  # Redis ìºì‹± ìœ í‹¸ë¦¬í‹° ì¶”ê°€
except ImportError:
    try:
        # ìƒëŒ€ ì„í¬íŠ¸ ì‹œë„
        from ..vectorization2 import get_engine, close_engine
        from ..auth_utils import get_current_user_optional
        from ..recommendation_config import EXPLORE_REGIONS, EXPLORE_CATEGORIES, config
        from ..cache_utils import cache, cached  # Redis ìºì‹± ìœ í‹¸ë¦¬í‹° ì¶”ê°€
    except ImportError:
        # ê°œë°œìš© Mock
        async def get_engine():
            return None
        async def close_engine():
            pass
        def get_current_user_optional():
            return None
        EXPLORE_REGIONS = ["ì„œìš¸íŠ¹ë³„ì‹œ", "ë¶€ì‚°ê´‘ì—­ì‹œ"]
        EXPLORE_CATEGORIES = ["restaurants", "accommodation"]
        config = None
        
        # Mock cache
        class MockCache:
            def get(self, key): return None
            def set(self, key, value, expire=None): return True
        cache = MockCache()
        def cached(expire=300, key_prefix=""):
            def decorator(func):
                return func
            return decorator

logger = logging.getLogger(__name__)

router = APIRouter(
    prefix="/recommendations",
    tags=["recommendations"]
)

# ë¦¬ì†ŒìŠ¤ ì œí•œ ì„¤ì • (í†µí•© ì„¤ì • ì‚¬ìš©)
MAX_PARALLEL_REQUESTS = config.max_parallel_requests if config else 8
RECOMMENDATION_TIMEOUT = config.recommendation_timeout if config else 3.0

# ë³‘ë ¬ ìš”ì²­ ì œí•œ (ë²¡í„°í™” ì—”ì§„ì˜ DB í’€ ë³´í˜¸)
REQUEST_SEMAPHORE = Semaphore(MAX_PARALLEL_REQUESTS)


# ============================================================================
# ğŸ”§ Redis ìºì‹± ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ============================================================================

def generate_cache_key(prefix: str, user_id: Optional[str], region: Optional[str], 
                      category: Optional[str], limit: int, **kwargs) -> str:
    """
    ìºì‹œ í‚¤ ìƒì„± í•¨ìˆ˜ (ì‚¬ìš©ì ìš°ì„ ìˆœìœ„ íƒœê·¸ í¬í•¨) - ê°œì„ ëœ ë²„ì „
    """
    # ì‚¬ìš©ìë³„ë¡œ ë‹¤ë¥¸ ìºì‹œë¥¼ ì‚¬ìš© (ê°œì¸í™” ì¶”ì²œ)
    user_part = f"user_{user_id}" if user_id else "anonymous"
    
    # ìš°ì„ ìˆœìœ„ íƒœê·¸ ì¶”ì¶œ (ìºì‹œ í‚¤ì— ë°˜ë“œì‹œ í¬í•¨)
    priority_tag = kwargs.get('priority_tag', 'none')
    
    # íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ë ¬ëœ ë¬¸ìì—´ë¡œ ë³€í™˜ (ìš°ì„ ìˆœìœ„ íƒœê·¸ í¬í•¨)
    params = {
        'region': region or 'all',
        'category': category or 'all',
        'limit': limit,
        'priority_tag': priority_tag  # ğŸ”‘ í•µì‹¬: ìš°ì„ ìˆœìœ„ íƒœê·¸ë¥¼ ìºì‹œ í‚¤ì— í¬í•¨
    }
    
    # ë‹¤ë¥¸ kwargsë„ ì¶”ê°€ (fast_mode, exclude_names ë“±)
    for key, value in kwargs.items():
        if key != 'priority_tag':  # ì´ë¯¸ ì¶”ê°€ë¨
            params[key] = str(value) if value is not None else 'none'
    
    # ì•ˆì •ì ì¸ í•´ì‹œ ìƒì„±ì„ ìœ„í•´ ì •ë ¬
    param_str = "&".join([f"{k}={v}" for k, v in sorted(params.items())])
    
    # MD5 í•´ì‹œë¡œ ê¸´ í‚¤ë¥¼ ì¤„ì„
    hash_obj = hashlib.md5(param_str.encode())
    param_hash = hash_obj.hexdigest()[:8]
    
    return f"{prefix}:{user_part}:{priority_tag}:{param_hash}"

def get_recommendations_cache(cache_key: str) -> Optional[List[Dict[str, Any]]]:
    """ìºì‹œì—ì„œ ì¶”ì²œ ë°ì´í„° ì¡°íšŒ (ë³µì›ë¨)"""
    try:
        cached_data = cache.get(cache_key)
        if cached_data:
            logger.info(f"âœ… Cache hit: {cache_key}")
            return cached_data
        logger.debug(f"ğŸ” Cache miss: {cache_key}")
        return None
    except Exception as e:
        logger.error(f"âŒ Cache get error: {e}")
        return None

def set_recommendations_cache(cache_key: str, data: List[Dict[str, Any]], expire: int = 900) -> bool:
    """ìºì‹œì— ì¶”ì²œ ë°ì´í„° ì €ì¥ (ê¸°ë³¸ 15ë¶„) - ë³µì›ë¨"""
    try:
        success = cache.set(cache_key, data, expire=expire)
        if success:
            logger.info(f"ğŸ’¾ Cache set: {cache_key} (expire: {expire}s)")
        return success
    except Exception as e:
        logger.error(f"âŒ Cache set error: {e}")
        return False


# ============================================================================
# ğŸ”§ ì•ˆì „í•œ ì¶”ì²œ ë°ì´í„° ì¡°íšŒ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ (ìºì‹± ì ìš©)
# ============================================================================

async def fetch_recommendations_with_fallback(
    user_id: Optional[str],
    region: Optional[str],
    category: Optional[str],
    limit: int,
    fast_mode: bool = False,  # ë©”ì¸ í˜ì´ì§€ìš© ê³ ì† ëª¨ë“œ
    priority_tag: Optional[str] = None  # ì‚¬ìš©ì ìš°ì„ ìˆœìœ„ íƒœê·¸
) -> List[Dict[str, Any]]:
    """
    ì•ˆì „í•œ ì¶”ì²œ ë°ì´í„° ì¡°íšŒ (í†µí•© ì—”ì§„ ì‚¬ìš©) - Redis ìºì‹± ì ìš©
    """
    # ìºì‹œ í‚¤ ìƒì„± (ìš°ì„ ìˆœìœ„ íƒœê·¸ í¬í•¨)
    cache_key = generate_cache_key(
        prefix="rec_main",
        user_id=user_id,
        region=region,
        category=category,
        limit=limit,
        fast_mode=fast_mode,
        priority_tag=priority_tag or "none"
    )
    
    # ìºì‹œì—ì„œ ì¡°íšŒ ì‹œë„ (ë³µì›ë¨)
    cached_result = get_recommendations_cache(cache_key)
    if cached_result is not None:
        return cached_result
    
    async with REQUEST_SEMAPHORE:
        try:
            # í†µí•© ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ íšë“
            engine = await get_engine()

            # íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ì¶”ì²œ ì¡°íšŒ
            result = await asyncio.wait_for(
                engine.get_recommendations(
                    user_id=user_id,
                    region=region,
                    category=category,
                    limit=limit,
                    fast_mode=fast_mode  # fast_mode ì „ë‹¬
                ),
                timeout=RECOMMENDATION_TIMEOUT
            )
            
            # ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìºì‹œì— ì €ì¥ (ë©”ì¸í˜ì´ì§€ëŠ” 1ì‹œê°„, ì¼ë°˜ì€ 15ë¶„) - ë³µì›ë¨
            if result:
                expire_time = 3600 if fast_mode else 900  # 1ì‹œê°„ or 15ë¶„
                set_recommendations_cache(cache_key, result, expire=expire_time)
            
            return result if result else []

        except asyncio.TimeoutError:
            logger.warning(f"Timeout for recommendations: user={user_id}, region={region}, category={category}")
            return []
        except Exception as e:
            logger.error(f"Failed to get recommendations: user={user_id}, region={region}, category={category}, error={e}")
            return []


async def fetch_explore_data_parallel(
    user_id: Optional[str],
    regions: List[str],
    categories: List[str],
    fast_mode: bool = True,  # exploreëŠ” ê¸°ë³¸ì ìœ¼ë¡œ fast_mode
    priority_tag: Optional[str] = None  # ì‚¬ìš©ì ìš°ì„ ìˆœìœ„ íƒœê·¸
) -> Dict[str, Dict[str, List[Dict[str, Any]]]]:
    """
    íƒìƒ‰ ë°ì´í„°ë¥¼ ë³‘ë ¬ë¡œ ì•ˆì „í•˜ê²Œ ì¡°íšŒ
    """
    # ì‘ì—… ì •ì˜ (í‚¤-ê°’ ë§¤í•‘ìœ¼ë¡œ ìˆœì„œ ë³´ì¥)
    tasks = {
        f"{region}:{category}": fetch_recommendations_with_fallback(
            user_id=user_id,
            region=region,
            category=category,
            limit=5,  # ì„±ëŠ¥ ê°œì„ ì„ ìœ„í•´ ê°ì†Œ
            fast_mode=fast_mode,  # fast_mode ì „ë‹¬
            priority_tag=priority_tag or "none"
        )
        for region in regions
        for category in categories
    }

    logger.info(f"Starting {len(tasks)} parallel recommendation requests")

    # ëª¨ë“  ì‘ì—…ì„ ë³‘ë ¬ ì‹¤í–‰ (ë¶€ë¶„ ì‹¤íŒ¨ í—ˆìš©)
    results = await asyncio.gather(*tasks.values(), return_exceptions=True)

    # ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
    explore_data = {}
    success_count = 0

    for (key, result) in zip(tasks.keys(), results):
        region, category = key.split(':')

        if region not in explore_data:
            explore_data[region] = {}

        # ì˜ˆì™¸ê°€ ë°œìƒí•œ ê²½ìš° ë¹ˆ ë°°ì—´ë¡œ ëŒ€ì²´
        if isinstance(result, Exception):
            logger.error(f"Task {key} failed with exception: {result}")
            explore_data[region][category] = []
        else:
            explore_data[region][category] = result
            success_count += 1

    logger.info(f"Completed parallel requests: {success_count}/{len(tasks)} successful")
    return explore_data


# ============================================================================
# ğŸš€ ë©”ì¸ í˜ì´ì§€ë¥¼ ìœ„í•œ API ì—”ë“œí¬ì¸íŠ¸ë“¤
# ============================================================================

@router.get("/main-feed/personalized", response_model=dict)
async def get_main_personalized_feed(
    current_user=Depends(get_current_user_optional),
    limit: int = Query(21, ge=1, le=50, description="ëŒ€í‘œ ì¹´ë“œ 1ê°œ + ëª©ë¡ 20ê°œ (ìµœëŒ€ 50ê°œ)"),
    region: Optional[str] = Query(None, description="ì§€ì—­ í•„í„° (ì„ íƒì‚¬í•­)")
):
    """
    ë©”ì¸ ìƒë‹¨ 'For You' ì„¹ì…˜ - ê°œì¸í™” ì¶”ì²œ (Redis ìºì‹± ì ìš©)
    - ë¡œê·¸ì¸: ê°œì¸í™” ì¶”ì²œ (ì§€ì—­/ì¹´í…Œê³ ë¦¬ ë¬´ê´€, ê· ë“± ê°€ì¤‘ì¹˜ 50:50)
    - ë¹„ë¡œê·¸ì¸: ì¸ê¸° ì¶”ì²œ (bookmark_cnt ê¸°ì¤€)
    """
    try:
        user_id = str(current_user.user_id) if current_user else None

        # priority_tag ê°€ì ¸ì˜¤ê¸° (ìºì‹œ í‚¤ì— í¬í•¨í•˜ê¸° ìœ„í•´ ë¨¼ì € ì¡°íšŒ)
        user_priority_tag = "none"
        if user_id:
            try:
                engine = await get_engine()
                priority = await engine.get_user_priority_tag(user_id)
                user_priority_tag = priority or "none"
            except Exception as e:
                logger.warning(f"Failed to get user priority for cache key: {e}")

        # ì „ì²´ ì‘ë‹µ ìºì‹±ì„ ìœ„í•œ ìºì‹œ í‚¤ ìƒì„± (ìš°ì„ ìˆœìœ„ íƒœê·¸ í¬í•¨)
        response_cache_key = generate_cache_key(
            prefix="main_personalized",
            user_id=user_id,
            region=region,
            category=None,
            limit=limit,
            priority_tag=user_priority_tag  # ìš°ì„ ìˆœìœ„ íƒœê·¸ ì¶”ê°€
        )
        
        # ìºì‹œëœ ì‘ë‹µ ì¡°íšŒ (ë³µì›ë¨)
        cached_response = cache.get(response_cache_key)
        if cached_response is not None:
            logger.info(f"ğŸš€ Main personalized feed cache hit: {response_cache_key}")
            return cached_response

        # user_priority_tagëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì¡°íšŒë¨

        logger.info(f"ğŸ” Getting personalized feed for user: {user_id}, priority_tag: {user_priority_tag}, limit: {limit}")
        print(f"ğŸ” DEBUG: user_id={user_id}, priority_tag={user_priority_tag}")

        # experience ì‚¬ìš©ìëŠ” ë³„ë„ ì²˜ë¦¬ (í´ë°± í¬í•¨)
        if user_priority_tag == "experience":
            logger.info(f"ğŸ¯ Processing experience user with fallback")
            # ë¨¼ì € ê°œì¸í™” ì¶”ì²œ ì‹œë„
            recommendations = await fetch_recommendations_with_fallback(
                user_id=user_id,
                region=region,
                category=None,
                limit=limit,
                fast_mode=True,
                priority_tag=user_priority_tag
            )
            # ê°œì¸í™” ì¶”ì²œì´ ì‹¤íŒ¨í•˜ë©´ experience ì¹´í…Œê³ ë¦¬ì˜ ì¸ê¸° ì¶”ì²œìœ¼ë¡œ í´ë°±
            if not recommendations:
                logger.info(f"ğŸ¯ Fallback to popular experience recommendations")
                # experience ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¸ê¸° ì¶”ì²œ ê°€ì ¸ì˜¤ê¸°
                experience_recommendations = []
                experience_categories = ["nature", "humanities", "leisure_sports"]
                for category in experience_categories:
                    category_recs = await fetch_recommendations_with_fallback(
                        user_id=None,  # ì¸ê¸° ì¶”ì²œì„ ìœ„í•´ None
                        region=None,
                        category=category,
                        limit=limit // len(experience_categories) + 2,
                        fast_mode=True,
                        priority_tag="none"  # ì¸ê¸° ì¶”ì²œì´ë¯€ë¡œ ìš°ì„ ìˆœìœ„ íƒœê·¸ ì—†ìŒ
                    )
                    if category_recs:
                        experience_recommendations.extend(category_recs)

                # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ì œí•œ
                if experience_recommendations:
                    experience_recommendations.sort(key=lambda x: x.get('final_score', 0), reverse=True)
                    recommendations = experience_recommendations[:limit]
                    logger.info(f"ğŸ¯ Fallback returned {len(recommendations)} experience recommendations")
        else:
            # ì¼ë°˜ ì‚¬ìš©ìëŠ” ê¸°ì¡´ ë¡œì§
            recommendations = await fetch_recommendations_with_fallback(
                user_id=user_id,
                region=region,  # ì§€ì—­ í•„í„° ì ìš©
                category=None,
                limit=limit,
                fast_mode=True,  # ë©”ì¸ í”¼ë“œëŠ” í•­ìƒ ê³ ì† ëª¨ë“œ
                priority_tag=user_priority_tag
            )

        logger.info(f"ğŸ” Initial recommendations count: {len(recommendations) if recommendations else 0}")

        if not recommendations:
            return {
                "featured": None,
                "feed": [],
                "message": "ì¶”ì²œí•  ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤."
            }

        # ì²´í—˜ ìš°ì„ ìˆœìœ„ ì‚¬ìš©ìì—ê²ŒëŠ” ì²´í—˜ ê´€ë ¨ ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§
        if user_priority_tag == "experience":
            experience_categories = ["nature", "humanities", "leisure_sports"]
            logger.info(f"ğŸ¯ Experience user - filtering to experience categories: {experience_categories}")
            recommendations = [
                rec for rec in recommendations
                if rec.get('table_name') in experience_categories
            ]
            logger.info(f"ğŸ¯ Filtered recommendations count: {len(recommendations)}")

        # ì‘ë‹µ ë°ì´í„°ì— category í•„ë“œ ì¶”ê°€
        processed_recommendations = []
        for rec in recommendations:
            processed_rec = dict(rec)  # ë”•ì…”ë„ˆë¦¬ ë³µì‚¬
            # table_nameì„ categoryë¡œ ë§¤í•‘
            table_name = rec.get('table_name', '')
            category_mapping = {
                'accommodation': 'accommodation',
                'restaurants': 'restaurants',
                'shopping': 'shopping',
                'nature': 'nature',
                'humanities': 'culture',
                'leisure_sports': 'leisure'
            }
            processed_rec['category'] = category_mapping.get(table_name, table_name)
            processed_recommendations.append(processed_rec)

        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        response_data = {
            "featured": processed_recommendations[0] if processed_recommendations else None,
            "feed": processed_recommendations[1:] if len(processed_recommendations) > 1 else [],
            "total_count": len(processed_recommendations)
        }
        
        # ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥ (1ì‹œê°„ ìºì‹±) - ë³µì›ë¨
        cache.set(response_cache_key, response_data, expire=3600)
        logger.info(f"ğŸš€ Main personalized feed cached: {response_cache_key}")
        
        return response_data

    except Exception as e:
        logger.error(f"Error in get_main_personalized_feed: {e}")
        raise HTTPException(
            status_code=500,
            detail="ê°œì¸í™” í”¼ë“œë¥¼ ì¡°íšŒí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )


@router.get("/main-feed/explore", response_model=dict)
async def get_main_explore_feed(
    current_user=Depends(get_current_user_optional),
    regions: Optional[List[str]] = Query(None, description="ìš”ì²­í•  ì§€ì—­ ëª©ë¡ (ë¯¸ì§€ì •ì‹œ ì¸ê¸°ìˆœ)"),
    categories: Optional[List[str]] = Query(None, description="ìš”ì²­í•  ì¹´í…Œê³ ë¦¬ ëª©ë¡ (ë¯¸ì§€ì •ì‹œ ì¸ê¸°ìˆœ)")
):
    """
    ë©”ì¸ í•˜ë‹¨ 'íƒìƒ‰' ì„¹ì…˜ - ë™ì  ì¸ê¸°ìˆœ ì§€ì—­ë³„/ì¹´í…Œê³ ë¦¬ë³„ ì¶”ì²œ (Redis ìºì‹± ì ìš©)
    - ì§€ì—­: ë¶ë§ˆí¬ ì´í•© ê¸°ì¤€ ì¸ê¸°ìˆœ
    - ì¹´í…Œê³ ë¦¬: ë¶ë§ˆí¬ ì´í•© ê¸°ì¤€ ì¸ê¸°ìˆœ
    - ì¥ì†Œ: bookmark_cnt ê¸°ì¤€ ì¸ê¸°ìˆœ
    """
    try:
        user_id = str(current_user.user_id) if current_user else None

        # ì „ì²´ ì‘ë‹µ ìºì‹±ì„ ìœ„í•œ ìºì‹œ í‚¤ ìƒì„±
        regions_str = ",".join(sorted(regions)) if regions else "default"
        categories_str = ",".join(sorted(categories)) if categories else "default"
        
        explore_cache_key = generate_cache_key(
            prefix="main_explore",
            user_id=user_id,
            region=regions_str,
            category=categories_str,
            limit=50,  # ê¸°ë³¸ limit
            regions_count=len(regions) if regions else 0,
            categories_count=len(categories) if categories else 0
        )
        
        # ìºì‹œëœ ì‘ë‹µ ì¡°íšŒ (ë³µì›ë¨)
        cached_response = cache.get(explore_cache_key)
        if cached_response is not None:
            logger.info(f"ğŸš€ Main explore feed cache hit: {explore_cache_key}")
            return cached_response

        # ë™ì  ì§€ì—­/ì¹´í…Œê³ ë¦¬ ìˆœì„œ ê²°ì • (í•˜ë“œì½”ë”© ì œê±°)
        if not regions or not categories:
            engine = await get_engine()
            popular_data = await engine.get_popular_regions_and_categories()

            target_regions = regions or popular_data['regions']
            target_categories = categories or popular_data['categories']
        else:
            target_regions = regions
            target_categories = categories

        logger.info(f"Getting explore feed for user: {user_id}")
        logger.info(f"Dynamic regions: {target_regions[:3]}... ({len(target_regions)} total)")
        logger.info(f"Dynamic categories: {target_categories[:3]}... ({len(target_categories)} total)")

        # ğŸ”‘ ì‚¬ìš©ì ìš°ì„ ìˆœìœ„ íƒœê·¸ ì¡°íšŒ (ì¹´í…Œê³ ë¦¬ í•„í„°ë§ìš©)
        user_priority_tag = "none"
        if user_id:
            try:
                engine = await get_engine()
                priority = await engine.get_user_priority_tag(user_id)
                user_priority_tag = priority or "none"
            except Exception as e:
                logger.warning(f"Failed to get user priority for cache key: {e}")

        # ì„±ëŠ¥ì„ ìœ„í•´ ì¼ë¶€ ì¹´í…Œê³ ë¦¬ë§Œ ì‚¬ìš©, ì§€ì—­ì€ ëª¨ë‘ í¬í•¨
        limited_regions = target_regions  # ëª¨ë“  ì§€ì—­ í¬í•¨

        # ì²´í—˜ ìš°ì„ ìˆœìœ„ ì‚¬ìš©ìì—ê²ŒëŠ” ì²´í—˜ ê´€ë ¨ ì¹´í…Œê³ ë¦¬ë§Œ ì œê³µ
        if user_priority_tag == "experience":
            limited_categories = ["nature", "humanities", "leisure_sports"]
            logger.info(f"ğŸ¯ Experience user - showing only experience categories: {limited_categories}")
        else:
            limited_categories = target_categories[:6]  # ìƒìœ„ 6ê°œ ì¹´í…Œê³ ë¦¬ (ìš”ì²­ì‚¬í•­ ë°˜ì˜)

        # ğŸš€ Redis ìºì‹œ í‚¤ ìƒì„± (ìš°ì„ ìˆœìœ„ íƒœê·¸ í¬í•¨) - v3 (ì²´í—˜ ìš°ì„ ìˆœìœ„ í•„í„°ë§ ìˆ˜ì •)
        cache_key = f"explore_feed_v3:{user_id or 'anonymous'}:{user_priority_tag}:{':'.join(sorted(limited_regions))}:{':'.join(sorted(limited_categories))}"

        logger.info(f"ğŸ”‘ Cache key generated: {cache_key}")

        # ìºì‹œì—ì„œ ì¡°íšŒ ì‹œë„ (ì£¼ì„ì²˜ë¦¬)
        # from cache_utils import cache
        # cached_result = cache.get(cache_key)
        # if cached_result is not None:
        #     logger.info(f"ğŸ¯ Cache hit for explore feed: {cache_key}")
        #     return cached_result
        # else:
        #     logger.info(f"ğŸ” Cache miss for explore feed: {cache_key}")

        # ë³‘ë ¬ë¡œ ì œí•œëœ ì„¹ì…˜ ë°ì´í„° ì¡°íšŒ
        explore_data = await fetch_explore_data_parallel(
            user_id=user_id,
            regions=limited_regions,
            categories=limited_categories,
            priority_tag=user_priority_tag
        )

        # ì‘ë‹µì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
        total_sections = len(target_regions) * len(target_categories)
        non_empty_sections = sum(
            1 for region_data in explore_data.values()
            for category_data in region_data.values()
            if category_data
        )

        result = {
            "data": explore_data,
            "metadata": {
                "total_sections": total_sections,
                "non_empty_sections": non_empty_sections,
                "regions": target_regions,
                "categories": target_categories,
                "ordering": "dynamic_popularity"  # ë™ì  ì¸ê¸°ìˆœ í‘œì‹œ
            }
        }

        # ğŸš€ ì‘ë‹µì„ ìƒˆë¡œìš´ ìºì‹œ í‚¤ë¡œ ì €ì¥ (1ì‹œê°„ TTL - ë©”ì¸í˜ì´ì§€ìš© ìµœì í™”) - ë³µì›ë¨
        cache.set(explore_cache_key, result, expire=3600)
        logger.info(f"ğŸš€ Main explore feed cached: {explore_cache_key}")

        return result

    except Exception as e:
        logger.error(f"Error in get_main_explore_feed: {e}")
        raise HTTPException(
            status_code=500,
            detail="íƒìƒ‰ í”¼ë“œë¥¼ ì¡°íšŒí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )


# ============================================================================
# ğŸ”§ ê°œë³„ ì„¹ì…˜ ì¡°íšŒ API (ì§€ì—° ë¡œë”© ì§€ì›)
# ============================================================================

@router.get("/explore/{region}/{category}", response_model=dict)
async def get_explore_section(
    region: str,
    category: str,
    current_user=Depends(get_current_user_optional),
    limit: int = Query(10, ge=1, le=50, description="ì¡°íšŒí•  ì•„ì´í…œ ìˆ˜"),
    offset: int = Query(0, ge=0, description="í˜ì´ì§• ì˜¤í”„ì…‹"),
    exclude_place_names: Optional[str] = Query(None, description="ì œì™¸í•  ì¥ì†Œ ì´ë¦„ë“¤ (ì‰¼í‘œë¡œ êµ¬ë¶„)")
):
    """
    íŠ¹ì • ì§€ì—­/ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ ë°ì´í„° ì¡°íšŒ (ìš°ì„ ìˆœìœ„ íƒœê·¸ ê¸°ë°˜ í•„í„°ë§, ì§€ì—° ë¡œë”©, í˜ì´ì§• ì§€ì›) - Redis ìºì‹± ì ìš©
    """
    try:
        user_id = str(current_user.user_id) if current_user else None

        # ê°œë³„ ì„¹ì…˜ ìºì‹œ í‚¤ ìƒì„±
        section_cache_key = generate_cache_key(
            prefix="explore_section",
            user_id=user_id,
            region=region,
            category=category,
            limit=limit,
            offset=offset
        )
        
        # ìºì‹œëœ ì‘ë‹µ ì¡°íšŒ (ë³µì›ë¨)
        cached_section = cache.get(section_cache_key)
        if cached_section is not None:
            logger.info(f"ğŸš€ Explore section cache hit: {section_cache_key}")
            return cached_section

        logger.info(f"Getting section data: {region}/{category} for user: {user_id}")

        # ğŸ¯ ë¡œê·¸ì¸ëœ ì‚¬ìš©ìì˜ ê²½ìš° ìš°ì„ ìˆœìœ„ íƒœê·¸ ê¸°ë°˜ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ê²°ì • (ì•ˆì „í•œ ì²˜ë¦¬)
        target_category = category
        user_priority = None  # ê¸°ë³¸ê°’ ì„¤ì •
        if current_user and user_id:
            try:
                engine = await get_engine()

                # ì‚¬ìš©ì ìš°ì„ ìˆœìœ„ íƒœê·¸ ì¡°íšŒ (ì¶”ê°€ ë³´í˜¸)
                try:
                    user_priority = await asyncio.wait_for(
                        engine.get_user_priority_tag(user_id),
                        timeout=2.0  # 2ì´ˆ íƒ€ì„ì•„ì›ƒ
                    )
                except asyncio.TimeoutError:
                    logger.warning(f"Timeout getting user priority for {user_id}")
                    user_priority = None
                except Exception as priority_e:
                    logger.warning(f"Error getting user priority for {user_id}: {priority_e}")
                    user_priority = None

                if user_priority:
                    logger.info(f"User {user_id} priority tag: {user_priority}")

                    # ìš°ì„ ìˆœìœ„ íƒœê·¸ì— ë”°ë¥¸ ì¹´í…Œê³ ë¦¬ ë§¤í•‘
                    priority_category_map = {
                        'accommodation': 'accommodation',
                        'restaurants': 'restaurants',
                        'shopping': 'shopping',
                        'experience': category  # ì²´í—˜ì€ ìš”ì²­ëœ ì¹´í…Œê³ ë¦¬ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    }

                    # ì²´í—˜ íƒœê·¸ì¸ ê²½ìš° nature/humanities/leisure_sports ì¤‘ì—ì„œë§Œ í—ˆìš©
                    if user_priority == 'experience':
                        experience_categories = ['nature', 'humanities', 'leisure_sports']
                        if category in experience_categories:
                            target_category = category
                        else:
                            # ìš”ì²­ëœ ì¹´í…Œê³ ë¦¬ê°€ ì²´í—˜ ì¹´í…Œê³ ë¦¬ê°€ ì•„ë‹ˆë©´ natureë¡œ ê¸°ë³¸ ì„¤ì •
                            target_category = 'nature'
                    else:
                        # ë‹¤ë¥¸ ìš°ì„ ìˆœìœ„ íƒœê·¸ì˜ ê²½ìš° í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë¡œ ê³ ì •
                        if user_priority in priority_category_map:
                            target_category = priority_category_map[user_priority]

                    logger.info(f"Target category for region {region}: {target_category} (based on priority: {user_priority})")
                else:
                    logger.info(f"No priority tag found for user {user_id}, using original category: {category}")

            except Exception as e:
                logger.error(f"Failed to process user priority for {user_id}: {e}")
                # ì‹¤íŒ¨ ì‹œ ì›ë˜ ì¹´í…Œê³ ë¦¬ ì‚¬ìš©
                target_category = category

        # ì œì™¸í•  ì¥ì†Œ ì´ë¦„ë“¤ íŒŒì‹±
        excluded_names = set()
        if exclude_place_names:
            excluded_names = {name.strip().lower() for name in exclude_place_names.split(',') if name.strip()}
            logger.info(f"ğŸš« ì œì™¸í•  ì¥ì†Œ {len(excluded_names)}ê°œ: {list(excluded_names)[:3]}...")

        # ì¶”ì²œ ì¡°íšŒ (ì¶”ê°€ íƒ€ì„ì•„ì›ƒ ë³´í˜¸) - ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ë” ë§ì´ ì¡°íšŒ
        extra_limit = len(excluded_names) * 2 + 5  # ì œì™¸ë  ì¥ì†Œë“¤ì„ ê³ ë ¤í•´ì„œ ë” ë§ì´ ì¡°íšŒ
        try:
            recommendations = await asyncio.wait_for(
                fetch_recommendations_with_fallback(
                    user_id=user_id,
                    region=region,
                    category=target_category,
                    limit=limit + offset + extra_limit,  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ë” ë§ì´ ì¡°íšŒ
                    fast_mode=False,  # ìƒì„¸ ì„­ì…˜ì€ ì „ì²´ ê¸°ëŠ¥ ì‚¬ìš©
                    priority_tag=user_priority or "none"
                ),
                timeout=10.0  # 10ì´ˆ íƒ€ì„ì•„ì›ƒ
            )
        except asyncio.TimeoutError:
            logger.error(f"Timeout getting recommendations for {region}/{target_category}")
            recommendations = []
        except Exception as rec_e:
            logger.error(f"Error getting recommendations for {region}/{target_category}: {rec_e}")
            recommendations = []

        # ì¤‘ë³µ ì œê±°: ì œì™¸í•  ì¥ì†Œ ì´ë¦„ë“¤ í•„í„°ë§
        if excluded_names and recommendations:
            original_count = len(recommendations)
            recommendations = [
                rec for rec in recommendations 
                if rec.get('name', '').strip().lower() not in excluded_names
            ]
            filtered_count = len(recommendations)
            if filtered_count < original_count:
                logger.info(f"âœ… ì¤‘ë³µ ì œê±°: {original_count}ê°œ â†’ {filtered_count}ê°œ (ì œê±°: {original_count - filtered_count}ê°œ)")

        # ì˜¤í”„ì…‹ ì ìš©
        paginated_recommendations = recommendations[offset:offset + limit]

        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        section_response = {
            "region": region,
            "category": target_category,  # ì‹¤ì œ ì‚¬ìš©ëœ ì¹´í…Œê³ ë¦¬ ë°˜í™˜
            "original_category": category,  # ì›ë˜ ìš”ì²­ëœ ì¹´í…Œê³ ë¦¬
            "data": paginated_recommendations,
            "pagination": {
                "offset": offset,
                "limit": limit,
                "total": len(recommendations),
                "has_more": len(recommendations) > offset + limit
            },
            "success": True,
            "message": f"Found {len(paginated_recommendations)} recommendations"
        }
        
        # ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥ (ê°œë³„ ì„¹ì…˜ì€ 15ë¶„ ìºì‹±) - ë³µì›ë¨
        cache.set(section_cache_key, section_response, expire=900)
        logger.info(f"ğŸš€ Explore section cached: {section_cache_key}")
        
        return section_response

    except Exception as e:
        logger.error(f"Error in get_explore_section: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"{region}/{category} ì„¹ì…˜ì„ ì¡°íšŒí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )


# ============================================================================
# ğŸ“Š í—¬ìŠ¤ì²´í¬ ë° ìƒíƒœ í™•ì¸ API
# ============================================================================

@router.get("/health", response_model=dict)
async def health_check():
    """
    ì¶”ì²œ ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬ (ìºì‹œ ìƒíƒœ í¬í•¨)
    """
    try:
        # ìºì‹œ ìƒíƒœ í™•ì¸
        cache_status = "healthy"
        cache_info = {"cached_keys": 0}
        try:
            # í…ŒìŠ¤íŠ¸ ìºì‹œ ì“°ê¸°/ì½ê¸° (ë³µì›ë¨)
            test_key = "health_check_test"
            test_value = {"status": "ok", "timestamp": asyncio.get_event_loop().time()}
            cache.set(test_key, test_value, expire=60)
            read_value = cache.get(test_key)
            
            if read_value and read_value.get("status") == "ok":
                cache_status = "healthy"
                # Redis ìºì‹œ í‚¤ ê°œìˆ˜ í™•ì¸
                try:
                    if hasattr(cache, 'redis'):
                        rec_keys = len(cache.redis.keys("rec_*"))
                        main_keys = len(cache.redis.keys("main_*"))
                        explore_keys = len(cache.redis.keys("explore_*"))
                        cache_info = {
                            "rec_keys": rec_keys,
                            "main_keys": main_keys,
                            "explore_keys": explore_keys,
                            "total_rec_cache": rec_keys + main_keys + explore_keys
                        }
                except Exception:
                    cache_info["note"] = "í‚¤ ê°œìˆ˜ í™•ì¸ ë¶ˆê°€"
                    
            else:
                cache_status = "write/read error"
        except Exception as e:
            cache_status = f"error: {str(e)[:50]}"

        # ê°„ë‹¨í•œ ì¶”ì²œ ìš”ì²­ìœ¼ë¡œ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ (ìºì‹œ íš¨ê³¼ í™•ì¸)
        import time
        start_time = time.time()
        test_recommendations = await fetch_recommendations_with_fallback(
            user_id=None,
            region=None,
            category=None,
            limit=1,
            fast_mode=True,  # í—¬ìŠ¤ì²´í¬ëŠ” ë¹ ë¥´ê²Œ
            priority_tag="none"
        )
        response_time = round((time.time() - start_time) * 1000, 1)  # ms

        return {
            "status": "healthy",
            "engine_responsive": True,
            "cache_status": cache_status,
            "cache_info": cache_info,
            "test_response_time_ms": response_time,
            "cache_working": response_time < 100,  # 100ms ì´í•˜ë©´ ìºì‹œì—ì„œ ì‘ë‹µ
            "timestamp": asyncio.get_event_loop().time(),
            "test_result": len(test_recommendations) > 0,
            "recommendations_count": len(test_recommendations)
        }

    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {
            "status": "unhealthy",
            "engine_responsive": False,
            "error": str(e),
            "timestamp": asyncio.get_event_loop().time()
        }


@router.delete("/cache/clear")
async def clear_cache():
    """ì¶”ì²œ ìºì‹œ ì‚­ì œ (ë³µì›ë¨)"""
    try:
        cleared = 0
        if hasattr(cache, 'redis'):
            for pattern in ["rec_*", "main_*", "explore_*"]:
                keys = cache.redis.keys(pattern)
                if keys:
                    cleared += cache.redis.delete(*keys)
        logger.info(f"ğŸ—‘ï¸ Cache cleared: {cleared} keys deleted")
        return {"cleared_keys": cleared, "message": f"{cleared}ê°œ ìºì‹œ ì‚­ì œë¨"}
    except Exception as e:
        logger.error(f"âŒ Cache clear error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# ğŸ“ ì„¤ì • ì •ë³´ ì¡°íšŒ API (ë””ë²„ê¹…/ëª¨ë‹ˆí„°ë§ìš©)
# ============================================================================

@router.get("/regions", response_model=dict)
async def get_available_regions():
    """
    ì¶”ì²œ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ì§€ì—­ ëª©ë¡ ì¡°íšŒ
    """
    try:
        engine = await get_engine()
        regions_data = await engine.get_popular_regions_and_categories()

        return {
            "regions": regions_data.get("regions", []),
            "categories": regions_data.get("categories", [])
        }
    except Exception as e:
        logger.error(f"âŒ Regions retrieval failed: {e}")
        return {
            "regions": EXPLORE_REGIONS,
            "categories": EXPLORE_CATEGORIES
        }

@router.get("/config", response_model=dict)
async def get_recommendation_config():
    """
    í˜„ì¬ ì¶”ì²œ ì‹œìŠ¤í…œ ì„¤ì • ì •ë³´ ì¡°íšŒ (ê°œë°œ/ìš´ì˜ ëª¨ë‹ˆí„°ë§ìš©)
    """
    try:
        engine = await get_engine()
        return {
            "explore_regions": EXPLORE_REGIONS,
            "explore_categories": EXPLORE_CATEGORIES,
            "max_parallel_requests": MAX_PARALLEL_REQUESTS,
            "recommendation_timeout": RECOMMENDATION_TIMEOUT,
            "engine_type": type(engine).__name__,
            "weights": {
                "similarity": config.similarity_weight if config else 0.5,
                "popularity": config.popularity_weight if config else 0.5
            }
        }
    except Exception as e:
        logger.error(f"âŒ Config retrieval failed: {e}")
        return {"error": str(e)}