# íŒŒì¼ëª…: vectorization2.py (ì™„ì „ ê°œì„  ë²„ì „)

import numpy as np
import asyncpg
import logging
import asyncio
from typing import Dict, List, Any, Optional, Union
from contextlib import asynccontextmanager
from dataclasses import dataclass
import json
import time

# í†µí•© ì„¤ì • íŒŒì¼ ì‚¬ìš© (backend í™˜ê²½ ëŒ€ì‘)
try:
    from recommendation_config import config as CONFIG
except ImportError:
    try:
        from .recommendation_config import config as CONFIG
    except ImportError:
        # Fallback ì„¤ì •
        from dataclasses import dataclass
        @dataclass
        class FallbackConfig:
            database_url: str = "postgresql://user:pass@localhost/db"
            min_pool_size: int = 3
            max_pool_size: int = 15
            db_timeout: int = 5
            candidate_limit: int = 2000
            similarity_weight: float = 0.5
            popularity_weight: float = 0.5
            min_similarity_threshold: float = 0.1
            vector_cache_size: int = 1000
            cache_ttl_seconds: int = 300
            action_weights: Dict[str, float] = None
            preference_weights: Dict[str, float] = None
            travel_style_bonuses: Dict[str, Dict[str, float]] = None
            def __post_init__(self):
                if self.action_weights is None:
                    self.action_weights = {'click': 1.0, 'like': 3.0, 'bookmark': 5.0}
                if self.preference_weights is None:
                    self.preference_weights = {'region': 0.4, 'category': 0.3, 'tag': 0.3, 'max_tag_score': 10.0, 'popularity_normalizer': 1000.0}
                if self.travel_style_bonuses is None:
                    self.travel_style_bonuses = {'luxury': {'accommodation': 0.1, 'restaurants': 0.1}}
        CONFIG = FallbackConfig()
        CONFIG.__post_init__()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# ğŸ”§ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ============================================================================

def safe_cosine_similarity(X: np.ndarray, Y: np.ndarray) -> np.ndarray:
    """ì•ˆì „í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (0 ë²¡í„° ë° ì°¨ì› ë¶ˆì¼ì¹˜ ì²˜ë¦¬)"""
    try:
        # ì…ë ¥ ê²€ì¦
        if X.size == 0 or Y.size == 0:
            return np.array([])

        # ì°¨ì› ë§ì¶”ê¸°
        X = np.array(X, dtype=np.float32).reshape(1, -1)
        Y = np.array(Y, dtype=np.float32)

        if Y.ndim == 1:
            Y = Y.reshape(1, -1)

        # ì°¨ì› ì¼ì¹˜ í™•ì¸
        if X.shape[1] != Y.shape[1]:
            logger.warning(f"Vector dimension mismatch: X={X.shape[1]}, Y={Y.shape[1]}")
            return np.zeros(Y.shape[0])

        # ì •ê·œí™”
        X_norm = np.linalg.norm(X, axis=1, keepdims=True)
        Y_norm = np.linalg.norm(Y, axis=1, keepdims=True)

        # 0 ë²¡í„° ì²˜ë¦¬
        X_normalized = np.divide(X, X_norm, out=np.zeros_like(X), where=X_norm!=0)
        Y_normalized = np.divide(Y, Y_norm, out=np.zeros_like(Y), where=Y_norm!=0)

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = np.dot(X_normalized, Y_normalized.T).flatten()

        # NaN/Inf ê°’ ì²˜ë¦¬
        similarities = np.nan_to_num(similarities, nan=0.0, posinf=1.0, neginf=-1.0)

        return similarities

    except Exception as e:
        logger.error(f"âŒ Cosine similarity calculation failed: {e}")
        return np.zeros(Y.shape[0] if Y.ndim > 1 else 1)


def calculate_weighted_popularity_score(place_data: Dict[str, int]) -> float:
    """ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì¸ê¸°ë„ ì ìˆ˜ ê³„ì‚° (ê°œì„ ëœ ì •ê·œí™”)"""
    try:
        weighted_score = (
            place_data.get('total_clicks', 0) * CONFIG.action_weights['click'] +
            place_data.get('total_likes', 0) * CONFIG.action_weights['like'] +
            place_data.get('total_bookmarks', 0) * CONFIG.action_weights['bookmark']
        )

        # ë™ì  ì •ê·œí™” (ìƒìœ„ 1% ê¸°ì¤€ì  ì‚¬ìš©)
        reference_score = 100  # ê¸°ë³¸ ê¸°ì¤€ì , ì‹¤ì œë¡œëŠ” í†µê³„ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ê³„ì‚° ê°€ëŠ¥
        normalized_score = min((weighted_score / reference_score) * 100, 100)

        return round(normalized_score, 2)

    except Exception as e:
        logger.error(f"âŒ Popularity score calculation failed: {e}")
        return 0.0


def calculate_engagement_score(place_data: Dict[str, int]) -> float:
    """ì°¸ì—¬ë„ ì ìˆ˜ ê³„ì‚° (like/bookmark ë¹„ìœ¨ ê¸°ë°˜)"""
    try:
        total_interactions = (
            place_data.get('total_clicks', 0) +
            place_data.get('total_likes', 0) +
            place_data.get('total_bookmarks', 0)
        )

        if total_interactions == 0:
            return 0.0

        high_value_actions = place_data.get('total_likes', 0) + place_data.get('total_bookmarks', 0)
        engagement_ratio = high_value_actions / total_interactions

        # ì ˆëŒ€ê°’ ë³´ì • ì¶”ê°€
        min_threshold_bonus = min(high_value_actions * 2, 20)  # ìµœëŒ€ 20ì  ë³´ë„ˆìŠ¤
        final_score = min((engagement_ratio * 100) + min_threshold_bonus, 100)

        return round(final_score, 2)

    except Exception as e:
        logger.error(f"âŒ Engagement score calculation failed: {e}")
        return 0.0


def validate_vector_data(vector_data: Any) -> Optional[np.ndarray]:
    """ë²¡í„° ë°ì´í„° ê²€ì¦ ë° ë³€í™˜"""
    try:
        if vector_data is None:
            return None

        # JSON ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
        if isinstance(vector_data, str):
            vector_data = json.loads(vector_data)

        # numpy ë°°ì—´ë¡œ ë³€í™˜
        vector = np.array(vector_data, dtype=np.float32)

        # ì°¨ì› ë° ìœ íš¨ì„± ê²€ì‚¬
        if vector.size == 0:
            return None

        if np.isnan(vector).any() or np.isinf(vector).any():
            logger.warning("Vector contains NaN or Inf values")
            return None

        return vector

    except Exception as e:
        logger.error(f"âŒ Vector validation failed: {e}")
        return None


# ============================================================================
# ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤
# ============================================================================

class DatabaseManager:
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ì¿¼ë¦¬ ê´€ë¦¬"""

    def __init__(self, database_url: str):
        self.database_url = database_url
        self.pool = None
        self._initialized = False

    async def initialize(self):
        """Connection Pool ì´ˆê¸°í™”"""
        try:
            self.pool = await asyncpg.create_pool(
                self.database_url,
                min_size=CONFIG.min_pool_size,
                max_size=CONFIG.max_pool_size,
                command_timeout=CONFIG.db_timeout,
                server_settings={
                    'application_name': 'unified_recommendation_engine'
                }
            )
            self._initialized = True
            logger.info(f"âœ… Database pool initialized: {CONFIG.min_pool_size}-{CONFIG.max_pool_size} connections")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize database pool: {e}")
            raise

    async def close(self):
        """Connection Pool ì •ë¦¬"""
        if self.pool:
            await self.pool.close()
            logger.info("ğŸ”Œ Database pool closed")

    @asynccontextmanager
    async def get_connection(self):
        """ì•ˆì „í•œ DB ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        if not self._initialized or not self.pool:
            raise RuntimeError("Database pool not initialized. Call initialize() first.")

        connection = None
        try:
            connection = await self.pool.acquire()
            yield connection
        except Exception as e:
            logger.error(f"âŒ Database connection error: {e}")
            raise
        finally:
            if connection:
                await self.pool.release(connection)

    async def execute_query(self, query: str, *args) -> List[Dict]:
        """ì•ˆì „í•œ ì¿¼ë¦¬ ì‹¤í–‰"""
        async with self.get_connection() as conn:
            try:
                result = await conn.fetch(query, *args)
                return [dict(row) for row in result]
            except Exception as e:
                logger.error(f"âŒ Query execution failed: {query[:100]}... Error: {e}")
                raise

    async def execute_single_query(self, query: str, *args) -> Optional[Any]:
        """ë‹¨ì¼ ê°’ ì¿¼ë¦¬ ì‹¤í–‰"""
        async with self.get_connection() as conn:
            try:
                return await conn.fetchval(query, *args)
            except Exception as e:
                logger.error(f"âŒ Single query execution failed: {query[:100]}... Error: {e}")
                raise


# ============================================================================
# ğŸ¯ í†µí•© ì¶”ì²œ ì—”ì§„ (ì™„ì „ ê°œì„  ë²„ì „)
# ============================================================================

class UnifiedRecommendationEngine:
    """
    ì™„ì „íˆ ê°œì„ ëœ í†µí•© ì¶”ì²œ ì—”ì§„
    - Connection Pool ê´€ë¦¬
    - ë²¡í„° ìºì‹±
    - ì—ëŸ¬ ë³µêµ¬
    - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    """

    def __init__(self, database_url: Optional[str] = None):
        self.database_url = database_url or CONFIG.database_url
        self.db_manager = DatabaseManager(self.database_url)

        # ìºì‹± ì‹œìŠ¤í…œ
        self.vector_cache: Dict[str, Dict] = {}
        self.cache_timestamps: Dict[str, float] = {}

        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            'total_requests': 0,
            'cache_hits': 0,
            'personalized_requests': 0,
            'popular_requests': 0,
            'avg_response_time': 0.0
        }

        logger.info("ğŸš€ UnifiedRecommendationEngine v2.0 initialized")

    async def initialize(self):
        """ì—”ì§„ ì´ˆê¸°í™” (ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ í˜¸ì¶œ)"""
        await self.db_manager.initialize()
        logger.info("âœ… Recommendation engine fully initialized")

    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        await self.db_manager.close()
        self.vector_cache.clear()
        self.cache_timestamps.clear()
        logger.info("ğŸ”Œ Recommendation engine closed")

    def _is_cache_valid(self, cache_key: str) -> bool:
        """ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬"""
        if cache_key not in self.cache_timestamps:
            return False

        age = time.time() - self.cache_timestamps[cache_key]
        return age < CONFIG.cache_ttl_seconds

    def _update_cache(self, cache_key: str, data: Any):
        """ìºì‹œ ì—…ë°ì´íŠ¸"""
        if len(self.vector_cache) >= CONFIG.vector_cache_size:
            # LRU ë°©ì‹ìœ¼ë¡œ ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key = min(self.cache_timestamps.keys(),
                           key=lambda k: self.cache_timestamps[k])
            del self.vector_cache[oldest_key]
            del self.cache_timestamps[oldest_key]

        self.vector_cache[cache_key] = data
        self.cache_timestamps[cache_key] = time.time()

    async def get_recommendations(
        self,
        user_id: Optional[str],
        region: Optional[str] = None,
        category: Optional[str] = None,
        limit: int = 20
    ) -> List[Dict]:
        """
        ë©”ì¸ ì¶”ì²œ API (ì™„ì „ ê°œì„  ë²„ì „)
        """
        start_time = time.time()
        self.stats['total_requests'] += 1

        try:
            # íŒŒë¼ë¯¸í„° ê²€ì¦
            limit = max(1, min(limit, 100))  # 1-100 ì‚¬ì´ë¡œ ì œí•œ

            user_vector = None
            if user_id:
                user_vector = await self._get_user_behavior_vector_cached(user_id)
                logger.info(f"DEBUG: User {user_id} vector status: {user_vector is not None}")
                if user_vector is not None:
                    logger.info(f"DEBUG: User vector shape: {user_vector.shape if hasattr(user_vector, 'shape') else 'no shape'}")

            if user_vector is not None:
                logger.info(f"ğŸ¯ Personalized recommendations for user {user_id}")
                self.stats['personalized_requests'] += 1

                # ë¶ë§ˆí¬ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„ ì¶”ê°€ ë°˜ì˜
                bookmark_preferences = await self._get_user_bookmark_preferences(user_id)

                result = await self._get_enhanced_vector_recommendations(
                    user_vector, bookmark_preferences, region, category, limit
                )
            else:
                # ì‹ ê·œ ê°€ì…ìë¥¼ ìœ„í•œ ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ì²œ ì‹œë„
                if user_id:
                    preferences_result = await self._get_preference_based_recommendations(
                        user_id, region, category, limit
                    )
                    if preferences_result:
                        logger.info(f"ğŸŒ± Preference-based recommendations for new user {user_id}")
                        self.stats['preference_requests'] = self.stats.get('preference_requests', 0) + 1
                        result = preferences_result
                    else:
                        logger.info(f"ğŸ“Š Popular recommendations for user {user_id} (no preferences found)")
                        self.stats['popular_requests'] += 1
                        result = await self._get_popular_recommendations(
                            region, category, limit
                        )
                else:
                    logger.info(f"ğŸ“Š Popular recommendations (anonymous user)")
                    self.stats['popular_requests'] += 1
                    result = await self._get_popular_recommendations(
                        region, category, limit
                    )

            # ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
            response_time = time.time() - start_time
            self._update_response_time(response_time)

            logger.info(f"âœ… Returned {len(result)} recommendations in {response_time:.3f}s")
            return result

        except Exception as e:
            logger.error(f"âŒ Recommendation failed: {e}")
            # ë¹ˆ ê²°ê³¼ë¼ë„ ì•ˆì „í•˜ê²Œ ë°˜í™˜
            return []

    async def _get_user_behavior_vector_cached(self, user_id: str) -> Optional[np.ndarray]:
        """ìºì‹œë¥¼ í™œìš©í•œ ì‚¬ìš©ì ë²¡í„° ì¡°íšŒ"""
        cache_key = f"user_vector:{user_id}"

        # ìºì‹œ í™•ì¸
        if self._is_cache_valid(cache_key):
            self.stats['cache_hits'] += 1
            cached_data = self.vector_cache[cache_key]
            if cached_data is not None:
                return np.array(cached_data, dtype=np.float32)
            return None

        # DBì—ì„œ ì¡°íšŒ
        try:
            query = """
                SELECT behavior_vector
                FROM user_behavior_vectors
                WHERE user_id = $1 AND behavior_vector IS NOT NULL
            """
            vector_data = await self.db_manager.execute_single_query(query, user_id)
            logger.info(f"DEBUG: User {user_id} raw vector data from DB: {vector_data is not None}")

            validated_vector = validate_vector_data(vector_data)
            logger.info(f"DEBUG: User {user_id} validated vector: {validated_vector is not None}")

            # ìºì‹œì— ì €ì¥ (Noneë„ ìºì‹œí•˜ì—¬ ë°˜ë³µ ì¿¼ë¦¬ ë°©ì§€)
            if validated_vector is not None:
                self._update_cache(cache_key, validated_vector.tolist())
                return validated_vector
            else:
                self._update_cache(cache_key, None)
                return None

        except Exception as e:
            logger.error(f"âŒ Failed to get user vector for {user_id}: {e}")
            return None

    async def _get_user_bookmark_preferences(self, user_id: str) -> Dict[str, float]:
        """ì‚¬ìš©ì ë¶ë§ˆí¬ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„ ê³„ì‚°"""
        try:
            query = """
                SELECT places
                FROM saved_locations
                WHERE user_id = $1
            """

            bookmarks = await self.db_manager.execute_query(query, user_id)

            if not bookmarks:
                return {}

            # ì¹´í…Œê³ ë¦¬ë³„ ë¶ë§ˆí¬ ìˆ˜ ê³„ì‚°
            category_counts = {}
            total_bookmarks = 0

            for bookmark in bookmarks:
                places_text = bookmark.get('places', '')
                if ':' in places_text:
                    table_name = places_text.split(':', 1)[0]
                    category_counts[table_name] = category_counts.get(table_name, 0) + 1
                    total_bookmarks += 1

            # ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° (ë¹„ìœ¨ ê¸°ë°˜)
            preferences = {}
            for category, count in category_counts.items():
                preferences[category] = count / total_bookmarks if total_bookmarks > 0 else 0

            logger.info(f"ğŸ“Š User {user_id} bookmark preferences: {preferences}")
            return preferences

        except Exception as e:
            logger.error(f"âŒ Failed to get bookmark preferences for {user_id}: {e}")
            return {}

    def _apply_category_quotas(
        self,
        recommendations: List[Dict],
        bookmark_preferences: Dict[str, float],
        limit: int
    ) -> List[Dict]:
        """ë¶ë§ˆí¬ ì„ í˜¸ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë³„ í• ë‹¹ëŸ‰ì„ ì ìš©í•œ ê· í˜•ì¡íŒ ì¶”ì²œ"""
        try:
            if not bookmark_preferences or not recommendations:
                return recommendations[:limit]

            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¶”ì²œ ë¶„ë¥˜
            category_recommendations = {}
            for rec in recommendations:
                category = rec.get('table_name', 'unknown')
                if category not in category_recommendations:
                    category_recommendations[category] = []
                category_recommendations[category].append(rec)

            # ì„ í˜¸ë„ ê¸°ë°˜ í• ë‹¹ëŸ‰ ê³„ì‚°
            result = []
            remaining_slots = limit

            # ë‹¤ì–‘ì„± ë³´ì¥: ìµœì†Œ 3ê°œ ì¹´í…Œê³ ë¦¬ëŠ” ë°˜ë“œì‹œ í¬í•¨
            min_categories = min(3, len(category_recommendations))
            max_per_category = max(1, limit // min_categories)

            # 1ë‹¨ê³„: ì£¼ìš” ì„ í˜¸ ì¹´í…Œê³ ë¦¬ë¶€í„° í• ë‹¹
            sorted_preferences = sorted(bookmark_preferences.items(), key=lambda x: x[1], reverse=True)

            for category, preference_rate in sorted_preferences:
                if category not in category_recommendations:
                    continue

                # ë” ê· í˜•ì¡íŒ í• ë‹¹ëŸ‰ ì‹œìŠ¤í…œ (ë‹¤ì–‘ì„± ê°•í™”)
                if preference_rate > 0.7:  # 70% ì´ìƒ ë§¤ìš° ê°•í•œ ì„ í˜¸
                    quota = min(max(int(limit * 0.35), 3), max_per_category + 2)  # 35% ë˜ëŠ” ê¸°ë³¸+2
                elif preference_rate > 0.4:  # 40% ì´ìƒ ì„ í˜¸ ì¹´í…Œê³ ë¦¬
                    quota = min(max(int(limit * 0.25), 2), max_per_category + 1)  # 25% ë˜ëŠ” ê¸°ë³¸+1
                elif preference_rate > 0.2:  # 20% ì´ìƒ ì„ í˜¸ ì¹´í…Œê³ ë¦¬
                    quota = min(max(int(limit * 0.15), 1), max_per_category)  # 15% ë˜ëŠ” ê¸°ë³¸
                elif preference_rate > 0.05:  # 5% ì´ìƒ ì„ í˜¸ ì¹´í…Œê³ ë¦¬
                    quota = min(2, max_per_category)  # ìµœëŒ€ 2ê°œ ë˜ëŠ” ê¸°ë³¸
                else:  # ë‚˜ë¨¸ì§€ ì¹´í…Œê³ ë¦¬
                    quota = 1

                # ì‹¤ì œ í• ë‹¹ ê°€ëŠ¥í•œ ìˆ˜ë§Œí¼ ì¶”ê°€
                available = min(quota, len(category_recommendations[category]), remaining_slots)
                result.extend(category_recommendations[category][:available])
                remaining_slots -= available

                logger.info(f"ğŸ“Š {category}: {preference_rate:.3f} -> {available}ê°œ í• ë‹¹")

                if remaining_slots <= 0:
                    break

            # 2ë‹¨ê³„: ë‚¨ì€ ìŠ¬ë¡¯ì„ ì ìˆ˜ìˆœìœ¼ë¡œ ì±„ì›€
            if remaining_slots > 0:
                used_ids = {rec.get('place_id') for rec in result}
                remaining_recs = [rec for rec in recommendations if rec.get('place_id') not in used_ids]
                result.extend(remaining_recs[:remaining_slots])

            return result[:limit]

        except Exception as e:
            logger.error(f"âŒ Category quota application failed: {e}")
            return recommendations[:limit]

    def _apply_category_shuffling(self, recommendations: List[Dict]) -> List[Dict]:
        """ì¹´í…Œê³ ë¦¬ê°€ ì ì ˆíˆ ì„ì´ë„ë¡ ì¸í„°ë¦¬ë¹™ ë°©ì‹ìœ¼ë¡œ ì¬ë°°ì¹˜"""
        try:
            if len(recommendations) <= 3:
                return recommendations

            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
            category_groups = {}
            for rec in recommendations:
                category = rec.get('table_name', 'unknown')
                if category not in category_groups:
                    category_groups[category] = []
                category_groups[category].append(rec)

            # ì¹´í…Œê³ ë¦¬ê°€ 2ê°œ ì´í•˜ë©´ ì…”í”Œë§ ë¶ˆí•„ìš”
            if len(category_groups) <= 2:
                return recommendations

            logger.info(f"ğŸ”„ Shuffling {len(category_groups)} categories for better distribution")

            # ì¸í„°ë¦¬ë¹™ ë°©ì‹ìœ¼ë¡œ ì¬ë°°ì¹˜
            result = []
            category_indices = {cat: 0 for cat in category_groups.keys()}
            categories = list(category_groups.keys())

            # ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë¥¼ ìˆœí™˜í•˜ë©° ë°°ì¹˜
            for position in range(len(recommendations)):
                # í˜„ì¬ ë¼ìš´ë“œì—ì„œ ì‚¬ìš©í•  ì¹´í…Œê³ ë¦¬ ì„ íƒ
                category_idx = position % len(categories)
                current_category = categories[category_idx]

                # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ì•„ì§ ë°°ì¹˜ë˜ì§€ ì•Šì€ ì•„ì´í…œì´ ìˆëŠ”ì§€ í™•ì¸
                attempts = 0
                while attempts < len(categories):
                    cat_idx = category_indices[current_category]
                    if cat_idx < len(category_groups[current_category]):
                        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ì•„ì´í…œ ì¶”ê°€
                        result.append(category_groups[current_category][cat_idx])
                        category_indices[current_category] += 1
                        break
                    else:
                        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ê°€ ì†Œì§„ë˜ë©´ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ
                        category_idx = (category_idx + 1) % len(categories)
                        current_category = categories[category_idx]
                        attempts += 1

                # ëª¨ë“  ì¹´í…Œê³ ë¦¬ê°€ ì†Œì§„ë˜ë©´ ì¢…ë£Œ
                if attempts >= len(categories):
                    break

            # í˜¹ì‹œ ë‚¨ì€ ì•„ì´í…œë“¤ ì¶”ê°€
            for category, items in category_groups.items():
                start_idx = category_indices[category]
                result.extend(items[start_idx:])

            logger.info(f"âœ… Category shuffling completed: {len(result)} items redistributed")
            return result[:len(recommendations)]

        except Exception as e:
            logger.error(f"âŒ Category shuffling failed: {e}")
            return recommendations

    async def _get_place_candidates(
        self,
        region: Optional[str],
        category: Optional[str]
    ) -> List[Dict]:
        """ì¶”ì²œ í›„ë³´ ì¥ì†Œ ì¡°íšŒ (ìµœì í™”ëœ ì¿¼ë¦¬)"""
        try:
            # place_vectorsì™€ place_recommendationsì˜ ë°ì´í„° íƒ€ì…ì´ ë‹¤ë¥´ë¯€ë¡œ
            # place_recommendationsë§Œ ì‚¬ìš©í•˜ê³  ë²¡í„°ëŠ” ë³„ë„ ì²˜ë¦¬
            query = """
                SELECT
                    pr.place_id::text as place_id,
                    pr.table_name,
                    pr.vector as vector,
                    COALESCE(pr.bookmark_cnt, 0) as total_likes,
                    COALESCE(pr.bookmark_cnt, 0) as total_bookmarks,
                    COALESCE(pr.bookmark_cnt, 0) as total_clicks,
                    1 as unique_users,
                    COALESCE(pr.bookmark_cnt, 0)::float as popularity_score,
                    COALESCE(pr.bookmark_cnt, 0)::float as engagement_score,
                    pr.name,
                    pr.region,
                    pr.city,
                    pr.latitude,
                    pr.longitude,
                    pr.overview as description,
                    pr.image_urls,
                    pr.bookmark_cnt
                FROM place_recommendations pr
                WHERE
                    pr.vector IS NOT NULL
                    AND pr.name IS NOT NULL
                    AND pr.bookmark_cnt IS NOT NULL
            """

            params = []
            param_count = 0

            # ì§€ì—­ í•„í„°
            if region:
                param_count += 1
                query += f" AND pr.region = ${param_count}"
                params.append(region)

            # ì¹´í…Œê³ ë¦¬ í•„í„°
            if category:
                param_count += 1
                query += f" AND pr.table_name = ${param_count}::text"
                params.append(category)

            # ì„±ëŠ¥ì„ ìœ„í•œ ì œí•œ ë° ì •ë ¬ (ë¶ë§ˆí¬ ì¹´ìš´íŠ¸ ê¸°ì¤€)
            query += " ORDER BY COALESCE(pr.bookmark_cnt, 0) DESC"
            param_count += 1
            query += f" LIMIT ${param_count}"
            params.append(CONFIG.candidate_limit)

            places = await self.db_manager.execute_query(query, *params)

            # ë²¡í„° ë°ì´í„° ê²€ì¦
            valid_places = []
            for place in places:
                if validate_vector_data(place['vector']) is not None:
                    valid_places.append(place)

            logger.info(f"ğŸ“‹ Retrieved {len(valid_places)} valid place candidates")
            return valid_places

        except Exception as e:
            logger.error(f"âŒ Failed to get place candidates: {e}")
            return []

    async def _get_popular_recommendations(
        self,
        region: Optional[str],
        category: Optional[str],
        limit: int
    ) -> List[Dict]:
        """ì¸ê¸° ê¸°ë°˜ ì¶”ì²œ (ë‹¨ìˆœ ë¶ë§ˆí¬ ì¹´ìš´íŠ¸ ì •ë ¬)"""
        places = await self._get_place_candidates(region, category)

        if not places:
            return []

        # ë‹¨ìˆœ ë¶ë§ˆí¬ ì¹´ìš´íŠ¸ ê¸°ë°˜ ì •ë ¬
        for place in places:
            try:
                bookmark_count = place.get('bookmark_cnt', 0)

                place['final_score'] = bookmark_count
                place['recommendation_type'] = 'popular'
                place['similarity_score'] = 0.8  # ì¸ê¸° ì¶”ì²œìš© ê¸°ë³¸ê°’

            except Exception as e:
                logger.error(f"âŒ Popular score calculation failed for place {place.get('place_id')}: {e}")
                place['final_score'] = 0

        # ë¶ë§ˆí¬ ì¹´ìš´íŠ¸ìˆœ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
        places.sort(key=lambda x: x.get('bookmark_cnt', 0), reverse=True)
        return places[:limit]

    async def _get_enhanced_vector_recommendations(
        self,
        user_vector: np.ndarray,
        bookmark_preferences: Dict[str, float],
        region: Optional[str],
        category: Optional[str],
        limit: int
    ) -> List[Dict]:
        """ë¶ë§ˆí¬ ì„ í˜¸ë„ë¥¼ ë°˜ì˜í•œ ê°œì„ ëœ ë²¡í„° ê¸°ë°˜ ì¶”ì²œ"""
        places = await self._get_place_candidates(region, category)

        if not places:
            return []

        try:
            # ë²¡í„° ë°°ì¹˜ ì²˜ë¦¬
            place_vectors = []
            valid_places = []

            for place in places:
                vector = validate_vector_data(place['vector'])
                if vector is not None:
                    place_vectors.append(vector)
                    valid_places.append(place)

            if not valid_places:
                logger.warning("âš ï¸ No valid place vectors found, falling back to popular")
                return await self._get_popular_recommendations(region, category, limit)

            # ë²¡í„°í™”ëœ ìœ ì‚¬ë„ ê³„ì‚°
            place_vectors_array = np.array(place_vectors, dtype=np.float32)
            similarities = safe_cosine_similarity(user_vector, place_vectors_array)

            # ë¶ë§ˆí¬ ì„ í˜¸ë„ ê°•í™”ëœ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
            results = []
            for i, place in enumerate(valid_places):
                try:
                    similarity = float(similarities[i])

                    # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš©
                    if similarity < CONFIG.min_similarity_threshold:
                        continue

                    # ê¸°ë³¸ ì¸ê¸°ë„ ì ìˆ˜
                    place_data = {
                        'total_clicks': place.get('total_clicks', 0),
                        'total_likes': place.get('total_likes', 0),
                        'total_bookmarks': place.get('total_bookmarks', 0)
                    }
                    popularity_score = calculate_weighted_popularity_score(place_data)
                    engagement_score = calculate_engagement_score(place_data)

                    # ğŸ”¥ ë¶ë§ˆí¬ ì„ í˜¸ë„ ë³´ë„ˆìŠ¤ ì¶”ê°€ (ì ì ˆí•œ ê°•í™”)
                    category_preference = bookmark_preferences.get(place['table_name'], 0)
                    bookmark_bonus = category_preference * 0.5  # ìµœëŒ€ 50% ë³´ë„ˆìŠ¤ (ê· í˜•ì¡íŒ ì¡°ì •)

                    # ê°œì„ ëœ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜
                    hybrid_score = (
                        similarity * CONFIG.similarity_weight +
                        (popularity_score / 100.0) * CONFIG.popularity_weight * 0.7 +
                        (engagement_score / 100.0) * CONFIG.popularity_weight * 0.3 +
                        bookmark_bonus  # ë¶ë§ˆí¬ ì„ í˜¸ë„ ë³´ë„ˆìŠ¤
                    )

                    place['similarity_score'] = round(similarity, 4)
                    place['popularity_score'] = popularity_score
                    place['engagement_score'] = engagement_score
                    place['bookmark_bonus'] = round(bookmark_bonus, 4)
                    place['final_score'] = round(hybrid_score, 4)
                    place['recommendation_type'] = 'personalized_enhanced'

                    results.append(place)

                except Exception as e:
                    logger.error(f"âŒ Score calculation failed for place {i}: {e}")
                    continue

            # ì ìˆ˜ìˆœ ì •ë ¬
            results.sort(key=lambda x: x['final_score'], reverse=True)

            # ë””ë²„ê¹…ì„ ìœ„í•œ ì¹´í…Œê³ ë¦¬ ë¶„ì„
            category_counts = {}
            for rec in results[:20]:  # ìƒìœ„ 20ê°œ ë¶„ì„
                cat = rec.get('table_name', 'unknown')
                category_counts[cat] = category_counts.get(cat, 0) + 1
            logger.info(f"ğŸ” Top 20 categories before balancing: {category_counts}")
            logger.info(f"ğŸ“Š Bookmark preferences: {bookmark_preferences}")

            # ğŸ¯ ì¹´í…Œê³ ë¦¬ë³„ ë³´ì¥ ì¶”ì²œ ì‹œìŠ¤í…œ ì ìš©
            balanced_results = self._apply_category_quotas(results, bookmark_preferences, limit)

            # ê· í˜• ì¡°ì • í›„ ì¹´í…Œê³ ë¦¬ ë¶„ì„
            balanced_counts = {}
            for rec in balanced_results:
                cat = rec.get('table_name', 'unknown')
                balanced_counts[cat] = balanced_counts.get(cat, 0) + 1
            logger.info(f"ğŸ¯ Categories after quota balancing: {balanced_counts}")

            # ğŸ”„ ì¹´í…Œê³ ë¦¬ ë¶„ì‚°ì„ ìœ„í•œ ì…”í”Œë§ ì ìš©
            final_results = self._apply_category_shuffling(balanced_results)

            # ìµœì¢… ê²°ê³¼ ë¶„ì„
            final_counts = {}
            final_sequence = []
            for i, rec in enumerate(final_results[:10]):  # ìƒìœ„ 10ê°œ ìˆœì„œ í™•ì¸
                cat = rec.get('table_name', 'unknown')
                name = rec.get('name', 'unknown')[:10]  # ì´ë¦„ ì• 10ê¸€ìë§Œ
                final_counts[cat] = final_counts.get(cat, 0) + 1
                final_sequence.append(f"{i+1}.{cat}({name})")

            logger.info(f"âœ… Final categories: {final_counts}")
            logger.info(f"ğŸ”„ Final sequence: {', '.join(final_sequence)}")

            return final_results

        except Exception as e:
            logger.error(f"âŒ Enhanced vector-based recommendation failed: {e}")
            # Fallback to popular recommendations
            return await self._get_popular_recommendations(region, category, limit)

    async def _get_vector_based_recommendations(
        self,
        user_vector: np.ndarray,
        region: Optional[str],
        category: Optional[str],
        limit: int
    ) -> List[Dict]:
        """ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ê°œì¸í™” ì¶”ì²œ (ìµœì í™”ëœ ë²„ì „)"""
        places = await self._get_place_candidates(region, category)

        if not places:
            return []

        try:
            # ë²¡í„° ë°°ì¹˜ ì²˜ë¦¬
            place_vectors = []
            valid_places = []

            for place in places:
                vector = validate_vector_data(place['vector'])
                if vector is not None:
                    place_vectors.append(vector)
                    valid_places.append(place)

            if not valid_places:
                logger.warning("âš ï¸ No valid place vectors found, falling back to popular")
                return await self._get_popular_recommendations(region, category, limit)

            # ë²¡í„°í™”ëœ ìœ ì‚¬ë„ ê³„ì‚°
            place_vectors_array = np.array(place_vectors, dtype=np.float32)
            similarities = safe_cosine_similarity(user_vector, place_vectors_array)

            # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
            results = []
            for i, place in enumerate(valid_places):
                try:
                    similarity = float(similarities[i])

                    # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš©
                    if similarity < CONFIG.min_similarity_threshold:
                        continue

                    # ì¸ê¸°ë„ ì ìˆ˜ ê³„ì‚°
                    place_data = {
                        'total_clicks': place.get('total_clicks', 0),
                        'total_likes': place.get('total_likes', 0),
                        'total_bookmarks': place.get('total_bookmarks', 0)
                    }
                    popularity_score = calculate_weighted_popularity_score(place_data)
                    engagement_score = calculate_engagement_score(place_data)

                    # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ (ê°œì¸í™” + ì¸ê¸°ë„ + ì°¸ì—¬ë„)
                    hybrid_score = (
                        similarity * CONFIG.similarity_weight +
                        (popularity_score / 100.0) * CONFIG.popularity_weight * 0.7 +
                        (engagement_score / 100.0) * CONFIG.popularity_weight * 0.3
                    )

                    place['similarity_score'] = round(similarity, 4)
                    place['popularity_score'] = popularity_score
                    place['engagement_score'] = engagement_score
                    place['final_score'] = round(hybrid_score, 4)
                    place['recommendation_type'] = 'personalized'

                    results.append(place)

                except Exception as e:
                    logger.error(f"âŒ Score calculation failed for place {i}: {e}")
                    continue

            # ì ìˆ˜ìˆœ ì •ë ¬
            results.sort(key=lambda x: x['final_score'], reverse=True)

            logger.info(f"ğŸ¯ Generated {len(results)} personalized recommendations")
            return results[:limit]

        except Exception as e:
            logger.error(f"âŒ Vector-based recommendation failed: {e}")
            # Fallback to popular recommendations
            return await self._get_popular_recommendations(region, category, limit)

    def _update_response_time(self, response_time: float):
        """ì‘ë‹µ ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸ (ì´ë™í‰ê· )"""
        alpha = 0.1  # ì´ë™í‰ê·  ê°€ì¤‘ì¹˜
        if self.stats['avg_response_time'] == 0.0:
            self.stats['avg_response_time'] = response_time
        else:
            self.stats['avg_response_time'] = (
                alpha * response_time +
                (1 - alpha) * self.stats['avg_response_time']
            )

    def get_stats(self) -> Dict:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        cache_hit_rate = (
            self.stats['cache_hits'] / max(self.stats['total_requests'], 1)
        ) * 100

        return {
            **self.stats,
            'cache_hit_rate': round(cache_hit_rate, 2),
            'cache_size': len(self.vector_cache),
            'personalization_rate': round(
                (self.stats['personalized_requests'] / max(self.stats['total_requests'], 1)) * 100, 2
            )
        }

    async def get_popular_regions_and_categories(self) -> Dict[str, List[str]]:
        """ì¸ê¸°ë„ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ì§€ì—­/ì¹´í…Œê³ ë¦¬ ìˆœì„œ ê²°ì •"""
        try:
            # ì§€ì—­ë³„ ë¶ë§ˆí¬ ì´í•© ì¡°íšŒ
            region_query = """
                SELECT region, SUM(COALESCE(bookmark_cnt, 0)) as total_bookmarks
                FROM place_recommendations
                WHERE region IS NOT NULL
                GROUP BY region
                ORDER BY total_bookmarks DESC
                LIMIT 10
            """

            # ì¹´í…Œê³ ë¦¬ë³„ ë¶ë§ˆí¬ ì´í•© ì¡°íšŒ
            category_query = """
                SELECT table_name as category, SUM(COALESCE(bookmark_cnt, 0)) as total_bookmarks
                FROM place_recommendations
                WHERE table_name IS NOT NULL
                GROUP BY table_name
                ORDER BY total_bookmarks DESC
                LIMIT 10
            """

            regions_data = await self.db_manager.execute_query(region_query)
            categories_data = await self.db_manager.execute_query(category_query)

            regions = [row['region'] for row in regions_data if row['region']]
            categories = [row['category'] for row in categories_data if row['category']]

            logger.info(f"ğŸ“Š Dynamic ordering: {len(regions)} regions, {len(categories)} categories")

            return {
                'regions': regions,
                'categories': categories
            }

        except Exception as e:
            logger.error(f"âŒ Failed to get dynamic regions/categories: {e}")
            # Fallback to config defaults
            return {
                'regions': CONFIG.explore_regions or [],
                'categories': CONFIG.explore_categories or []
            }

    async def health_check(self) -> Dict[str, Any]:
        """ì—”ì§„ í—¬ìŠ¤ì²´í¬"""
        try:
            # ê°„ë‹¨í•œ DB ì—°ê²° í…ŒìŠ¤íŠ¸
            test_result = await self.db_manager.execute_single_query("SELECT 1")
            db_healthy = test_result == 1

            # ìºì‹œ ìƒíƒœ í™•ì¸
            cache_healthy = len(self.vector_cache) < CONFIG.vector_cache_size

            # ì „ì²´ ìƒíƒœ íŒë‹¨
            overall_healthy = db_healthy and cache_healthy

            return {
                'status': 'healthy' if overall_healthy else 'degraded',
                'database': 'connected' if db_healthy else 'disconnected',
                'cache': 'normal' if cache_healthy else 'full',
                'stats': self.get_stats(),
                'config': {
                    'candidate_limit': CONFIG.candidate_limit,
                    'similarity_weight': CONFIG.similarity_weight,
                    'popularity_weight': CONFIG.popularity_weight
                }
            }

        except Exception as e:
            logger.error(f"âŒ Health check failed: {e}")
            return {
                'status': 'unhealthy',
                'error': str(e),
                'stats': self.get_stats()
            }

    async def _get_preference_based_recommendations(
        self,
        user_id: str,
        region: Optional[str] = None,
        category: Optional[str] = None,
        limit: int = 20
    ) -> List[Dict]:
        """
        ì‹ ê·œ ê°€ì…ìë¥¼ ìœ„í•œ ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ì²œ
        user_preferencesì™€ user_preference_tags í…Œì´ë¸”ì„ í™œìš©í•œ ì—¬í–‰ ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ì²œ
        """
        try:
            # 1. ì‚¬ìš©ì ì„ í˜¸ë„ ì •ë³´ ì¡°íšŒ
            user_preferences = await self._get_user_preferences(user_id)
            if not user_preferences:
                logger.info(f"No preferences found for user {user_id}")
                return []

            # 2. ì„ í˜¸ë„ ê¸°ë°˜ ì¥ì†Œ í•„í„°ë§ ë° ì ìˆ˜ ê³„ì‚°
            recommendations = await self._calculate_preference_scores(
                user_preferences, region, category, limit
            )

            logger.info(f"âœ… Generated {len(recommendations)} preference-based recommendations for user {user_id}")
            return recommendations

        except Exception as e:
            logger.error(f"âŒ Preference-based recommendation failed for user {user_id}: {e}")
            return []

    async def _get_user_preferences(self, user_id: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì„ í˜¸ë„ ì •ë³´ ì¡°íšŒ (users í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¡°íšŒ)"""
        try:
            # users í…Œì´ë¸”ì—ì„œ ì„ í˜¸ë„ ì •ë³´ ì¡°íšŒ (ì‹¤ì œ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ìˆ˜ì •)
            preferences_query = """
                SELECT
                    priority,
                    accommodation,
                    exploration,
                    persona
                FROM users
                WHERE user_id = $1
            """

            # user_preference_tags í…Œì´ë¸”ì—ì„œ íƒœê·¸ ì •ë³´ ì¡°íšŒ (í˜„ì¬ ìŠ¤í‚¤ë§ˆ)
            tags_query = """
                SELECT
                    tag,
                    weight
                FROM user_preference_tags
                WHERE user_id = $1
                ORDER BY weight DESC
            """

            # ë³‘ë ¬ë¡œ ë‘ ì¿¼ë¦¬ ì‹¤í–‰
            async with self.db_manager.get_connection() as conn:
                preferences_data = await conn.fetchrow(preferences_query, user_id)
                tags_data = await conn.fetch(tags_query, user_id)

            if not preferences_data and not tags_data:
                return {}

            # ê²°ê³¼ êµ¬ì„± (í˜„ì¬ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ)
            result = {
                'priority': preferences_data.get('priority') if preferences_data else None,
                'accommodation': preferences_data.get('accommodation') if preferences_data else None,
                'exploration': preferences_data.get('exploration') if preferences_data else None,
                'persona': preferences_data.get('persona') if preferences_data else None,
                'preference_tags': {
                    row['tag']: row['weight']
                    for row in tags_data
                }
            }

            return result

        except Exception as e:
            logger.error(f"âŒ Failed to get user preferences for {user_id}: {e}")
            return {}

    async def _calculate_preference_scores(
        self,
        user_preferences: Dict[str, Any],
        region: Optional[str] = None,
        category: Optional[str] = None,
        limit: int = 20
    ) -> List[Dict]:
        """ì„ í˜¸ë„ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° ë° ì¶”ì²œ ìƒì„±"""
        try:
            # ì¥ì†Œ í›„ë³´êµ° ì¡°íšŒ
            places_query = """
                SELECT
                    place_id, table_name, region, name,
                    latitude, longitude, overview, image_urls, bookmark_cnt,
                    COALESCE(bookmark_cnt, 0) as popularity_score
                FROM place_recommendations
                WHERE name IS NOT NULL
                    AND ($1::text IS NULL OR region = $1)
                    AND ($2::text IS NULL OR table_name = $2)
                ORDER BY bookmark_cnt DESC
                LIMIT $3
            """

            async with self.db_manager.get_connection() as conn:
                places_data = await conn.fetch(
                    places_query,
                    region,
                    category,
                    CONFIG.candidate_limit
                )

            if not places_data:
                return []

            # ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
            scored_places = []
            popularity_normalizer = CONFIG.preference_weights['popularity_normalizer']

            for place in places_data:
                preference_score = self._calculate_place_preference_score(place, user_preferences)

                if preference_score > 0:
                    place_dict = dict(place)
                    popularity_normalized = min(place['popularity_score'] / popularity_normalizer, 1.0)
                    final_score = (preference_score * CONFIG.similarity_weight) + (popularity_normalized * CONFIG.popularity_weight)

                    place_dict['preference_score'] = preference_score
                    place_dict['final_score'] = final_score
                    scored_places.append(place_dict)

            scored_places.sort(key=lambda x: x['final_score'], reverse=True)
            return scored_places[:limit]

        except Exception as e:
            logger.error(f"âŒ Failed to calculate preference scores: {e}")
            return []

    def _calculate_place_preference_score(
        self,
        place: Dict[str, Any],
        user_preferences: Dict[str, Any]
    ) -> float:
        """ê°œë³„ ì¥ì†Œì— ëŒ€í•œ ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° (í˜„ì¬ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ìˆ˜ì •)"""
        score = 0.0

        try:
            weights = CONFIG.preference_weights

            # í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„
            persona = user_preferences.get('persona')
            if persona and place['table_name']:
                # í˜ë¥´ì†Œë‚˜ë³„ ì¹´í…Œê³ ë¦¬ ë³´ë„ˆìŠ¤
                persona_bonuses = {
                    'culture_lover': {'humanities': 0.3, 'culture': 0.3},
                    'nature_lover': {'nature': 0.3, 'leisure_sports': 0.2},
                    'foodie': {'restaurants': 0.4},
                    'shopper': {'shopping': 0.3},
                    'luxury_traveler': {'accommodation': 0.2, 'restaurants': 0.2}
                }

                if persona in persona_bonuses:
                    category_bonus = persona_bonuses[persona].get(place['table_name'], 0)
                    score += category_bonus

            # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì ìˆ˜
            priority = user_preferences.get('priority')
            if priority:
                # ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
                if priority == 'popular' and place.get('bookmark_cnt', 0) > 1000:
                    score += 0.2
                elif priority == 'unique' and place.get('bookmark_cnt', 0) < 500:
                    score += 0.2

            # íƒœê·¸ ë§¤ì¹­ (í˜„ì¬ ìŠ¤í‚¤ë§ˆ)
            preference_tags = user_preferences.get('preference_tags', {})
            if preference_tags:
                place_description = (place.get('description', '') or '').lower()
                place_name = (place.get('name', '') or '').lower()
                combined_text = place_description + ' ' + place_name

                tag_score, tag_count = 0.0, 0

                for tag_name, tag_weight in preference_tags.items():
                    tag_lower = tag_name.lower()
                    if tag_lower in combined_text:
                        # weightëŠ” 1-10 ìŠ¤ì¼€ì¼ë¡œ ê°€ì •, ì •ê·œí™”
                        normalized_weight = min(tag_weight / 10.0, 1.0)
                        tag_score += normalized_weight
                        tag_count += 1

                if tag_count > 0:
                    # íƒœê·¸ ì ìˆ˜ ì •ê·œí™”
                    normalized_tag_score = min(tag_score / tag_count, 1.0)
                    score += normalized_tag_score * weights['tag']

            # íƒí—˜ ì„±í–¥ ë°˜ì˜
            exploration = user_preferences.get('exploration')
            if exploration == 'adventurous' and place['table_name'] in ['nature', 'leisure_sports']:
                score += 0.1
            elif exploration == 'comfort' and place['table_name'] in ['accommodation', 'restaurants']:
                score += 0.1

            return min(score, 1.0)

        except Exception as e:
            logger.error(f"âŒ Failed to calculate preference score for place {place.get('place_id')}: {e}")
            return 0.0


# ============================================================================
# ğŸš€ ì „ì—­ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
# ============================================================================

_engine_instance: Optional[UnifiedRecommendationEngine] = None

async def get_engine() -> UnifiedRecommendationEngine:
    """ì „ì—­ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì§€ì—° ì´ˆê¸°í™”)"""
    global _engine_instance

    if _engine_instance is None:
        _engine_instance = UnifiedRecommendationEngine()
        await _engine_instance.initialize()

    return _engine_instance

async def close_engine():
    """ì „ì—­ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬"""
    global _engine_instance

    if _engine_instance:
        await _engine_instance.close()
        _engine_instance = None


