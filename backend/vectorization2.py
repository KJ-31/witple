# íŒŒì¼ëª…: vectorization2.py (ì™„ì „ ê°œì„  ë²„ì „)

import numpy as np
import asyncpg
import logging
from typing import Dict, List, Any, Optional
from contextlib import asynccontextmanager
from dataclasses import dataclass
import json
import time

# í†µí•© ì„¤ì • íŒŒì¼ ì‚¬ìš© (backend í™˜ê²½ ëŒ€ì‘)
try:
    from recommendation_config import config as CONFIG
except ImportError:
    try:
        from .recommendation_config import config as CONFIG
    except ImportError:
        # Fallback ì„¤ì •
        from dataclasses import dataclass
        @dataclass
        class FallbackConfig:
            database_url: str = "postgresql://user:pass@localhost/db"
            min_pool_size: int = 3
            max_pool_size: int = 15
            db_timeout: int = 5
            candidate_limit: int = 2000
            similarity_weight: float = 0.5
            popularity_weight: float = 0.5
            min_similarity_threshold: float = 0.1
            vector_cache_size: int = 1000
            cache_ttl_seconds: int = 300
            action_weights: Dict[str, float] = None
            preference_weights: Dict[str, float] = None
            travel_style_bonuses: Dict[str, Dict[str, float]] = None
            def __post_init__(self):
                if self.action_weights is None:
                    self.action_weights = {'click': 1.0, 'like': 3.0, 'bookmark': 5.0}
                if self.preference_weights is None:
                    self.preference_weights = {'region': 0.4, 'category': 0.3, 'tag': 0.3, 'max_tag_score': 10.0, 'popularity_normalizer': 1000.0}
                if self.travel_style_bonuses is None:
                    self.travel_style_bonuses = {'luxury': {'accommodation': 0.1, 'restaurants': 0.1}}
        CONFIG = FallbackConfig()
        CONFIG.__post_init__()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# ğŸ”§ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ============================================================================

def safe_cosine_similarity(X: np.ndarray, Y: np.ndarray) -> np.ndarray:
    """ì•ˆì „í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ëª¨ë“  ì—ì§€ ì¼€ì´ìŠ¤ ì²˜ë¦¬)"""
    try:
        # None ê°’ ê²€ì¦
        if X is None or Y is None:
            return np.array([0.0])

        # ì…ë ¥ì„ numpy ë°°ì—´ë¡œ ë³€í™˜
        X = np.asarray(X, dtype=np.float32)
        Y = np.asarray(Y, dtype=np.float32)

        # ë¹ˆ ë°°ì—´ ê²€ì¦
        if X.size == 0 or Y.size == 0:
            return np.array([0.0])

        # ì°¨ì› ë§ì¶”ê¸°
        X = X.reshape(1, -1)
        if Y.ndim == 1:
            Y = Y.reshape(1, -1)

        # ì°¨ì› ì¼ì¹˜ í™•ì¸
        if X.shape[1] != Y.shape[1]:
            logger.warning(f"Vector dimension mismatch: X={X.shape[1]}, Y={Y.shape[1]}")
            return np.zeros(Y.shape[0])

        # NaN/Inf ê°’ ì²˜ë¦¬
        X = np.nan_to_num(X, nan=0.0, posinf=1.0, neginf=-1.0)
        Y = np.nan_to_num(Y, nan=0.0, posinf=1.0, neginf=-1.0)

        # ì •ê·œí™” (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
        X_norm = np.linalg.norm(X, axis=1, keepdims=True)
        Y_norm = np.linalg.norm(Y, axis=1, keepdims=True)

        # 0 ë²¡í„° ì²˜ë¦¬
        if np.any(X_norm == 0) or np.any(Y_norm == 0):
            return np.zeros(Y.shape[0])

        X_normalized = X / X_norm
        Y_normalized = Y / Y_norm

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = np.dot(X_normalized, Y_normalized.T).flatten()

        # ìµœì¢… NaN/Inf ê°’ ì²˜ë¦¬
        similarities = np.nan_to_num(similarities, nan=0.0, posinf=1.0, neginf=-1.0)

        # ìœ ì‚¬ë„ ë²”ìœ„ í´ë¦¬í•‘ (-1 ~ 1)
        similarities = np.clip(similarities, -1.0, 1.0)

        return similarities

    except Exception as e:
        logger.error(f"âŒ Cosine similarity calculation failed: {e}")
        # ì•ˆì „í•œ ê¸°ë³¸ê°’ ë°˜í™˜
        try:
            return np.zeros(Y.shape[0] if hasattr(Y, 'shape') and Y.ndim > 1 else 1)
        except:
            return np.array([0.0])


def calculate_weighted_popularity_score(place_data: Dict[str, int]) -> float:
    """ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì¸ê¸°ë„ ì ìˆ˜ ê³„ì‚° (ê°œì„ ëœ ì •ê·œí™”)"""
    try:
        weighted_score = (
            place_data.get('total_clicks', 0) * CONFIG.action_weights['click'] +
            place_data.get('total_likes', 0) * CONFIG.action_weights['like'] +
            place_data.get('total_bookmarks', 0) * CONFIG.action_weights['bookmark']
        )

        # ë™ì  ì •ê·œí™” (ìƒìœ„ 1% ê¸°ì¤€ì  ì‚¬ìš©)
        reference_score = 100  # ê¸°ë³¸ ê¸°ì¤€ì , ì‹¤ì œë¡œëŠ” í†µê³„ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ê³„ì‚° ê°€ëŠ¥
        normalized_score = min((weighted_score / reference_score) * 100, 100)

        return round(normalized_score, 2)

    except Exception as e:
        logger.error(f"âŒ Popularity score calculation failed: {e}")
        return 0.0


def calculate_engagement_score(place_data: Dict[str, int]) -> float:
    """ì°¸ì—¬ë„ ì ìˆ˜ ê³„ì‚° (like/bookmark ë¹„ìœ¨ ê¸°ë°˜)"""
    try:
        total_interactions = (
            place_data.get('total_clicks', 0) +
            place_data.get('total_likes', 0) +
            place_data.get('total_bookmarks', 0)
        )

        if total_interactions == 0:
            return 0.0

        high_value_actions = place_data.get('total_likes', 0) + place_data.get('total_bookmarks', 0)
        engagement_ratio = high_value_actions / total_interactions

        # ì ˆëŒ€ê°’ ë³´ì • ì¶”ê°€
        min_threshold_bonus = min(high_value_actions * 2, 20)  # ìµœëŒ€ 20ì  ë³´ë„ˆìŠ¤
        final_score = min((engagement_ratio * 100) + min_threshold_bonus, 100)

        return round(final_score, 2)

    except Exception as e:
        logger.error(f"âŒ Engagement score calculation failed: {e}")
        return 0.0


def validate_vector_data(vector_data: Any) -> Optional[np.ndarray]:
    """ë²¡í„° ë°ì´í„° ê²€ì¦ ë° ë³€í™˜ (PostgreSQL vector íƒ€ì… ë° ARRAY íƒ€ì… ì§€ì›)"""
    try:
        if vector_data is None:
            return None

        # PostgreSQL ARRAY íƒ€ì… ì²˜ë¦¬ (user_behavior_vectors.behavior_vector)
        if isinstance(vector_data, list):
            vector = np.array(vector_data, dtype=np.float32)

        # PostgreSQL vector íƒ€ì… ë¬¸ìì—´ ì²˜ë¦¬ (place_recommendations.vector, posts.image_vector)
        elif isinstance(vector_data, str):
            # vector íƒ€ì…ì€ "[1,2,3]" í˜•íƒœì˜ ë¬¸ìì—´
            if vector_data.startswith('[') and vector_data.endswith(']'):
                # PostgreSQL vector íƒ€ì… íŒŒì‹±
                vector_str = vector_data.strip('[]')
                if vector_str:
                    vector_list = [float(x.strip()) for x in vector_str.split(',')]
                    vector = np.array(vector_list, dtype=np.float32)
                else:
                    return None
            else:
                # JSON ë¬¸ìì—´ ì‹œë„
                vector_data = json.loads(vector_data)
                vector = np.array(vector_data, dtype=np.float32)

        # ì´ë¯¸ numpy ë°°ì—´ì¸ ê²½ìš°
        elif isinstance(vector_data, np.ndarray):
            vector = vector_data.astype(np.float32)

        # ê¸°íƒ€ ìˆ«ì íƒ€ì…
        else:
            vector = np.array(vector_data, dtype=np.float32)

        # ì°¨ì› ë° ìœ íš¨ì„± ê²€ì‚¬
        if vector.size == 0:
            return None

        if np.isnan(vector).any() or np.isinf(vector).any():
            logger.warning("Vector contains NaN or Inf values")
            return None

        return vector

    except Exception as e:
        logger.error(f"âŒ Vector validation failed: {e}")
        return None


# ============================================================================
# ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤
# ============================================================================

class DatabaseManager:
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ì¿¼ë¦¬ ê´€ë¦¬"""

    def __init__(self, database_url: str):
        self.database_url = database_url
        self.pool = None
        self._initialized = False

    async def initialize(self):
        """Connection Pool ì´ˆê¸°í™”"""
        try:
            self.pool = await asyncpg.create_pool(
                self.database_url,
                min_size=CONFIG.min_pool_size,
                max_size=CONFIG.max_pool_size,
                command_timeout=CONFIG.db_timeout,
                server_settings={
                    'application_name': 'unified_recommendation_engine'
                }
            )
            self._initialized = True
            logger.info(f"âœ… Database pool initialized: {CONFIG.min_pool_size}-{CONFIG.max_pool_size} connections")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize database pool: {e}")
            raise

    async def close(self):
        """Connection Pool ì •ë¦¬"""
        if self.pool:
            await self.pool.close()
            logger.info("ğŸ”Œ Database pool closed")

    @asynccontextmanager
    async def get_connection(self):
        """ì•ˆì „í•œ DB ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        if not self._initialized or not self.pool:
            raise RuntimeError("Database pool not initialized. Call initialize() first.")

        connection = None
        try:
            connection = await self.pool.acquire()
            yield connection
        except Exception as e:
            logger.error(f"âŒ Database connection error: {e}")
            raise
        finally:
            if connection:
                await self.pool.release(connection)

    async def execute_query(self, query: str, *args) -> List[Dict]:
        """ì•ˆì „í•œ ì¿¼ë¦¬ ì‹¤í–‰"""
        async with self.get_connection() as conn:
            try:
                result = await conn.fetch(query, *args)
                return [dict(row) for row in result]
            except Exception as e:
                logger.error(f"âŒ Query execution failed: {query[:100]}... Error: {e}")
                raise

    async def execute_single_query(self, query: str, *args) -> Optional[Any]:
        """ë‹¨ì¼ ê°’ ì¿¼ë¦¬ ì‹¤í–‰"""
        async with self.get_connection() as conn:
            try:
                return await conn.fetchval(query, *args)
            except Exception as e:
                logger.error(f"âŒ Single query execution failed: {query[:100]}... Error: {e}")
                raise


# ============================================================================
# ğŸ¯ í†µí•© ì¶”ì²œ ì—”ì§„ (ì™„ì „ ê°œì„  ë²„ì „)
# ============================================================================

class UnifiedRecommendationEngine:
    """
    ì™„ì „íˆ ê°œì„ ëœ í†µí•© ì¶”ì²œ ì—”ì§„
    - Connection Pool ê´€ë¦¬
    - ë²¡í„° ìºì‹±
    - ì—ëŸ¬ ë³µêµ¬
    - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    """

    def __init__(self, database_url: Optional[str] = None):
        self.database_url = database_url or CONFIG.database_url
        self.db_manager = DatabaseManager(self.database_url)

        # ìºì‹± ì‹œìŠ¤í…œ
        self.vector_cache: Dict[str, Dict] = {}
        self.cache_timestamps: Dict[str, float] = {}

        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            'total_requests': 0,
            'cache_hits': 0,
            'personalized_requests': 0,
            'popular_requests': 0,
            'avg_response_time': 0.0
        }

        logger.info("ğŸš€ UnifiedRecommendationEngine v2.0 initialized")

    async def initialize(self):
        """ì—”ì§„ ì´ˆê¸°í™” (ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ í˜¸ì¶œ)"""
        await self.db_manager.initialize()
        logger.info("âœ… Recommendation engine fully initialized")

    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        await self.db_manager.close()
        self.vector_cache.clear()
        self.cache_timestamps.clear()
        logger.info("ğŸ”Œ Recommendation engine closed")

    def _is_cache_valid(self, cache_key: str) -> bool:
        """ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬"""
        if cache_key not in self.cache_timestamps:
            return False

        age = time.time() - self.cache_timestamps[cache_key]
        return age < CONFIG.cache_ttl_seconds

    def _update_cache(self, cache_key: str, data: Any):
        """ìºì‹œ ì—…ë°ì´íŠ¸"""
        if len(self.vector_cache) >= CONFIG.vector_cache_size:
            # LRU ë°©ì‹ìœ¼ë¡œ ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            oldest_key = min(self.cache_timestamps.keys(),
                           key=lambda k: self.cache_timestamps[k])
            del self.vector_cache[oldest_key]
            del self.cache_timestamps[oldest_key]

        self.vector_cache[cache_key] = data
        self.cache_timestamps[cache_key] = time.time()

    async def get_recommendations(
        self,
        user_id: Optional[str],
        region: Optional[str] = None,
        category: Optional[str] = None,
        limit: int = 20
    ) -> List[Dict]:
        """
        ë©”ì¸ ì¶”ì²œ API (ì™„ì „ ê°œì„  ë²„ì „)
        """
        start_time = time.time()
        self.stats['total_requests'] += 1

        try:
            # íŒŒë¼ë¯¸í„° ê²€ì¦
            limit = max(1, min(limit, 100))  # 1-100 ì‚¬ì´ë¡œ ì œí•œ

            user_vector = None
            if user_id:
                user_vector = await self._get_user_behavior_vector_cached(user_id)
                logger.info(f"DEBUG: User {user_id} vector status: {user_vector is not None}")
                if user_vector is not None:
                    logger.info(f"DEBUG: User vector shape: {user_vector.shape if hasattr(user_vector, 'shape') else 'no shape'}")

            if user_vector is not None:
                logger.info(f"ğŸ¯ Personalized recommendations for user {user_id}")
                self.stats['personalized_requests'] += 1

                # ë¶ë§ˆí¬ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„ ì¶”ê°€ ë°˜ì˜
                bookmark_preferences = await self._get_user_bookmark_preferences(user_id)

                # ë‹¤ì¤‘ ë²¡í„° ê¸°ë°˜ ì¶”ì²œ (í…ìŠ¤íŠ¸+ì´ë¯¸ì§€ í•˜ì´ë¸Œë¦¬ë“œ)
                result = await self._get_multi_vector_recommendations(
                    user_id, user_vector, bookmark_preferences, region, category, limit
                )
            else:
                # ì‹ ê·œ ê°€ì…ìë¥¼ ìœ„í•œ ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ì²œ ì‹œë„
                if user_id:
                    preferences_result = await self._get_preference_based_recommendations(
                        user_id, region, category, limit
                    )
                    if preferences_result:
                        logger.info(f"ğŸŒ± Preference-based recommendations for new user {user_id}")
                        self.stats['preference_requests'] = self.stats.get('preference_requests', 0) + 1
                        result = preferences_result
                    else:
                        logger.info(f"ğŸ“Š Popular recommendations for user {user_id} (no preferences found)")
                        self.stats['popular_requests'] += 1
                        result = await self._get_popular_recommendations(
                            region, category, limit
                        )
                else:
                    logger.info(f"ğŸ“Š Popular recommendations (anonymous user)")
                    self.stats['popular_requests'] += 1
                    result = await self._get_popular_recommendations(
                        region, category, limit
                    )

            # ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
            response_time = time.time() - start_time
            self._update_response_time(response_time)

            logger.info(f"âœ… Returned {len(result)} recommendations in {response_time:.3f}s")
            return result

        except Exception as e:
            logger.error(f"âŒ Recommendation failed: {e}")
            # ë¹ˆ ê²°ê³¼ë¼ë„ ì•ˆì „í•˜ê²Œ ë°˜í™˜
            return []

    async def _get_user_behavior_vector_cached(self, user_id: str) -> Optional[np.ndarray]:
        """ìºì‹œë¥¼ í™œìš©í•œ ì‚¬ìš©ì ë²¡í„° ì¡°íšŒ (PostgreSQL ARRAY íƒ€ì… ì§€ì›)"""
        cache_key = f"user_vector:{user_id}"

        # ìºì‹œ í™•ì¸
        if self._is_cache_valid(cache_key):
            self.stats['cache_hits'] += 1
            cached_data = self.vector_cache[cache_key]
            if cached_data is not None:
                return np.array(cached_data, dtype=np.float32)
            return None

        # DBì—ì„œ ì¡°íšŒ (PostgreSQL ARRAY íƒ€ì…)
        try:
            query = """
                SELECT behavior_vector
                FROM user_behavior_vectors
                WHERE user_id = $1 AND behavior_vector IS NOT NULL
            """
            vector_data = await self.db_manager.execute_single_query(query, user_id)
            logger.info(f"DEBUG: User {user_id} raw vector data from DB: {vector_data is not None}")

            validated_vector = validate_vector_data(vector_data)
            logger.info(f"DEBUG: User {user_id} validated vector: {validated_vector is not None}")

            # ìºì‹œì— ì €ì¥ (Noneë„ ìºì‹œí•˜ì—¬ ë°˜ë³µ ì¿¼ë¦¬ ë°©ì§€)
            if validated_vector is not None:
                self._update_cache(cache_key, validated_vector.tolist())
                return validated_vector
            else:
                self._update_cache(cache_key, None)
                return None

        except Exception as e:
            logger.error(f"âŒ Failed to get user vector for {user_id}: {e}")
            return None

    async def _get_user_bookmark_preferences(self, user_id: str) -> Dict[str, float]:
        """ì‚¬ìš©ì ë¶ë§ˆí¬ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„ ê³„ì‚°"""
        try:
            query = """
                SELECT places
                FROM saved_locations
                WHERE user_id = $1
            """

            bookmarks = await self.db_manager.execute_query(query, user_id)

            if not bookmarks:
                return {}

            # ì¹´í…Œê³ ë¦¬ë³„ ë¶ë§ˆí¬ ìˆ˜ ê³„ì‚°
            category_counts = {}
            total_bookmarks = 0

            for bookmark in bookmarks:
                places_text = bookmark.get('places', '')
                if ':' in places_text:
                    table_name = places_text.split(':', 1)[0]
                    category_counts[table_name] = category_counts.get(table_name, 0) + 1
                    total_bookmarks += 1

            # ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° (ë¹„ìœ¨ ê¸°ë°˜)
            preferences = {}
            for category, count in category_counts.items():
                preferences[category] = count / total_bookmarks if total_bookmarks > 0 else 0

            logger.info(f"ğŸ“Š User {user_id} bookmark preferences: {preferences}")
            return preferences

        except Exception as e:
            logger.error(f"âŒ Failed to get bookmark preferences for {user_id}: {e}")
            return {}

    def _apply_category_quotas(
        self,
        recommendations: List[Dict],
        bookmark_preferences: Dict[str, float],
        limit: int
    ) -> List[Dict]:
        """ë¶ë§ˆí¬ ì„ í˜¸ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë³„ í• ë‹¹ëŸ‰ì„ ì ìš©í•œ ê· í˜•ì¡íŒ ì¶”ì²œ"""
        try:
            if not bookmark_preferences or not recommendations:
                return recommendations[:limit]

            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¶”ì²œ ë¶„ë¥˜
            category_recommendations = {}
            for rec in recommendations:
                category = rec.get('table_name', 'unknown')
                if category not in category_recommendations:
                    category_recommendations[category] = []
                category_recommendations[category].append(rec)

            # ì„ í˜¸ë„ ê¸°ë°˜ í• ë‹¹ëŸ‰ ê³„ì‚°
            result = []
            remaining_slots = limit

            # ë‹¤ì–‘ì„± ë³´ì¥: ìµœì†Œ 3ê°œ ì¹´í…Œê³ ë¦¬ëŠ” ë°˜ë“œì‹œ í¬í•¨
            min_categories = min(3, len(category_recommendations))
            max_per_category = max(1, limit // min_categories)

            # 1ë‹¨ê³„: ì£¼ìš” ì„ í˜¸ ì¹´í…Œê³ ë¦¬ë¶€í„° í• ë‹¹
            sorted_preferences = sorted(bookmark_preferences.items(), key=lambda x: x[1], reverse=True)

            for category, preference_rate in sorted_preferences:
                if category not in category_recommendations:
                    continue

                # ë” ê· í˜•ì¡íŒ í• ë‹¹ëŸ‰ ì‹œìŠ¤í…œ (ë‹¤ì–‘ì„± ê°•í™”)
                if preference_rate > 0.7:  # 70% ì´ìƒ ë§¤ìš° ê°•í•œ ì„ í˜¸
                    quota = min(max(int(limit * 0.35), 3), max_per_category + 2)  # 35% ë˜ëŠ” ê¸°ë³¸+2
                elif preference_rate > 0.4:  # 40% ì´ìƒ ì„ í˜¸ ì¹´í…Œê³ ë¦¬
                    quota = min(max(int(limit * 0.25), 2), max_per_category + 1)  # 25% ë˜ëŠ” ê¸°ë³¸+1
                elif preference_rate > 0.2:  # 20% ì´ìƒ ì„ í˜¸ ì¹´í…Œê³ ë¦¬
                    quota = min(max(int(limit * 0.15), 1), max_per_category)  # 15% ë˜ëŠ” ê¸°ë³¸
                elif preference_rate > 0.05:  # 5% ì´ìƒ ì„ í˜¸ ì¹´í…Œê³ ë¦¬
                    quota = min(2, max_per_category)  # ìµœëŒ€ 2ê°œ ë˜ëŠ” ê¸°ë³¸
                else:  # ë‚˜ë¨¸ì§€ ì¹´í…Œê³ ë¦¬
                    quota = 1

                # ì‹¤ì œ í• ë‹¹ ê°€ëŠ¥í•œ ìˆ˜ë§Œí¼ ì¶”ê°€
                available = min(quota, len(category_recommendations[category]), remaining_slots)
                result.extend(category_recommendations[category][:available])
                remaining_slots -= available

                logger.info(f"ğŸ“Š {category}: {preference_rate:.3f} -> {available}ê°œ í• ë‹¹")

                if remaining_slots <= 0:
                    break

            # 2ë‹¨ê³„: ë‚¨ì€ ìŠ¬ë¡¯ì„ ì ìˆ˜ìˆœìœ¼ë¡œ ì±„ì›€
            if remaining_slots > 0:
                used_ids = {rec.get('place_id') for rec in result}
                remaining_recs = [rec for rec in recommendations if rec.get('place_id') not in used_ids]
                result.extend(remaining_recs[:remaining_slots])

            return result[:limit]

        except Exception as e:
            logger.error(f"âŒ Category quota application failed: {e}")
            return recommendations[:limit]

    def _apply_category_shuffling(self, recommendations: List[Dict]) -> List[Dict]:
        """ì¹´í…Œê³ ë¦¬ê°€ ì ì ˆíˆ ì„ì´ë„ë¡ ì¸í„°ë¦¬ë¹™ ë°©ì‹ìœ¼ë¡œ ì¬ë°°ì¹˜"""
        try:
            if len(recommendations) <= 3:
                return recommendations

            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
            category_groups = {}
            for rec in recommendations:
                category = rec.get('table_name', 'unknown')
                if category not in category_groups:
                    category_groups[category] = []
                category_groups[category].append(rec)

            # ì¹´í…Œê³ ë¦¬ê°€ 2ê°œ ì´í•˜ë©´ ì…”í”Œë§ ë¶ˆí•„ìš”
            if len(category_groups) <= 2:
                return recommendations

            logger.info(f"ğŸ”„ Shuffling {len(category_groups)} categories for better distribution")

            # ì¸í„°ë¦¬ë¹™ ë°©ì‹ìœ¼ë¡œ ì¬ë°°ì¹˜
            result = []
            category_indices = {cat: 0 for cat in category_groups.keys()}
            categories = list(category_groups.keys())

            # ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë¥¼ ìˆœí™˜í•˜ë©° ë°°ì¹˜
            for position in range(len(recommendations)):
                # í˜„ì¬ ë¼ìš´ë“œì—ì„œ ì‚¬ìš©í•  ì¹´í…Œê³ ë¦¬ ì„ íƒ
                category_idx = position % len(categories)
                current_category = categories[category_idx]

                # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ì•„ì§ ë°°ì¹˜ë˜ì§€ ì•Šì€ ì•„ì´í…œì´ ìˆëŠ”ì§€ í™•ì¸
                attempts = 0
                while attempts < len(categories):
                    cat_idx = category_indices[current_category]
                    if cat_idx < len(category_groups[current_category]):
                        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ì•„ì´í…œ ì¶”ê°€
                        result.append(category_groups[current_category][cat_idx])
                        category_indices[current_category] += 1
                        break
                    else:
                        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ê°€ ì†Œì§„ë˜ë©´ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ
                        category_idx = (category_idx + 1) % len(categories)
                        current_category = categories[category_idx]
                        attempts += 1

                # ëª¨ë“  ì¹´í…Œê³ ë¦¬ê°€ ì†Œì§„ë˜ë©´ ì¢…ë£Œ
                if attempts >= len(categories):
                    break

            # í˜¹ì‹œ ë‚¨ì€ ì•„ì´í…œë“¤ ì¶”ê°€
            for category, items in category_groups.items():
                start_idx = category_indices[category]
                result.extend(items[start_idx:])

            logger.info(f"âœ… Category shuffling completed: {len(result)} items redistributed")
            return result[:len(recommendations)]

        except Exception as e:
            logger.error(f"âŒ Category shuffling failed: {e}")
            return recommendations

    async def _get_place_candidates(
        self,
        region: Optional[str],
        category: Optional[str]
    ) -> List[Dict]:
        """ì¶”ì²œ í›„ë³´ ì¥ì†Œ ì¡°íšŒ (ìµœì í™”ëœ ì¿¼ë¦¬)"""
        try:
            # place_recommendations í…Œì´ë¸”ì—ì„œ í…ìŠ¤íŠ¸ ë²¡í„° ì¡°íšŒ (PostgreSQL vector íƒ€ì…)
            query = """
                SELECT
                    pr.place_id::text as place_id,
                    pr.table_name,
                    pr.vector as vector,
                    COALESCE(pr.bookmark_cnt, 0) as total_likes,
                    COALESCE(pr.bookmark_cnt, 0) as total_bookmarks,
                    COALESCE(pr.bookmark_cnt, 0) as total_clicks,
                    1 as unique_users,
                    COALESCE(pr.bookmark_cnt, 0)::float as popularity_score,
                    COALESCE(pr.bookmark_cnt, 0)::float as engagement_score,
                    pr.name,
                    pr.region,
                    pr.city,
                    pr.latitude,
                    pr.longitude,
                    pr.overview as description,
                    pr.image_urls,
                    pr.bookmark_cnt
                FROM place_recommendations pr
                WHERE
                    pr.vector IS NOT NULL
                    AND pr.name IS NOT NULL
                    AND pr.bookmark_cnt IS NOT NULL
            """

            params = []
            param_count = 0

            # ì§€ì—­ í•„í„°
            if region:
                param_count += 1
                query += f" AND pr.region = ${param_count}"
                params.append(region)

            # ì¹´í…Œê³ ë¦¬ í•„í„°
            if category:
                param_count += 1
                query += f" AND pr.table_name = ${param_count}::text"
                params.append(category)

            # ì„±ëŠ¥ì„ ìœ„í•œ ì œí•œ ë° ì •ë ¬ (ë¶ë§ˆí¬ ì¹´ìš´íŠ¸ ê¸°ì¤€)
            query += " ORDER BY COALESCE(pr.bookmark_cnt, 0) DESC"
            param_count += 1
            query += f" LIMIT ${param_count}"
            params.append(CONFIG.candidate_limit)

            places = await self.db_manager.execute_query(query, *params)

            # ë²¡í„° ë°ì´í„° ê²€ì¦
            valid_places = []
            for place in places:
                if validate_vector_data(place['vector']) is not None:
                    valid_places.append(place)

            logger.info(f"ğŸ“‹ Retrieved {len(valid_places)} valid place candidates")
            return valid_places

        except Exception as e:
            logger.error(f"âŒ Failed to get place candidates: {e}")
            return []

    async def _get_popular_recommendations(
        self,
        region: Optional[str],
        category: Optional[str],
        limit: int
    ) -> List[Dict]:
        """ì¸ê¸° ê¸°ë°˜ ì¶”ì²œ (ë‹¨ìˆœ ë¶ë§ˆí¬ ì¹´ìš´íŠ¸ ì •ë ¬)"""
        places = await self._get_place_candidates(region, category)

        if not places:
            return []

        # ë‹¨ìˆœ ë¶ë§ˆí¬ ì¹´ìš´íŠ¸ ê¸°ë°˜ ì •ë ¬
        for place in places:
            try:
                bookmark_count = place.get('bookmark_cnt', 0)

                place['final_score'] = bookmark_count
                place['recommendation_type'] = 'popular'
                place['similarity_score'] = 0.8  # ì¸ê¸° ì¶”ì²œìš© ê¸°ë³¸ê°’

            except Exception as e:
                logger.error(f"âŒ Popular score calculation failed for place {place.get('place_id')}: {e}")
                place['final_score'] = 0

        # ë¶ë§ˆí¬ ì¹´ìš´íŠ¸ìˆœ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
        places.sort(key=lambda x: x.get('bookmark_cnt', 0), reverse=True)
        
        # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
        for place in places[:limit]:
            if 'vector' in place and isinstance(place['vector'], np.ndarray):
                place['vector'] = place['vector'].tolist()
            if 'text_vector' in place and isinstance(place['text_vector'], np.ndarray):
                place['text_vector'] = place['text_vector'].tolist()
            if 'image_vector' in place and isinstance(place['image_vector'], np.ndarray):
                place['image_vector'] = place['image_vector'].tolist()
        
        return places[:limit]

    async def _get_multi_vector_recommendations(
        self,
        user_id: str,
        user_vector: np.ndarray,
        bookmark_preferences: Dict[str, float],
        region: Optional[str],
        category: Optional[str],
        limit: int
    ) -> List[Dict]:
        """
        ë‹¤ì¤‘ ë²¡í„° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ
        - í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ (ê¸°ì¡´ overview ë²¡í„°)
        - ì´ë¯¸ì§€-ì´ë¯¸ì§€ ìœ ì‚¬ë„ (ìƒˆë¡œìš´ image ë²¡í„°)
        - í¬ë¡œìŠ¤ ëª¨ë‹¬ ìœ ì‚¬ë„ (í…ìŠ¤íŠ¸-ì´ë¯¸ì§€, ì´ë¯¸ì§€-í…ìŠ¤íŠ¸)
        - ë¶ë§ˆí¬ ê¸°ë°˜ ì„ í˜¸ë„ ë°˜ì˜
        """
        try:
            # ì¥ì†Œ í›„ë³´êµ° ì¡°íšŒ (ì´ë¯¸ì§€ ë²¡í„° í¬í•¨)
            places = await self._get_place_candidates_with_images(region, category)

            if not places:
                return []

            # ì‚¬ìš©ì í–‰ë™ ë°ì´í„° ì¡°íšŒ (ë¶ë§ˆí¬ëœ ì¥ì†Œì˜ ì´ë¯¸ì§€ ë²¡í„°, ì¢‹ì•„ìš”í•œ í¬ìŠ¤íŠ¸ì˜ ì´ë¯¸ì§€ ë²¡í„°)
            user_image_preferences = await self._get_user_image_preferences(user_id)

            # ë…ë¦½ì ì¸ ë‹¤ì¤‘ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°
            multi_scores = await self._calculate_independent_similarities(
                user_id, user_vector, user_image_preferences, places
            )

            # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° ë° ê²°ê³¼ ìƒì„±
            results = []
            for i, place in enumerate(places):
                if i >= len(multi_scores):
                    logger.warning(f"Missing score for place {i}, using defaults")
                    scores = {
                        'behavior_text_similarity': 0.0,
                        'upload_image_similarity': 0.0,
                        'bookmark_text_similarity': 0.0,
                        'bookmark_image_similarity': 0.0,
                        'liked_post_similarity': 0.0,
                        'combined_score': 0.0
                    }
                else:
                    scores = multi_scores[i]

                try:
                    # ì¸ê¸°ë„ ì ìˆ˜
                    place_data = {
                        'total_clicks': place.get('total_clicks', 0),
                        'total_likes': place.get('total_likes', 0),
                        'total_bookmarks': place.get('total_bookmarks', 0)
                    }
                    popularity_score = calculate_weighted_popularity_score(place_data)
                    engagement_score = calculate_engagement_score(place_data)

                    # ë¶ë§ˆí¬ ì„ í˜¸ë„ ë³´ë„ˆìŠ¤
                    category_preference = bookmark_preferences.get(place['table_name'], 0)
                    bookmark_bonus = category_preference * 0.5

                    # ë‹¤ì¤‘ ë²¡í„° ì¢…í•© ì ìˆ˜ (ë…ë¦½ì  ë²¡í„° ì¡°í•©)
                    multi_vector_score = scores.get('combined_score', 0.0)

                    # ìµœì¢… í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜
                    final_score = (
                        multi_vector_score * CONFIG.similarity_weight +
                        (popularity_score / 100.0) * CONFIG.popularity_weight * 0.7 +
                        (engagement_score / 100.0) * CONFIG.popularity_weight * 0.3 +
                        bookmark_bonus
                    )

                    # ì ìˆ˜ê°€ ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ í¬í•¨
                    if multi_vector_score >= CONFIG.min_similarity_threshold:
                        place['behavior_text_similarity'] = round(scores.get('behavior_text_similarity', 0.0), 4)
                        place['upload_image_similarity'] = round(scores.get('upload_image_similarity', 0.0), 4)
                        place['bookmark_text_similarity'] = round(scores.get('bookmark_text_similarity', 0.0), 4)
                        place['bookmark_image_similarity'] = round(scores.get('bookmark_image_similarity', 0.0), 4)
                        place['liked_post_similarity'] = round(scores.get('liked_post_similarity', 0.0), 4)
                        place['combined_score'] = round(scores.get('combined_score', 0.0), 4)
                        place['multi_vector_score'] = round(multi_vector_score, 4)
                        place['popularity_score'] = popularity_score
                        place['engagement_score'] = engagement_score
                        place['bookmark_bonus'] = round(bookmark_bonus, 4)
                        place['final_score'] = round(final_score, 4)
                        place['recommendation_type'] = 'five_channel_system'

                        results.append(place)

                except Exception as e:
                    logger.error(f"âŒ Multi-vector score calculation failed for place {i}: {e}")
                    continue

            # ì ìˆ˜ìˆœ ì •ë ¬
            results.sort(key=lambda x: x['final_score'], reverse=True)

            logger.info(f"ğŸ¯ Multi-vector recommendations: {len(results)} candidates")

            # ì¹´í…Œê³ ë¦¬ ê· í˜• ì¡°ì • ì ìš©
            balanced_results = self._apply_category_quotas(results, bookmark_preferences, limit)
            final_results = self._apply_category_shuffling(balanced_results)
            
            # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
            for result in final_results:
                if 'vector' in result and isinstance(result['vector'], np.ndarray):
                    result['vector'] = result['vector'].tolist()
                if 'text_vector' in result and isinstance(result['text_vector'], np.ndarray):
                    result['text_vector'] = result['text_vector'].tolist()
                if 'image_vector' in result and isinstance(result['image_vector'], np.ndarray):
                    result['image_vector'] = result['image_vector'].tolist()

            return final_results

        except Exception as e:
            logger.error(f"âŒ Multi-vector recommendation failed: {e}")
            # Fallback to enhanced vector recommendations
            return await self._get_enhanced_vector_recommendations(
                user_vector, bookmark_preferences, region, category, limit
            )

    async def _get_enhanced_vector_recommendations(
        self,
        user_vector: np.ndarray,
        bookmark_preferences: Dict[str, float],
        region: Optional[str],
        category: Optional[str],
        limit: int
    ) -> List[Dict]:
        """ë¶ë§ˆí¬ ì„ í˜¸ë„ë¥¼ ë°˜ì˜í•œ ê°œì„ ëœ ë²¡í„° ê¸°ë°˜ ì¶”ì²œ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)"""
        places = await self._get_place_candidates(region, category)

        if not places:
            return []

        try:
            # ë²¡í„° ë°°ì¹˜ ì²˜ë¦¬
            place_vectors = []
            valid_places = []

            for place in places:
                vector = validate_vector_data(place['vector'])
                if vector is not None:
                    place_vectors.append(vector)
                    valid_places.append(place)

            if not valid_places:
                logger.warning("âš ï¸ No valid place vectors found, falling back to popular")
                return await self._get_popular_recommendations(region, category, limit)

            # ë²¡í„°í™”ëœ ìœ ì‚¬ë„ ê³„ì‚°
            place_vectors_array = np.array(place_vectors, dtype=np.float32)
            similarities = safe_cosine_similarity(user_vector, place_vectors_array)

            # ë¶ë§ˆí¬ ì„ í˜¸ë„ ê°•í™”ëœ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
            results = []
            for i, place in enumerate(valid_places):
                try:
                    similarity = float(similarities[i])

                    # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš©
                    if similarity < CONFIG.min_similarity_threshold:
                        continue

                    # ê¸°ë³¸ ì¸ê¸°ë„ ì ìˆ˜
                    place_data = {
                        'total_clicks': place.get('total_clicks', 0),
                        'total_likes': place.get('total_likes', 0),
                        'total_bookmarks': place.get('total_bookmarks', 0)
                    }
                    popularity_score = calculate_weighted_popularity_score(place_data)
                    engagement_score = calculate_engagement_score(place_data)

                    # ğŸ”¥ ë¶ë§ˆí¬ ì„ í˜¸ë„ ë³´ë„ˆìŠ¤ ì¶”ê°€ (ì ì ˆí•œ ê°•í™”)
                    category_preference = bookmark_preferences.get(place['table_name'], 0)
                    bookmark_bonus = category_preference * 0.5  # ìµœëŒ€ 50% ë³´ë„ˆìŠ¤ (ê· í˜•ì¡íŒ ì¡°ì •)

                    # ê°œì„ ëœ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜
                    hybrid_score = (
                        similarity * CONFIG.similarity_weight +
                        (popularity_score / 100.0) * CONFIG.popularity_weight * 0.7 +
                        (engagement_score / 100.0) * CONFIG.popularity_weight * 0.3 +
                        bookmark_bonus  # ë¶ë§ˆí¬ ì„ í˜¸ë„ ë³´ë„ˆìŠ¤
                    )

                    place['similarity_score'] = round(similarity, 4)
                    place['popularity_score'] = popularity_score
                    place['engagement_score'] = engagement_score
                    place['bookmark_bonus'] = round(bookmark_bonus, 4)
                    place['final_score'] = round(hybrid_score, 4)
                    place['recommendation_type'] = 'personalized_enhanced'

                    results.append(place)

                except Exception as e:
                    logger.error(f"âŒ Score calculation failed for place {i}: {e}")
                    continue

            # ì ìˆ˜ìˆœ ì •ë ¬
            results.sort(key=lambda x: x['final_score'], reverse=True)

            # ğŸ¯ ì¹´í…Œê³ ë¦¬ë³„ ë³´ì¥ ì¶”ì²œ ì‹œìŠ¤í…œ ì ìš©
            balanced_results = self._apply_category_quotas(results, bookmark_preferences, limit)

            # ğŸ”„ ì¹´í…Œê³ ë¦¬ ë¶„ì‚°ì„ ìœ„í•œ ì…”í”Œë§ ì ìš©
            final_results = self._apply_category_shuffling(balanced_results)

            return final_results

        except Exception as e:
            logger.error(f"âŒ Enhanced vector-based recommendation failed: {e}")
            # Fallback to popular recommendations
            return await self._get_popular_recommendations(region, category, limit)

    async def _get_vector_based_recommendations(
        self,
        user_vector: np.ndarray,
        region: Optional[str],
        category: Optional[str],
        limit: int
    ) -> List[Dict]:
        """ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ê°œì¸í™” ì¶”ì²œ (ìµœì í™”ëœ ë²„ì „)"""
        places = await self._get_place_candidates(region, category)

        if not places:
            return []

        try:
            # ë²¡í„° ë°°ì¹˜ ì²˜ë¦¬
            place_vectors = []
            valid_places = []

            for place in places:
                vector = validate_vector_data(place['vector'])
                if vector is not None:
                    place_vectors.append(vector)
                    valid_places.append(place)

            if not valid_places:
                logger.warning("âš ï¸ No valid place vectors found, falling back to popular")
                return await self._get_popular_recommendations(region, category, limit)

            # ë²¡í„°í™”ëœ ìœ ì‚¬ë„ ê³„ì‚°
            place_vectors_array = np.array(place_vectors, dtype=np.float32)
            similarities = safe_cosine_similarity(user_vector, place_vectors_array)

            # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
            results = []
            for i, place in enumerate(valid_places):
                try:
                    similarity = float(similarities[i])

                    # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš©
                    if similarity < CONFIG.min_similarity_threshold:
                        continue

                    # ì¸ê¸°ë„ ì ìˆ˜ ê³„ì‚°
                    place_data = {
                        'total_clicks': place.get('total_clicks', 0),
                        'total_likes': place.get('total_likes', 0),
                        'total_bookmarks': place.get('total_bookmarks', 0)
                    }
                    popularity_score = calculate_weighted_popularity_score(place_data)
                    engagement_score = calculate_engagement_score(place_data)

                    # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ (ê°œì¸í™” + ì¸ê¸°ë„ + ì°¸ì—¬ë„)
                    hybrid_score = (
                        similarity * CONFIG.similarity_weight +
                        (popularity_score / 100.0) * CONFIG.popularity_weight * 0.7 +
                        (engagement_score / 100.0) * CONFIG.popularity_weight * 0.3
                    )

                    place['similarity_score'] = round(similarity, 4)
                    place['popularity_score'] = popularity_score
                    place['engagement_score'] = engagement_score
                    place['final_score'] = round(hybrid_score, 4)
                    place['recommendation_type'] = 'personalized'

                    results.append(place)

                except Exception as e:
                    logger.error(f"âŒ Score calculation failed for place {i}: {e}")
                    continue

            # ì ìˆ˜ìˆœ ì •ë ¬
            results.sort(key=lambda x: x['final_score'], reverse=True)

            logger.info(f"ğŸ¯ Generated {len(results)} personalized recommendations")
            
            # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
            for result in results[:limit]:
                if 'vector' in result and isinstance(result['vector'], np.ndarray):
                    result['vector'] = result['vector'].tolist()
                if 'text_vector' in result and isinstance(result['text_vector'], np.ndarray):
                    result['text_vector'] = result['text_vector'].tolist()
                if 'image_vector' in result and isinstance(result['image_vector'], np.ndarray):
                    result['image_vector'] = result['image_vector'].tolist()
            
            return results[:limit]

        except Exception as e:
            logger.error(f"âŒ Vector-based recommendation failed: {e}")
            # Fallback to popular recommendations
            return await self._get_popular_recommendations(region, category, limit)

    def _update_response_time(self, response_time: float):
        """ì‘ë‹µ ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸ (ì´ë™í‰ê· )"""
        alpha = 0.1  # ì´ë™í‰ê·  ê°€ì¤‘ì¹˜
        if self.stats['avg_response_time'] == 0.0:
            self.stats['avg_response_time'] = response_time
        else:
            self.stats['avg_response_time'] = (
                alpha * response_time +
                (1 - alpha) * self.stats['avg_response_time']
            )

    def get_stats(self) -> Dict:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        cache_hit_rate = (
            self.stats['cache_hits'] / max(self.stats['total_requests'], 1)
        ) * 100

        return {
            **self.stats,
            'cache_hit_rate': round(cache_hit_rate, 2),
            'cache_size': len(self.vector_cache),
            'personalization_rate': round(
                (self.stats['personalized_requests'] / max(self.stats['total_requests'], 1)) * 100, 2
            )
        }

    async def get_popular_regions_and_categories(self) -> Dict[str, List[str]]:
        """ì¸ê¸°ë„ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ì§€ì—­/ì¹´í…Œê³ ë¦¬ ìˆœì„œ ê²°ì •"""
        try:
            # ì§€ì—­ë³„ ë¶ë§ˆí¬ ì´í•© ì¡°íšŒ
            region_query = """
                SELECT region, SUM(COALESCE(bookmark_cnt, 0)) as total_bookmarks
                FROM place_recommendations
                WHERE region IS NOT NULL
                GROUP BY region
                ORDER BY total_bookmarks DESC
                LIMIT 10
            """

            # ì¹´í…Œê³ ë¦¬ë³„ ë¶ë§ˆí¬ ì´í•© ì¡°íšŒ
            category_query = """
                SELECT table_name as category, SUM(COALESCE(bookmark_cnt, 0)) as total_bookmarks
                FROM place_recommendations
                WHERE table_name IS NOT NULL
                GROUP BY table_name
                ORDER BY total_bookmarks DESC
                LIMIT 10
            """

            regions_data = await self.db_manager.execute_query(region_query)
            categories_data = await self.db_manager.execute_query(category_query)

            regions = [row['region'] for row in regions_data if row['region']]
            categories = [row['category'] for row in categories_data if row['category']]

            logger.info(f"ğŸ“Š Dynamic ordering: {len(regions)} regions, {len(categories)} categories")

            return {
                'regions': regions,
                'categories': categories
            }

        except Exception as e:
            logger.error(f"âŒ Failed to get dynamic regions/categories: {e}")
            # Fallback to config defaults
            return {
                'regions': CONFIG.explore_regions or [],
                'categories': CONFIG.explore_categories or []
            }

    async def health_check(self) -> Dict[str, Any]:
        """ì—”ì§„ í—¬ìŠ¤ì²´í¬"""
        try:
            # ê°„ë‹¨í•œ DB ì—°ê²° í…ŒìŠ¤íŠ¸
            test_result = await self.db_manager.execute_single_query("SELECT 1")
            db_healthy = test_result == 1

            # ìºì‹œ ìƒíƒœ í™•ì¸
            cache_healthy = len(self.vector_cache) < CONFIG.vector_cache_size

            # ì „ì²´ ìƒíƒœ íŒë‹¨
            overall_healthy = db_healthy and cache_healthy

            return {
                'status': 'healthy' if overall_healthy else 'degraded',
                'database': 'connected' if db_healthy else 'disconnected',
                'cache': 'normal' if cache_healthy else 'full',
                'stats': self.get_stats(),
                'config': {
                    'candidate_limit': CONFIG.candidate_limit,
                    'similarity_weight': CONFIG.similarity_weight,
                    'popularity_weight': CONFIG.popularity_weight
                }
            }

        except Exception as e:
            logger.error(f"âŒ Health check failed: {e}")
            return {
                'status': 'unhealthy',
                'error': str(e),
                'stats': self.get_stats()
            }

    async def _get_preference_based_recommendations(
        self,
        user_id: str,
        region: Optional[str] = None,
        category: Optional[str] = None,
        limit: int = 20
    ) -> List[Dict]:
        """
        ì‹ ê·œ ê°€ì…ìë¥¼ ìœ„í•œ ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ì²œ
        user_preferencesì™€ user_preference_tags í…Œì´ë¸”ì„ í™œìš©í•œ ì—¬í–‰ ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ì²œ
        """
        try:
            # 1. ì‚¬ìš©ì ì„ í˜¸ë„ ì •ë³´ ì¡°íšŒ
            user_preferences = await self._get_user_preferences(user_id)
            if not user_preferences:
                logger.info(f"No preferences found for user {user_id}")
                return []

            # 2. ì„ í˜¸ë„ ê¸°ë°˜ ì¥ì†Œ í•„í„°ë§ ë° ì ìˆ˜ ê³„ì‚°
            recommendations = await self._calculate_preference_scores(
                user_preferences, region, category, limit
            )

            logger.info(f"âœ… Generated {len(recommendations)} preference-based recommendations for user {user_id}")
            return recommendations

        except Exception as e:
            logger.error(f"âŒ Preference-based recommendation failed for user {user_id}: {e}")
            return []

    async def _get_user_preferences(self, user_id: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì„ í˜¸ë„ ì •ë³´ ì¡°íšŒ (users í…Œì´ë¸”ì—ì„œ ì§ì ‘ ì¡°íšŒ)"""
        try:
            # users í…Œì´ë¸”ì—ì„œ ì„ í˜¸ë„ ì •ë³´ ì¡°íšŒ (ì‹¤ì œ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ìˆ˜ì •)
            preferences_query = """
                SELECT
                    priority,
                    accommodation,
                    exploration,
                    persona
                FROM users
                WHERE user_id = $1
            """

            # user_preference_tags í…Œì´ë¸”ì—ì„œ íƒœê·¸ ì •ë³´ ì¡°íšŒ (í˜„ì¬ ìŠ¤í‚¤ë§ˆ)
            tags_query = """
                SELECT
                    tag,
                    weight
                FROM user_preference_tags
                WHERE user_id = $1
                ORDER BY weight DESC
            """

            # ë³‘ë ¬ë¡œ ë‘ ì¿¼ë¦¬ ì‹¤í–‰
            async with self.db_manager.get_connection() as conn:
                preferences_data = await conn.fetchrow(preferences_query, user_id)
                tags_data = await conn.fetch(tags_query, user_id)

            if not preferences_data and not tags_data:
                return {}

            # ê²°ê³¼ êµ¬ì„± (í˜„ì¬ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ)
            result = {
                'priority': preferences_data.get('priority') if preferences_data else None,
                'accommodation': preferences_data.get('accommodation') if preferences_data else None,
                'exploration': preferences_data.get('exploration') if preferences_data else None,
                'persona': preferences_data.get('persona') if preferences_data else None,
                'preference_tags': {
                    row['tag']: row['weight']
                    for row in tags_data
                }
            }

            return result

        except Exception as e:
            logger.error(f"âŒ Failed to get user preferences for {user_id}: {e}")
            return {}

    async def _calculate_preference_scores(
        self,
        user_preferences: Dict[str, Any],
        region: Optional[str] = None,
        category: Optional[str] = None,
        limit: int = 20
    ) -> List[Dict]:
        """ì„ í˜¸ë„ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° ë° ì¶”ì²œ ìƒì„±"""
        try:
            # ì¥ì†Œ í›„ë³´êµ° ì¡°íšŒ
            places_query = """
                SELECT
                    place_id, table_name, region, name,
                    latitude, longitude, overview, image_urls, bookmark_cnt,
                    COALESCE(bookmark_cnt, 0) as popularity_score
                FROM place_recommendations
                WHERE name IS NOT NULL
                    AND ($1::text IS NULL OR region = $1)
                    AND ($2::text IS NULL OR table_name = $2)
                ORDER BY bookmark_cnt DESC
                LIMIT $3
            """

            async with self.db_manager.get_connection() as conn:
                places_data = await conn.fetch(
                    places_query,
                    region,
                    category,
                    CONFIG.candidate_limit
                )

            if not places_data:
                return []

            # ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
            scored_places = []
            popularity_normalizer = CONFIG.preference_weights['popularity_normalizer']

            for place in places_data:
                preference_score = self._calculate_place_preference_score(place, user_preferences)

                if preference_score > 0:
                    place_dict = dict(place)
                    popularity_normalized = min(place['popularity_score'] / popularity_normalizer, 1.0)
                    final_score = (preference_score * CONFIG.similarity_weight) + (popularity_normalized * CONFIG.popularity_weight)

                    place_dict['preference_score'] = preference_score
                    place_dict['final_score'] = final_score
                    scored_places.append(place_dict)

            scored_places.sort(key=lambda x: x['final_score'], reverse=True)
            
            # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
            for place in scored_places[:limit]:
                if 'vector' in place and isinstance(place['vector'], np.ndarray):
                    place['vector'] = place['vector'].tolist()
                if 'text_vector' in place and isinstance(place['text_vector'], np.ndarray):
                    place['text_vector'] = place['text_vector'].tolist()
                if 'image_vector' in place and isinstance(place['image_vector'], np.ndarray):
                    place['image_vector'] = place['image_vector'].tolist()
            
            return scored_places[:limit]

        except Exception as e:
            logger.error(f"âŒ Failed to calculate preference scores: {e}")
            return []

    def _calculate_place_preference_score(
        self,
        place: Dict[str, Any],
        user_preferences: Dict[str, Any]
    ) -> float:
        """ê°œë³„ ì¥ì†Œì— ëŒ€í•œ ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° (í˜„ì¬ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ìˆ˜ì •)"""
        score = 0.0

        try:
            weights = CONFIG.preference_weights

            # í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„
            persona = user_preferences.get('persona')
            if persona and place['table_name']:
                # í˜ë¥´ì†Œë‚˜ë³„ ì¹´í…Œê³ ë¦¬ ë³´ë„ˆìŠ¤
                persona_bonuses = {
                    'culture_lover': {'humanities': 0.3, 'culture': 0.3},
                    'nature_lover': {'nature': 0.3, 'leisure_sports': 0.2},
                    'foodie': {'restaurants': 0.4},
                    'shopper': {'shopping': 0.3},
                    'luxury_traveler': {'accommodation': 0.2, 'restaurants': 0.2}
                }

                if persona in persona_bonuses:
                    category_bonus = persona_bonuses[persona].get(place['table_name'], 0)
                    score += category_bonus

            # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì ìˆ˜
            priority = user_preferences.get('priority')
            if priority:
                # ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
                if priority == 'popular' and place.get('bookmark_cnt', 0) > 1000:
                    score += 0.2
                elif priority == 'unique' and place.get('bookmark_cnt', 0) < 500:
                    score += 0.2

            # íƒœê·¸ ë§¤ì¹­ (í˜„ì¬ ìŠ¤í‚¤ë§ˆ)
            preference_tags = user_preferences.get('preference_tags', {})
            if preference_tags:
                place_description = (place.get('description', '') or '').lower()
                place_name = (place.get('name', '') or '').lower()
                combined_text = place_description + ' ' + place_name

                tag_score, tag_count = 0.0, 0

                for tag_name, tag_weight in preference_tags.items():
                    tag_lower = tag_name.lower()
                    if tag_lower in combined_text:
                        # weightëŠ” 1-10 ìŠ¤ì¼€ì¼ë¡œ ê°€ì •, ì •ê·œí™”
                        normalized_weight = min(tag_weight / 10.0, 1.0)
                        tag_score += normalized_weight
                        tag_count += 1

                if tag_count > 0:
                    # íƒœê·¸ ì ìˆ˜ ì •ê·œí™”
                    normalized_tag_score = min(tag_score / tag_count, 1.0)
                    score += normalized_tag_score * weights['tag']

            # íƒí—˜ ì„±í–¥ ë°˜ì˜
            exploration = user_preferences.get('exploration')
            if exploration == 'adventurous' and place['table_name'] in ['nature', 'leisure_sports']:
                score += 0.1
            elif exploration == 'comfort' and place['table_name'] in ['accommodation', 'restaurants']:
                score += 0.1

            return min(score, 1.0)

        except Exception as e:
            logger.error(f"âŒ Failed to calculate preference score for place {place.get('place_id')}: {e}")
            return 0.0

    async def _get_place_candidates_with_images(
        self,
        region: Optional[str],
        category: Optional[str]
    ) -> List[Dict]:
        """ì´ë¯¸ì§€ ë²¡í„°ë¥¼ í¬í•¨í•œ ì¥ì†Œ í›„ë³´êµ° ì¡°íšŒ"""
        try:
            query = """
                SELECT
                    pr.place_id::text as place_id,
                    pr.table_name,
                    pr.vector as text_vector,
                    pr.image_vector,
                    COALESCE(pr.bookmark_cnt, 0) as total_likes,
                    COALESCE(pr.bookmark_cnt, 0) as total_bookmarks,
                    COALESCE(pr.bookmark_cnt, 0) as total_clicks,
                    1 as unique_users,
                    COALESCE(pr.bookmark_cnt, 0)::float as popularity_score,
                    COALESCE(pr.bookmark_cnt, 0)::float as engagement_score,
                    pr.name,
                    pr.region,
                    pr.city,
                    pr.latitude,
                    pr.longitude,
                    pr.overview as description,
                    pr.image_urls,
                    pr.bookmark_cnt
                FROM place_recommendations pr
                WHERE
                    pr.vector IS NOT NULL
                    AND pr.name IS NOT NULL
                    AND pr.bookmark_cnt IS NOT NULL
            """

            params = []
            param_count = 0

            if region:
                param_count += 1
                query += f" AND pr.region = ${param_count}"
                params.append(region)

            if category:
                param_count += 1
                query += f" AND pr.table_name = ${param_count}::text"
                params.append(category)

            query += " ORDER BY COALESCE(pr.bookmark_cnt, 0) DESC"
            param_count += 1
            query += f" LIMIT ${param_count}"
            params.append(CONFIG.candidate_limit)

            places = await self.db_manager.execute_query(query, *params)

            # í…ìŠ¤íŠ¸ ë²¡í„°ëŠ” í•„ìˆ˜, ì´ë¯¸ì§€ ë²¡í„°ëŠ” ì„ íƒì 
            valid_places = []
            for place in places:
                text_vector = validate_vector_data(place['text_vector'])
                if text_vector is not None:
                    place['text_vector'] = text_vector

                    # ì´ë¯¸ì§€ ë²¡í„°ëŠ” ìˆìœ¼ë©´ ì¶”ê°€, ì—†ìœ¼ë©´ None
                    image_vector = validate_vector_data(place.get('image_vector'))
                    place['image_vector'] = image_vector

                    valid_places.append(place)

            logger.info(f"ğŸ“‹ Retrieved {len(valid_places)} places with text vectors ({sum(1 for p in valid_places if p['image_vector'] is not None)} with image vectors)")
            return valid_places

        except Exception as e:
            logger.error(f"âŒ Failed to get place candidates with images: {e}")
            return []

    async def _get_user_image_preferences(self, user_id: str) -> Dict[str, np.ndarray]:
        """ì‚¬ìš©ìì˜ ì´ë¯¸ì§€ ì„ í˜¸ë„ ë²¡í„° ìˆ˜ì§‘ (ë¶ë§ˆí¬, ì¢‹ì•„ìš” ê¸°ë°˜)"""
        try:

            # 1. ë¶ë§ˆí¬í•œ ì¥ì†Œë“¤ì˜ ì´ë¯¸ì§€ ë²¡í„° ìˆ˜ì§‘
            bookmark_query = """
                SELECT pr.image_vector
                FROM saved_locations sl
                JOIN place_recommendations pr ON pr.place_id = CAST(SPLIT_PART(sl.places, ':', 2) AS INTEGER)
                    AND pr.table_name = SPLIT_PART(sl.places, ':', 1)
                WHERE sl.user_id = $1
                    AND pr.image_vector IS NOT NULL
                LIMIT 20
            """

            # 2. ì¢‹ì•„ìš”í•œ í¬ìŠ¤íŠ¸ë“¤ì˜ ì´ë¯¸ì§€ ë²¡í„° ìˆ˜ì§‘ (posts.image_vectorëŠ” PostgreSQL vector íƒ€ì…)
            liked_posts_query = """
                SELECT p.image_vector
                FROM user_actions ua
                JOIN posts p ON p.id = CAST(ua.place_id AS INTEGER)
                WHERE ua.user_id = $1
                    AND ua.action_type = 'like'
                    AND ua.place_category = 'posts'
                    AND p.image_vector IS NOT NULL
                LIMIT 20
            """

            # 3. ì‚¬ìš©ìê°€ ì§ì ‘ ì—…ë¡œë“œí•œ í¬ìŠ¤íŠ¸ë“¤ì˜ ì´ë¯¸ì§€ ë²¡í„° ìˆ˜ì§‘ (ìì‹ ì˜ ì„ í˜¸ë„ ë°˜ì˜)
            user_posts_query = """
                SELECT image_vector
                FROM posts
                WHERE user_id = $1
                    AND image_vector IS NOT NULL
                LIMIT 30
            """

            bookmark_vectors = await self.db_manager.execute_query(bookmark_query, user_id)
            liked_post_vectors = await self.db_manager.execute_query(liked_posts_query, user_id)
            user_post_vectors = await self.db_manager.execute_query(user_posts_query, user_id)

            # ë²¡í„° ìˆ˜ì§‘ ë° ê²€ì¦ (ë¶„ë¦¬ëœ ë¦¬ìŠ¤íŠ¸ë¡œ)
            bookmark_image_vectors = []
            liked_post_image_vectors = []
            user_upload_image_vectors = []

            # 1. ë¶ë§ˆí¬í•œ ì¥ì†Œ ì´ë¯¸ì§€ ë²¡í„°
            for row in bookmark_vectors:
                vector = validate_vector_data(row['image_vector'])
                if vector is not None:
                    bookmark_image_vectors.append(vector)

            # 2. ì¢‹ì•„ìš”í•œ í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ ë²¡í„° (ë…ë¦½ì ìœ¼ë¡œ ìˆ˜ì§‘)
            for row in liked_post_vectors:
                vector = validate_vector_data(row['image_vector'])
                if vector is not None:
                    liked_post_image_vectors.append(vector)

            # 3. ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ ë²¡í„° (ë…ë¦½ì ìœ¼ë¡œ ìˆ˜ì§‘)
            for row in user_post_vectors:
                vector = validate_vector_data(row['image_vector'])
                if vector is not None:
                    user_upload_image_vectors.append(vector)

            total_vectors = len(bookmark_image_vectors) + len(liked_post_image_vectors) + len(user_upload_image_vectors)

            if total_vectors == 0:
                logger.info(f"No image preferences found for user {user_id}")
                return {}

            logger.info(f"ğŸ“¸ User {user_id} image preferences: {total_vectors} total vectors (ë¶ë§ˆí¬: {len(bookmark_image_vectors)}, ì¢‹ì•„ìš”: {len(liked_post_image_vectors)}, ì—…ë¡œë“œ: {len(user_upload_image_vectors)})")

            return {
                'bookmarks': bookmark_image_vectors,       # ë¶ë§ˆí¬ ì¥ì†Œ ì´ë¯¸ì§€ (ì±„ë„4 ì‚¬ìš©)
                'liked_posts': liked_post_image_vectors,   # ì¢‹ì•„ìš” í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ (ì±„ë„5 ì‚¬ìš©)
                'user_uploads': user_upload_image_vectors, # ì—…ë¡œë“œ í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ (ì±„ë„2 ì‚¬ìš©)
                'source_breakdown': {
                    'bookmarks': len(bookmark_image_vectors),
                    'liked_posts': len(liked_post_image_vectors),
                    'user_posts': len(user_upload_image_vectors)
                }
            }

        except Exception as e:
            logger.error(f"âŒ Failed to get user image preferences for {user_id}: {e}")
            return {}

    async def _calculate_independent_similarities(
        self,
        user_id: str,
        user_behavior_vector: np.ndarray,
        user_image_preferences: Dict[str, Any],
        places: List[Dict]
    ) -> List[Dict[str, float]]:
        """
        ë…ë¦½ì ì¸ ê²€ìƒ‰ ì±„ë„ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° (5ê°œ ì±„ë„)
        1. í–‰ë™ë²¡í„°(í´ë¦­/ë¶ë§ˆí¬) â†’ ì¥ì†Œ í…ìŠ¤íŠ¸
        2. ì‚¬ìš©ì ì—…ë¡œë“œ í¬ìŠ¤íŒ… ì´ë¯¸ì§€ â†’ ì¥ì†Œ ì´ë¯¸ì§€
        3. ë¶ë§ˆí¬ ì¥ì†Œ í…ìŠ¤íŠ¸ â†’ ë‹¤ë¥¸ ì¥ì†Œ í…ìŠ¤íŠ¸
        4. ë¶ë§ˆí¬ ì¥ì†Œ ì´ë¯¸ì§€ â†’ ë‹¤ë¥¸ ì¥ì†Œ ì´ë¯¸ì§€
        5. ì¢‹ì•„ìš”í•œ í¬ìŠ¤íŒ… ì´ë¯¸ì§€ â†’ ì¥ì†Œ ì´ë¯¸ì§€
        """
        results = []

        try:
            # ì´ë¯¸ì§€ ì„ í˜¸ë„ ë¶„ë¦¬ (ì—…ë¡œë“œ vs ì¢‹ì•„ìš”)
            user_upload_images = user_image_preferences.get('user_uploads', [])
            liked_post_images = user_image_preferences.get('liked_posts', [])

            # í‰ê·  ë²¡í„° ê³„ì‚° (ì•ˆì „í•œ ì²˜ë¦¬)
            user_upload_vector = None
            if user_upload_images and len(user_upload_images) > 0:
                try:
                    user_upload_vector = np.mean(user_upload_images, axis=0)
                except Exception as e:
                    logger.warning(f"Failed to calculate user upload vector mean: {e}")

            liked_posts_vector = None
            if liked_post_images and len(liked_post_images) > 0:
                try:
                    liked_posts_vector = np.mean(liked_post_images, axis=0)
                except Exception as e:
                    logger.warning(f"Failed to calculate liked posts vector mean: {e}")

            # ì‚¬ìš©ì ë¶ë§ˆí¬ ì¥ì†Œ ê¸°ë°˜ ì„ í˜¸ë„ ì¶”ì¶œ
            bookmark_preferences = await self._get_detailed_bookmark_preferences(user_id)

            for place in places:
                scores = {
                    'behavior_text_similarity': 0.0,     # í–‰ë™ë²¡í„°(í´ë¦­/ë¶ë§ˆí¬) â†’ ì¥ì†Œí…ìŠ¤íŠ¸
                    'upload_image_similarity': 0.0,      # ì—…ë¡œë“œ í¬ìŠ¤íŒ…ì´ë¯¸ì§€ â†’ ì¥ì†Œì´ë¯¸ì§€
                    'bookmark_text_similarity': 0.0,     # ë¶ë§ˆí¬ì¥ì†Œí…ìŠ¤íŠ¸ â†’ ì¥ì†Œí…ìŠ¤íŠ¸
                    'bookmark_image_similarity': 0.0,    # ë¶ë§ˆí¬ì¥ì†Œì´ë¯¸ì§€ â†’ ì¥ì†Œì´ë¯¸ì§€
                    'liked_post_similarity': 0.0,        # ì¢‹ì•„ìš” í¬ìŠ¤íŒ…ì´ë¯¸ì§€ â†’ ì¥ì†Œì´ë¯¸ì§€
                    'combined_score': 0.0
                }

                # 1. í–‰ë™ ë²¡í„°(í´ë¦­/ë¶ë§ˆí¬) â†’ ì¥ì†Œ í…ìŠ¤íŠ¸ (384ì°¨ì›)
                place_text_vector = place.get('text_vector')
                if place_text_vector is not None and user_behavior_vector is not None:
                    text_sim = safe_cosine_similarity(user_behavior_vector, place_text_vector)
                    scores['behavior_text_similarity'] = float(text_sim[0]) if len(text_sim) > 0 else 0.0

                # 2. ì—…ë¡œë“œ í¬ìŠ¤íŒ… ì´ë¯¸ì§€ â†’ ì¥ì†Œ ì´ë¯¸ì§€ (512ì°¨ì›)
                place_image_vector = place.get('image_vector')
                if user_upload_vector is not None and place_image_vector is not None:
                    upload_sim = safe_cosine_similarity(user_upload_vector, place_image_vector)
                    scores['upload_image_similarity'] = float(upload_sim[0]) if len(upload_sim) > 0 else 0.0

                # 3. ë¶ë§ˆí¬ ì¥ì†Œ í…ìŠ¤íŠ¸ â†’ ì¥ì†Œ í…ìŠ¤íŠ¸ (384ì°¨ì›)
                if bookmark_preferences.get('avg_text_vector') is not None and place_text_vector is not None:
                    bookmark_text_sim = safe_cosine_similarity(
                        bookmark_preferences['avg_text_vector'], place_text_vector
                    )
                    scores['bookmark_text_similarity'] = float(bookmark_text_sim[0]) if len(bookmark_text_sim) > 0 else 0.0

                # 4. ë¶ë§ˆí¬ ì¥ì†Œ ì´ë¯¸ì§€ â†’ ì¥ì†Œ ì´ë¯¸ì§€ (512ì°¨ì›)
                if bookmark_preferences.get('avg_image_vector') is not None and place_image_vector is not None:
                    bookmark_image_sim = safe_cosine_similarity(
                        bookmark_preferences['avg_image_vector'], place_image_vector
                    )
                    scores['bookmark_image_similarity'] = float(bookmark_image_sim[0]) if len(bookmark_image_sim) > 0 else 0.0

                # 5. ì¢‹ì•„ìš”í•œ í¬ìŠ¤íŒ… ì´ë¯¸ì§€ â†’ ì¥ì†Œ ì´ë¯¸ì§€ (512ì°¨ì›)
                if liked_posts_vector is not None and place_image_vector is not None:
                    liked_sim = safe_cosine_similarity(liked_posts_vector, place_image_vector)
                    scores['liked_post_similarity'] = float(liked_sim[0]) if len(liked_sim) > 0 else 0.0

                # 6. 5ê°œ ë…ë¦½ì  ì±„ë„ë“¤ì˜ ì¡°í•© ì ìˆ˜ ê³„ì‚°
                channel_scores = [
                    scores['behavior_text_similarity'] * 0.25,     # í–‰ë™ê¸°ë°˜ í…ìŠ¤íŠ¸
                    scores['upload_image_similarity'] * 0.25,      # ì—…ë¡œë“œ í¬ìŠ¤íŒ… ì´ë¯¸ì§€
                    scores['bookmark_text_similarity'] * 0.2,      # ë¶ë§ˆí¬ í…ìŠ¤íŠ¸
                    scores['bookmark_image_similarity'] * 0.15,    # ë¶ë§ˆí¬ ì´ë¯¸ì§€
                    scores['liked_post_similarity'] * 0.15         # ì¢‹ì•„ìš” í¬ìŠ¤íŒ… ì´ë¯¸ì§€
                ]

                # ìœ íš¨í•œ ì±„ë„ë“¤ë§Œ ì¡°í•©
                valid_scores = [score for score in channel_scores if score > 0]
                if valid_scores:
                    scores['combined_score'] = sum(valid_scores) / len(valid_scores)
                    # ë‹¤ì¤‘ ì±„ë„ ë³´ë„ˆìŠ¤
                    if len(valid_scores) > 1:
                        scores['combined_score'] += 0.1 * (len(valid_scores) - 1)
                else:
                    scores['combined_score'] = 0.0

                results.append(scores)

            logger.info(f"ğŸ”„ Calculated independent channel similarities for {len(results)} places")
            return results

        except Exception as e:
            logger.error(f"âŒ Independent similarity calculation failed: {e}")
            # ë¹ˆ ì ìˆ˜ ë°˜í™˜
            return [{
                'behavior_text_similarity': 0.0,
                'upload_image_similarity': 0.0,
                'bookmark_text_similarity': 0.0,
                'bookmark_image_similarity': 0.0,
                'liked_post_similarity': 0.0,
                'combined_score': 0.0
            } for _ in places]

    async def _get_detailed_bookmark_preferences(self, user_id: str) -> Dict[str, np.ndarray]:
        """ë¶ë§ˆí¬í•œ ì¥ì†Œë“¤ì˜ ìƒì„¸ ë²¡í„° ì„ í˜¸ë„ ì¶”ì¶œ"""
        try:
            # ë¶ë§ˆí¬í•œ ì¥ì†Œë“¤ì˜ í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ë²¡í„° ì¡°íšŒ
            query = """
                SELECT pr.vector as text_vector, pr.image_vector
                FROM saved_locations sl
                JOIN place_recommendations pr ON pr.place_id = CAST(SPLIT_PART(sl.places, ':', 2) AS INTEGER)
                    AND pr.table_name = SPLIT_PART(sl.places, ':', 1)
                WHERE sl.user_id = $1
                    AND (pr.vector IS NOT NULL OR pr.image_vector IS NOT NULL)
                LIMIT 30
            """

            bookmark_data = await self.db_manager.execute_query(query, user_id)

            text_vectors = []
            image_vectors = []

            for row in bookmark_data:
                # í…ìŠ¤íŠ¸ ë²¡í„° ìˆ˜ì§‘
                if row['text_vector']:
                    text_vector = validate_vector_data(row['text_vector'])
                    if text_vector is not None:
                        text_vectors.append(text_vector)

                # ì´ë¯¸ì§€ ë²¡í„° ìˆ˜ì§‘
                if row['image_vector']:
                    image_vector = validate_vector_data(row['image_vector'])
                    if image_vector is not None:
                        image_vectors.append(image_vector)

            result = {}

            # í‰ê·  í…ìŠ¤íŠ¸ ë²¡í„° ê³„ì‚° (ì•ˆì „í•œ ì²˜ë¦¬)
            if text_vectors and len(text_vectors) > 0:
                try:
                    result['avg_text_vector'] = np.mean(text_vectors, axis=0)
                except Exception as e:
                    logger.warning(f"Failed to calculate avg text vector: {e}")

            # í‰ê·  ì´ë¯¸ì§€ ë²¡í„° ê³„ì‚° (ì•ˆì „í•œ ì²˜ë¦¬)
            if image_vectors and len(image_vectors) > 0:
                try:
                    result['avg_image_vector'] = np.mean(image_vectors, axis=0)
                except Exception as e:
                    logger.warning(f"Failed to calculate avg image vector: {e}")

            logger.info(f"ğŸ“š User {user_id} bookmark preferences: {len(text_vectors)} text, {len(image_vectors)} image vectors")
            return result

        except Exception as e:
            logger.error(f"âŒ Failed to get detailed bookmark preferences for {user_id}: {e}")
            return {}


# ============================================================================
# ğŸš€ ì „ì—­ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
# ============================================================================

_engine_instance: Optional[UnifiedRecommendationEngine] = None

async def get_engine() -> UnifiedRecommendationEngine:
    """ì „ì—­ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì§€ì—° ì´ˆê¸°í™”)"""
    global _engine_instance

    if _engine_instance is None:
        _engine_instance = UnifiedRecommendationEngine()
        await _engine_instance.initialize()

    return _engine_instance

async def close_engine():
    """ì „ì—­ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬"""
    global _engine_instance

    if _engine_instance:
        await _engine_instance.close()
        _engine_instance = None


