# íŒŒì¼ëª…: vectorization2.py (ì™„ì „ ê°œì„  ë²„ì „)

import numpy as np
import asyncpg
import asyncio
import logging
from typing import Dict, List, Any, Optional
from contextlib import asynccontextmanager
from dataclasses import dataclass
import json
import time

# í†µí•© ì„¤ì • íŒŒì¼ ì‚¬ìš© (backend í™˜ê²½ ëŒ€ì‘)
try:
    from recommendation_config import config as CONFIG
except ImportError:
    try:
        from .recommendation_config import config as CONFIG
    except ImportError:
        # Fallback ì„¤ì •
        from dataclasses import dataclass
        @dataclass
        class FallbackConfig:
            database_url: str = "postgresql://user:pass@localhost/db"
            min_pool_size: int = 3
            max_pool_size: int = 15
            db_timeout: int = 5
            candidate_limit: int = 2000
            similarity_weight: float = 0.5
            popularity_weight: float = 0.5
            min_similarity_threshold: float = 0.1
            vector_cache_size: int = 1000
            cache_ttl_seconds: int = 300
            action_weights: Dict[str, float] = None
            preference_weights: Dict[str, float] = None
            travel_style_bonuses: Dict[str, Dict[str, float]] = None
            def __post_init__(self):
                if self.action_weights is None:
                    self.action_weights = {'click': 1.0, 'like': 3.0, 'bookmark': 5.0}
                if self.preference_weights is None:
                    self.preference_weights = {'region': 0.4, 'category': 0.3, 'tag': 0.3, 'max_tag_score': 10.0, 'popularity_normalizer': 1000.0}
                if self.travel_style_bonuses is None:
                    self.travel_style_bonuses = {'luxury': {'accommodation': 0.1, 'restaurants': 0.1}}
        CONFIG = FallbackConfig()
        CONFIG.__post_init__()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# ğŸ”§ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ============================================================================

def safe_cosine_similarity(X: np.ndarray, Y: np.ndarray) -> np.ndarray:
    """ì•ˆì „í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ì„±ëŠ¥ ìµœì í™” ë²„ì „)"""
    try:
        # None ê°’ ê²€ì¦
        if X is None or Y is None:
            return np.array([0.0])

        # ì…ë ¥ì„ numpy ë°°ì—´ë¡œ ë³€í™˜ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
        X = np.asarray(X, dtype=np.float32)
        Y = np.asarray(Y, dtype=np.float32)

        # ë¹ˆ ë°°ì—´ ê²€ì¦
        if X.size == 0 or Y.size == 0:
            return np.array([0.0])

        # ì°¨ì› ë§ì¶”ê¸°
        if X.ndim == 1:
            X = X.reshape(1, -1)
        if Y.ndim == 1:
            Y = Y.reshape(1, -1)

        # ì°¨ì› ì¼ì¹˜ í™•ì¸
        if X.shape[1] != Y.shape[1]:
            logger.warning(f"Vector dimension mismatch: X={X.shape[1]}, Y={Y.shape[1]}")
            return np.zeros(Y.shape[0])

        # ë²¡í„°í™”ëœ NaN/Inf ì²˜ë¦¬ (ë” ë¹ ë¦„)
        X = np.nan_to_num(X, nan=0.0, posinf=1.0, neginf=-1.0)
        Y = np.nan_to_num(Y, nan=0.0, posinf=1.0, neginf=-1.0)

        # L2 norm ê³„ì‚° (axis=1ì—ì„œ keepdims=Trueë¡œ íš¨ìœ¨ì )
        X_norm = np.linalg.norm(X, axis=1, keepdims=True)
        Y_norm = np.linalg.norm(Y, axis=1, keepdims=True)

        # 0 ë²¡í„° ë§ˆìŠ¤í¬ ìƒì„± (í•œ ë²ˆì— ì²˜ë¦¬)
        zero_mask_X = (X_norm == 0).flatten()
        zero_mask_Y = (Y_norm == 0).flatten()

        if np.any(zero_mask_X) or np.any(zero_mask_Y):
            return np.zeros(Y.shape[0])

        # ì •ê·œí™” (in-place ì—°ì‚°ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½)
        X = X / X_norm
        Y = Y / Y_norm

        # í–‰ë ¬ ê³± (ê°€ì¥ íš¨ìœ¨ì ì¸ ë°©ë²•)
        similarities = np.einsum('ij,kj->ik', X, Y).flatten()

        # ìµœì¢… NaN/Inf ê°’ ì²˜ë¦¬
        similarities = np.nan_to_num(similarities, nan=0.0, posinf=1.0, neginf=-1.0)

        # ìœ ì‚¬ë„ ë²”ìœ„ í´ë¦¬í•‘ (-1 ~ 1)
        similarities = np.clip(similarities, -1.0, 1.0)

        return similarities

    except Exception as e:
        logger.error(f"âŒ Cosine similarity calculation failed: {e}")
        # ì•ˆì „í•œ ê¸°ë³¸ê°’ ë°˜í™˜
        try:
            return np.zeros(Y.shape[0] if hasattr(Y, 'shape') and Y.ndim > 1 else 1)
        except:
            return np.array([0.0])


def calculate_weighted_popularity_score(place_data: Dict[str, int]) -> float:
    """ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì¸ê¸°ë„ ì ìˆ˜ ê³„ì‚° (ê°œì„ ëœ ì •ê·œí™”)"""
    try:
        weighted_score = (
            place_data.get('total_clicks', 0) * CONFIG.action_weights['click'] +
            place_data.get('total_likes', 0) * CONFIG.action_weights['like'] +
            place_data.get('total_bookmarks', 0) * CONFIG.action_weights['bookmark']
        )

        # ë™ì  ì •ê·œí™” (ìƒìœ„ 1% ê¸°ì¤€ì  ì‚¬ìš©)
        reference_score = 100  # ê¸°ë³¸ ê¸°ì¤€ì , ì‹¤ì œë¡œëŠ” í†µê³„ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ê³„ì‚° ê°€ëŠ¥
        normalized_score = min((weighted_score / reference_score) * 100, 100)

        return round(normalized_score, 2)

    except Exception as e:
        logger.error(f"âŒ Popularity score calculation failed: {e}")
        return 0.0


def calculate_engagement_score(place_data: Dict[str, int]) -> float:
    """ì°¸ì—¬ë„ ì ìˆ˜ ê³„ì‚° (like/bookmark ë¹„ìœ¨ ê¸°ë°˜)"""
    try:
        total_interactions = (
            place_data.get('total_clicks', 0) +
            place_data.get('total_likes', 0) +
            place_data.get('total_bookmarks', 0)
        )

        if total_interactions == 0:
            return 0.0

        high_value_actions = place_data.get('total_likes', 0) + place_data.get('total_bookmarks', 0)
        engagement_ratio = high_value_actions / total_interactions

        # ì ˆëŒ€ê°’ ë³´ì • ì¶”ê°€
        min_threshold_bonus = min(high_value_actions * 2, 20)  # ìµœëŒ€ 20ì  ë³´ë„ˆìŠ¤
        final_score = min((engagement_ratio * 100) + min_threshold_bonus, 100)

        return round(final_score, 2)

    except Exception as e:
        logger.error(f"âŒ Engagement score calculation failed: {e}")
        return 0.0


def validate_vector_data(vector_data: Any) -> Optional[np.ndarray]:
    """ë²¡í„° ë°ì´í„° ê²€ì¦ ë° ë³€í™˜ (PostgreSQL vector íƒ€ì… ë° ARRAY íƒ€ì… ì§€ì›)"""
    try:
        if vector_data is None:
            return None

        # PostgreSQL ARRAY íƒ€ì… ì²˜ë¦¬ (user_behavior_vectors.behavior_vector)
        if isinstance(vector_data, list):
            vector = np.array(vector_data, dtype=np.float32)

        # PostgreSQL vector íƒ€ì… ë¬¸ìì—´ ì²˜ë¦¬ (place_recommendations.vector, posts.image_vector)
        elif isinstance(vector_data, str):
            # vector íƒ€ì…ì€ "[1,2,3]" í˜•íƒœì˜ ë¬¸ìì—´
            if vector_data.startswith('[') and vector_data.endswith(']'):
                # PostgreSQL vector íƒ€ì… íŒŒì‹±
                vector_str = vector_data.strip('[]')
                if vector_str:
                    vector_list = [float(x.strip()) for x in vector_str.split(',')]
                    vector = np.array(vector_list, dtype=np.float32)
                else:
                    return None
            else:
                # JSON ë¬¸ìì—´ ì‹œë„
                vector_data = json.loads(vector_data)
                vector = np.array(vector_data, dtype=np.float32)

        # ì´ë¯¸ numpy ë°°ì—´ì¸ ê²½ìš°
        elif isinstance(vector_data, np.ndarray):
            vector = vector_data.astype(np.float32)

        # ê¸°íƒ€ ìˆ«ì íƒ€ì…
        else:
            vector = np.array(vector_data, dtype=np.float32)

        # ì°¨ì› ë° ìœ íš¨ì„± ê²€ì‚¬
        if vector.size == 0:
            return None

        if np.isnan(vector).any() or np.isinf(vector).any():
            logger.warning("Vector contains NaN or Inf values")
            return None

        return vector

    except Exception as e:
        logger.error(f"âŒ Vector validation failed: {e}")
        return None


# ============================================================================
# ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤
# ============================================================================

class DatabaseManager:
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ì¿¼ë¦¬ ê´€ë¦¬"""

    def __init__(self, database_url: str):
        self.database_url = database_url
        self.pool = None
        self._initialized = False

    async def initialize(self):
        """Connection Pool ì´ˆê¸°í™”"""
        try:
            self.pool = await asyncpg.create_pool(
                self.database_url,
                min_size=CONFIG.min_pool_size,
                max_size=CONFIG.max_pool_size,
                command_timeout=CONFIG.db_timeout,
                server_settings={
                    'application_name': 'unified_recommendation_engine',
                    'tcp_keepalives_idle': '60',    # TCP keepalive ì„¤ì •
                    'tcp_keepalives_interval': '30',
                    'tcp_keepalives_count': '3'
                },
                # ê³ ê¸‰ ìµœì í™” ì„¤ì •
                setup=self._setup_connection if hasattr(CONFIG, 'pool_pre_ping') and CONFIG.pool_pre_ping else None
            )
            self._initialized = True
            logger.info(f"âœ… Database pool initialized: {CONFIG.min_pool_size}-{CONFIG.max_pool_size} connections")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize database pool: {e}")
            raise

    async def _setup_connection(self, connection):
        """ì—°ê²° ì´ˆê¸° ì„¤ì • (ì„±ëŠ¥ ìµœì í™”)"""
        try:
            await connection.execute("SET work_mem = '64MB'")  # ì‘ì—… ë©”ëª¨ë¦¬ ì¦ê°€
            await connection.execute("SET random_page_cost = 1.1")  # SSD ìµœì í™”
            await connection.execute("SET effective_cache_size = '512MB'")  # ìºì‹œ í¬ê¸°
        except Exception as e:
            logger.warning(f"Connection setup optimization failed: {e}")

    async def close(self):
        """Connection Pool ì •ë¦¬"""
        if self.pool:
            await self.pool.close()
            logger.info("ğŸ”Œ Database pool closed")

    @asynccontextmanager
    async def get_connection(self):
        """ì•ˆì „í•œ DB ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        if not self._initialized or not self.pool:
            raise RuntimeError("Database pool not initialized. Call initialize() first.")

        connection = None
        try:
            connection = await self.pool.acquire()
            yield connection
        except Exception as e:
            logger.error(f"âŒ Database connection error: {e}")
            raise
        finally:
            if connection:
                await self.pool.release(connection)

    async def execute_query(self, query: str, *args) -> List[Dict]:
        """ì•ˆì „í•œ ì¿¼ë¦¬ ì‹¤í–‰"""
        async with self.get_connection() as conn:
            try:
                result = await conn.fetch(query, *args)
                return [dict(row) for row in result]
            except Exception as e:
                logger.error(f"âŒ Query execution failed: {query[:100]}... Error: {e}")
                raise

    async def execute_single_query(self, query: str, *args) -> Optional[Any]:
        """ë‹¨ì¼ ê°’ ì¿¼ë¦¬ ì‹¤í–‰"""
        async with self.get_connection() as conn:
            try:
                return await conn.fetchval(query, *args)
            except Exception as e:
                logger.error(f"âŒ Single query execution failed: {query[:100]}... Error: {e}")
                raise


# ============================================================================
# ğŸ¯ í†µí•© ì¶”ì²œ ì—”ì§„ (ì™„ì „ ê°œì„  ë²„ì „)
# ============================================================================

class UnifiedRecommendationEngine:
    """
    ì™„ì „íˆ ê°œì„ ëœ í†µí•© ì¶”ì²œ ì—”ì§„
    - Connection Pool ê´€ë¦¬
    - ë²¡í„° ìºì‹±
    - ì—ëŸ¬ ë³µêµ¬
    - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    """

    def __init__(self, database_url: Optional[str] = None):
        self.database_url = database_url or CONFIG.database_url
        self.db_manager = DatabaseManager(self.database_url)

        # ê³„ì¸µì  ìºì‹± ì‹œìŠ¤í…œ (ê°œì„ )
        self.vector_cache: Dict[str, Dict] = {}  # ê¸°ë³¸ ë²¡í„° ìºì‹œ
        self.cache_timestamps: Dict[str, float] = {}

        # ì „ìš© ìºì‹œë“¤ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
        self.user_data_cache: Dict[str, Dict] = {}  # ì‚¬ìš©ì í†µí•© ë°ì´í„°
        self.user_data_timestamps: Dict[str, float] = {}

        self.place_batch_cache: Dict[str, List[Dict]] = {}  # ì¥ì†Œ ë°°ì¹˜ ë°ì´í„°
        self.place_batch_timestamps: Dict[str, float] = {}

        self.similarity_cache: Dict[str, np.ndarray] = {}  # ìœ ì‚¬ë„ ê²°ê³¼
        self.similarity_timestamps: Dict[str, float] = {}

        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            'total_requests': 0,
            'cache_hits': 0,
            'personalized_requests': 0,
            'popular_requests': 0,
            'avg_response_time': 0.0
        }

    def _convert_s3_urls_to_https(self, place: Dict) -> Dict:
        """ì´ë¯¸ì§€ URLì„ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (DBì˜ ë‹¤ì–‘í•œ í˜•íƒœ ì²˜ë¦¬)"""
        if not place.get('image_urls'):
            return place

        try:
            image_urls = place['image_urls']

            # 1. JSON ë°°ì—´ ë¬¸ìì—´ í˜•íƒœ: ["url1", "url2"]
            if isinstance(image_urls, str) and image_urls.startswith('['):
                import json
                urls_list = json.loads(image_urls)
                place['image_urls'] = urls_list
                logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ URL ë³€í™˜ ì™„ë£Œ - ì¥ì†Œ: {place.get('name')}, URLs: {len(urls_list)}ê°œ")

            # 2. PostgreSQL ë°°ì—´ í˜•íƒœ: {url1,url2,url3}
            elif isinstance(image_urls, str) and image_urls.startswith('{'):
                urls_str = image_urls.strip('{}')
                if urls_str:
                    urls = [url.strip().strip('"') for url in urls_str.split(',')]
                    https_urls = []
                    for url in urls:
                        if url.startswith('s3://'):
                            # S3 URLì„ HTTPSë¡œ ë³€í™˜
                            bucket = url.split('/')[2]
                            key = '/'.join(url.split('/')[3:])
                            https_url = f"https://{bucket}.s3.ap-northeast-2.amazonaws.com/{key}"
                            https_urls.append(https_url)
                        else:
                            https_urls.append(url)
                    place['image_urls'] = https_urls
                else:
                    place['image_urls'] = []

            # 3. ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
            elif isinstance(image_urls, list):
                https_urls = []
                for url in image_urls:
                    if url and url.startswith('s3://'):
                        bucket = url.split('/')[2]
                        key = '/'.join(url.split('/')[3:])
                        https_url = f"https://{bucket}.s3.ap-northeast-2.amazonaws.com/{key}"
                        https_urls.append(https_url)
                    else:
                        https_urls.append(url)
                place['image_urls'] = https_urls

            # 4. ë‹¨ì¼ ë¬¸ìì—´ì¸ ê²½ìš° (ë°°ì—´ì´ ì•„ë‹Œ)
            elif isinstance(image_urls, str) and (image_urls.startswith('http') or image_urls.startswith('s3://')):
                if image_urls.startswith('s3://'):
                    bucket = image_urls.split('/')[2]
                    key = '/'.join(image_urls.split('/')[3:])
                    https_url = f"https://{bucket}.s3.ap-northeast-2.amazonaws.com/{key}"
                    place['image_urls'] = [https_url]
                else:
                    place['image_urls'] = [image_urls]
            else:
                # ì•Œ ìˆ˜ ì—†ëŠ” í˜•íƒœ
                logger.warning(f"Unknown image_urls format for place {place.get('place_id')}: {type(image_urls)} - {str(image_urls)[:100]}")
                place['image_urls'] = []

        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ URL ë³€í™˜ ì‹¤íŒ¨ for place {place.get('place_id')}: {e}")
            place['image_urls'] = []

        return place

        logger.info("ğŸš€ UnifiedRecommendationEngine v2.0 initialized")

    async def initialize(self):
        """ì—”ì§„ ì´ˆê¸°í™” (ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ í˜¸ì¶œ)"""
        await self.db_manager.initialize()
        logger.info("âœ… Recommendation engine fully initialized")

    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        await self.db_manager.close()
        self.vector_cache.clear()
        self.cache_timestamps.clear()
        logger.info("ğŸ”Œ Recommendation engine closed")

    def _is_cache_valid(self, cache_key: str, cache_type: str = 'vector') -> bool:
        """ê³„ì¸µì  ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬"""
        timestamps = {
            'vector': self.cache_timestamps,
            'user_data': self.user_data_timestamps,
            'place_batch': self.place_batch_timestamps,
            'similarity': self.similarity_timestamps
        }

        if cache_key not in timestamps.get(cache_type, {}):
            return False

        age = time.time() - timestamps[cache_type][cache_key]
        return age < CONFIG.cache_ttl_seconds

    def _update_cache(self, cache_key: str, data: Any, cache_type: str = 'vector'):
        """ê³„ì¸µì  ìºì‹œ ì—…ë°ì´íŠ¸ (LRU ì „ëµ)"""
        cache_configs = {
            'vector': (self.vector_cache, self.cache_timestamps, CONFIG.vector_cache_size),
            'user_data': (self.user_data_cache, self.user_data_timestamps, CONFIG.user_data_cache_size),
            'place_batch': (self.place_batch_cache, self.place_batch_timestamps, CONFIG.place_batch_cache_size),
            'similarity': (self.similarity_cache, self.similarity_timestamps, CONFIG.similarity_cache_size)
        }

        cache, timestamps, max_size = cache_configs.get(cache_type, cache_configs['vector'])

        # LRU ì œê±°
        if len(cache) >= max_size:
            oldest_key = min(timestamps.keys(), key=lambda k: timestamps[k])
            del cache[oldest_key]
            del timestamps[oldest_key]

        cache[cache_key] = data
        timestamps[cache_key] = time.time()

    async def get_recommendations(
        self,
        user_id: Optional[str],
        region: Optional[str] = None,
        category: Optional[str] = None,
        limit: int = 20,
        fast_mode: bool = False  # ë©”ì¸ í˜ì´ì§€ìš© ê³ ì† ëª¨ë“œ
    ) -> List[Dict]:
        """
        ë©”ì¸ ì¶”ì²œ API (ë™ì  ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ ì ìš©)
        - ì‹ ê·œ ê°€ì…ì: ìš°ì„ ìˆœìœ„ ì„ í˜¸ë„ íƒœê·¸ 100%
        - í–‰ë™ ë°ì´í„° ìˆëŠ” ì‚¬ìš©ì: ìš°ì„ ìˆœìœ„ 70%, í–‰ë™ ë°ì´í„° 30%
        """
        start_time = time.time()
        self.stats['total_requests'] += 1

        try:
            # íŒŒë¼ë¯¸í„° ê²€ì¦
            limit = max(1, min(limit, 100))  # 1-100 ì‚¬ì´ë¡œ ì œí•œ

            if not user_id:
                # ë¹„ë¡œê·¸ì¸ ì‚¬ìš©ì: ì¸ê¸° ì¶”ì²œë§Œ
                logger.info("ğŸŒŸ Popular recommendations for anonymous user")
                self.stats['popular_requests'] += 1
                return await self._get_popular_recommendations(region, category, limit, fast_mode)

            # ëª¨ë“  ë¡œê·¸ì¸ ì‚¬ìš©ìì—ê²Œ ì§€ì—­ë³„ ì„ í˜¸ë„ ì¶”ì²œ ì ìš©
            logger.info(f"ğŸŒ Regional preference recommendations for user {user_id}")

            # ì§€ì—­ ì§€ì • ì—¬ë¶€ì— ë”°ë¼ ë¶„ê¸°
            if region:
                # íŠ¹ì • ì§€ì—­ ì§€ì •ì‹œ: í•´ë‹¹ ì§€ì—­ ë‚´ ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ì²œ
                logger.info(f"ğŸ¯ Regional preference recommendations for user {user_id} in {region}")
                result = await self._get_preference_based_recommendations(user_id, region, category, limit)
                if not result:
                    # ì„ í˜¸ë„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¸ê¸° ì¶”ì²œìœ¼ë¡œ í´ë°±
                    logger.info(f"ğŸ“Š Fallback to popular recommendations for user {user_id}")
                    result = await self._get_popular_recommendations(region, category, limit, fast_mode)
            else:
                # ì§€ì—­ ì§€ì • ì—†ì„ ë•Œ: ëª¨ë“  ì§€ì—­ì„ ëŒ€ìƒìœ¼ë¡œ ì§€ì—­ë³„ ì„ í˜¸ë„ ì¶”ì²œ
                logger.info(f"ğŸŒ All regions preference recommendations for user {user_id}")
                result = await self._get_regional_preference_recommendations(user_id, limit)
                if not result:
                    # ì„ í˜¸ë„ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¸ê¸° ì¶”ì²œìœ¼ë¡œ í´ë°±
                    logger.info(f"ğŸ“Š Fallback to popular recommendations for user {user_id}")
                    result = await self._get_popular_recommendations(region, category, limit, fast_mode)

            # ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸
            response_time = time.time() - start_time
            self._update_response_time(response_time)

            logger.info(f"âœ… Returned {len(result)} recommendations in {response_time:.3f}s")
            return result

        except Exception as e:
            logger.error(f"âŒ Recommendation failed: {e}")
            # ë¹ˆ ê²°ê³¼ë¼ë„ ì•ˆì „í•˜ê²Œ ë°˜í™˜
            return []

    async def _get_comprehensive_user_data_cached(self, user_id: str) -> Dict[str, Any]:
        """ìºì‹œëœ ì‚¬ìš©ì í†µí•© ë°ì´í„° ì¡°íšŒ (DB í˜¸ì¶œ ìµœì†Œí™”)"""
        cache_key = f"user_comprehensive:{user_id}"

        # ìºì‹œ í™•ì¸
        if self._is_cache_valid(cache_key, 'user_data'):
            self.stats['cache_hits'] += 1
            return self.user_data_cache[cache_key]

        # ìºì‹œ ë¯¸ìŠ¤ ì‹œ DBì—ì„œ ì¡°íšŒ
        comprehensive_data = await self._get_comprehensive_user_data(user_id)
        self._update_cache(cache_key, comprehensive_data, 'user_data')
        return comprehensive_data

    async def _get_comprehensive_user_data(self, user_id: str) -> Dict[str, Any]:
        """
        í†µí•© ì‚¬ìš©ì ë°ì´í„° ì¡°íšŒ (DB í˜¸ì¶œ ìµœì†Œí™”)
        - í–‰ë™ ì ìˆ˜
        - ì„ í˜¸ë„ ì •ë³´
        - ë¶ë§ˆí¬ ë°ì´í„°
        - ë²¡í„° ë°ì´í„°
        ëª¨ë“  ê²ƒì„ í•œ ë²ˆì— ì¡°íšŒ
        """
        try:
            # ë‹¨ì¼ íŠ¸ëœì­ì…˜ìœ¼ë¡œ ëª¨ë“  ì‚¬ìš©ì ë°ì´í„° ì¡°íšŒ
            async with self.db_manager.get_connection() as conn:
                # 1. í–‰ë™ ì ìˆ˜ ì¡°íšŒ (user_behavior_vectors í…Œì´ë¸” êµ¬ì¡°ì— ë§ì¶¤)
                behavior_query = """
                    SELECT COALESCE(
                        total_bookmarks + total_likes + total_clicks, 0
                    ) as behavior_score
                    FROM user_behavior_vectors
                    WHERE user_id = $1
                """

                # 2. ì‚¬ìš©ì ì„ í˜¸ë„ ì¡°íšŒ (user_preferences í…Œì´ë¸”ì—ì„œ)
                preferences_query = """
                    SELECT priority, accommodation, exploration, persona
                    FROM user_preferences
                    WHERE user_id = $1
                """

                # 3. ì„ í˜¸ë„ íƒœê·¸ ì¡°íšŒ
                tags_query = """
                    SELECT tag, weight
                    FROM user_preference_tags
                    WHERE user_id = $1
                    ORDER BY weight DESC
                """

                # 4. í–‰ë™ ë²¡í„° ì¡°íšŒ
                vector_query = """
                    SELECT behavior_vector
                    FROM user_behavior_vectors
                    WHERE user_id = $1 AND behavior_vector IS NOT NULL
                """

                # 5. ë¶ë§ˆí¬ ë°ì´í„° ì¡°íšŒ
                bookmarks_query = """
                    SELECT places
                    FROM saved_locations
                    WHERE user_id = $1
                """

                # ìˆœì°¨ ì¿¼ë¦¬ ì‹¤í–‰ (ì•ˆì „í•œ ë°©ì‹)
                try:
                    behavior_score = await conn.fetchval(behavior_query, user_id) or 0
                except Exception as e:
                    logger.error(f"Behavior query failed: {e}")
                    behavior_score = 0

                try:
                    preferences_data = await conn.fetchrow(preferences_query, user_id)
                except Exception as e:
                    logger.error(f"Preferences query failed: {e}")
                    preferences_data = None

                try:
                    tags_data = await conn.fetch(tags_query, user_id)
                except Exception as e:
                    logger.error(f"Tags query failed: {e}")
                    tags_data = []

                try:
                    vector_data = await conn.fetchval(vector_query, user_id)
                except Exception as e:
                    logger.error(f"Vector query failed: {e}")
                    vector_data = None

                try:
                    bookmarks_data = await conn.fetch(bookmarks_query, user_id)
                except Exception as e:
                    logger.error(f"Bookmarks query failed: {e}")
                    bookmarks_data = []

                # ê²°ê³¼ í†µí•©
                result = {
                    'behavior_score': behavior_score,
                    'user_preferences': {
                        'priority': preferences_data['priority'] if preferences_data else None,
                        'accommodation': preferences_data['accommodation'] if preferences_data else None,
                        'exploration': preferences_data['exploration'] if preferences_data else None,
                        'persona': preferences_data['persona'] if preferences_data else None
                    },
                    'preference_tags': {
                        row['tag']: row['weight'] for row in tags_data
                    },
                    'behavior_vector': validate_vector_data(vector_data),
                    'bookmarks': [dict(row) for row in bookmarks_data]
                }

                return result

        except Exception as e:
            logger.error(f"âŒ Failed to get comprehensive user data for {user_id}: {e}")
            return {
                'behavior_score': 0,
                'preferences': {'preference_tags': {}},
                'behavior_vector': None,
                'bookmarks': []
            }

    async def _get_user_behavior_score(self, user_id: str) -> int:
        """ì‚¬ìš©ì í–‰ë™ ì ìˆ˜ (ìºì‹œëœ ë°ì´í„° í™œìš©)"""
        cache_key = f"user_comprehensive:{user_id}"
        if self._is_cache_valid(cache_key):
            cached_data = self.vector_cache.get(cache_key)
            return cached_data.get('behavior_score', 0)

        # ìºì‹œê°€ ì—†ìœ¼ë©´ í†µí•© ë°ì´í„° ì¡°íšŒ
        comprehensive_data = await self._get_comprehensive_user_data(user_id)
        self._update_cache(cache_key, comprehensive_data)
        return comprehensive_data.get('behavior_score', 0)

    async def _get_user_behavior_vector_cached(self, user_id: str) -> Optional[np.ndarray]:
        """ìºì‹œë¥¼ í™œìš©í•œ ì‚¬ìš©ì ë²¡í„° ì¡°íšŒ (PostgreSQL ARRAY íƒ€ì… ì§€ì›)"""
        cache_key = f"user_vector:{user_id}"

        # ìºì‹œ í™•ì¸
        if self._is_cache_valid(cache_key):
            self.stats['cache_hits'] += 1
            cached_data = self.vector_cache[cache_key]
            if cached_data is not None:
                return np.array(cached_data, dtype=np.float32)
            return None

        # DBì—ì„œ ì¡°íšŒ (PostgreSQL ARRAY íƒ€ì…)
        try:
            query = """
                SELECT behavior_vector
                FROM user_behavior_vectors
                WHERE user_id = $1 AND behavior_vector IS NOT NULL
            """
            vector_data = await self.db_manager.execute_single_query(query, user_id)
            logger.info(f"DEBUG: User {user_id} raw vector data from DB: {vector_data is not None}")

            validated_vector = validate_vector_data(vector_data)
            logger.info(f"DEBUG: User {user_id} validated vector: {validated_vector is not None}")

            # ìºì‹œì— ì €ì¥ (Noneë„ ìºì‹œí•˜ì—¬ ë°˜ë³µ ì¿¼ë¦¬ ë°©ì§€)
            if validated_vector is not None:
                self._update_cache(cache_key, validated_vector.tolist())
                return validated_vector
            else:
                self._update_cache(cache_key, None)
                return None

        except Exception as e:
            logger.error(f"âŒ Failed to get user vector for {user_id}: {e}")
            return None

    async def _get_user_bookmark_preferences(self, user_id: str) -> Dict[str, float]:
        """ì‚¬ìš©ì ë¶ë§ˆí¬ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„ ê³„ì‚°"""
        try:
            query = """
                SELECT places
                FROM saved_locations
                WHERE user_id = $1
            """

            bookmarks = await self.db_manager.execute_query(query, user_id)

            if not bookmarks:
                return {}

            # ì¹´í…Œê³ ë¦¬ë³„ ë¶ë§ˆí¬ ìˆ˜ ê³„ì‚°
            category_counts = {}
            total_bookmarks = 0

            for bookmark in bookmarks:
                places_text = bookmark.get('places', '')
                if ':' in places_text:
                    table_name = places_text.split(':', 1)[0]
                    category_counts[table_name] = category_counts.get(table_name, 0) + 1
                    total_bookmarks += 1

            # ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° (ë¹„ìœ¨ ê¸°ë°˜)
            preferences = {}
            for category, count in category_counts.items():
                preferences[category] = count / total_bookmarks if total_bookmarks > 0 else 0

            logger.info(f"ğŸ“Š User {user_id} bookmark preferences: {preferences}")
            return preferences

        except Exception as e:
            logger.error(f"âŒ Failed to get bookmark preferences for {user_id}: {e}")
            return {}

    def _apply_category_quotas(
        self,
        recommendations: List[Dict],
        bookmark_preferences: Dict[str, float],
        limit: int
    ) -> List[Dict]:
        """ë¶ë§ˆí¬ ì„ í˜¸ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë³„ í• ë‹¹ëŸ‰ì„ ì ìš©í•œ ê· í˜•ì¡íŒ ì¶”ì²œ"""
        try:
            if not bookmark_preferences or not recommendations:
                return recommendations[:limit]

            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì¶”ì²œ ë¶„ë¥˜
            category_recommendations = {}
            for rec in recommendations:
                category = rec.get('table_name', 'unknown')
                if category not in category_recommendations:
                    category_recommendations[category] = []
                category_recommendations[category].append(rec)

            # ì„ í˜¸ë„ ê¸°ë°˜ í• ë‹¹ëŸ‰ ê³„ì‚°
            result = []
            remaining_slots = limit

            # ë‹¤ì–‘ì„± ë³´ì¥: ìµœì†Œ 3ê°œ ì¹´í…Œê³ ë¦¬ëŠ” ë°˜ë“œì‹œ í¬í•¨
            min_categories = min(3, len(category_recommendations))
            max_per_category = max(1, limit // min_categories)

            # 1ë‹¨ê³„: ì£¼ìš” ì„ í˜¸ ì¹´í…Œê³ ë¦¬ë¶€í„° í• ë‹¹
            sorted_preferences = sorted(bookmark_preferences.items(), key=lambda x: x[1], reverse=True)

            for category, preference_rate in sorted_preferences:
                if category not in category_recommendations:
                    continue

                # ì´ˆê°•ë ¥ ì„ í˜¸ë„ í¸í–¥ ì‹œìŠ¤í…œ (ë” ê³µê²©ì  í• ë‹¹)
                if preference_rate > 0.6:  # 60% ì´ìƒ ê°•í•œ ì„ í˜¸ (ê¸°ì¤€ ë‚®ì¶¤)
                    quota = min(max(int(limit * 0.5), 4), max_per_category + 3)  # 50% ë˜ëŠ” ê¸°ë³¸+3 (ë” ê³µê²©ì )
                elif preference_rate > 0.3:  # 30% ì´ìƒ ì„ í˜¸ ì¹´í…Œê³ ë¦¬ (ê¸°ì¤€ ë‚®ì¶¤)
                    quota = min(max(int(limit * 0.35), 3), max_per_category + 2)  # 35% ë˜ëŠ” ê¸°ë³¸+2
                elif preference_rate > 0.1:  # 10% ì´ìƒ ì„ í˜¸ ì¹´í…Œê³ ë¦¬ (ê¸°ì¤€ ë‚®ì¶¤)
                    quota = min(max(int(limit * 0.2), 2), max_per_category + 1)  # 20% ë˜ëŠ” ê¸°ë³¸+1
                else:  # ë‚®ì€ ì„ í˜¸ë„ ì¹´í…Œê³ ë¦¬
                    quota = max(1, int(limit * 0.05))  # ìµœì†Œ 5% í• ë‹¹

                # ì‹¤ì œ í• ë‹¹ ê°€ëŠ¥í•œ ìˆ˜ë§Œí¼ ì¶”ê°€
                available = min(quota, len(category_recommendations[category]), remaining_slots)
                result.extend(category_recommendations[category][:available])
                remaining_slots -= available

                logger.info(f"ğŸ“Š {category}: {preference_rate:.3f} -> {available}ê°œ í• ë‹¹")

                if remaining_slots <= 0:
                    break

            # 2ë‹¨ê³„: ë‚¨ì€ ìŠ¬ë¡¯ì„ ì ìˆ˜ìˆœìœ¼ë¡œ ì±„ì›€
            if remaining_slots > 0:
                used_ids = {rec.get('place_id') for rec in result}
                remaining_recs = [rec for rec in recommendations if rec.get('place_id') not in used_ids]
                result.extend(remaining_recs[:remaining_slots])

            return result[:limit]

        except Exception as e:
            logger.error(f"âŒ Category quota application failed: {e}")
            return recommendations[:limit]

    def _apply_category_shuffling(self, recommendations: List[Dict]) -> List[Dict]:
        """ì¹´í…Œê³ ë¦¬ê°€ ì ì ˆíˆ ì„ì´ë„ë¡ ì¸í„°ë¦¬ë¹™ ë°©ì‹ìœ¼ë¡œ ì¬ë°°ì¹˜"""
        try:
            if len(recommendations) <= 3:
                return recommendations

            # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
            category_groups = {}
            for rec in recommendations:
                category = rec.get('table_name', 'unknown')
                if category not in category_groups:
                    category_groups[category] = []
                category_groups[category].append(rec)

            # ì¹´í…Œê³ ë¦¬ê°€ 2ê°œ ì´í•˜ë©´ ì…”í”Œë§ ë¶ˆí•„ìš”
            if len(category_groups) <= 2:
                return recommendations

            logger.info(f"ğŸ”„ Shuffling {len(category_groups)} categories for better distribution")

            # ì¸í„°ë¦¬ë¹™ ë°©ì‹ìœ¼ë¡œ ì¬ë°°ì¹˜
            result = []
            category_indices = {cat: 0 for cat in category_groups.keys()}
            categories = list(category_groups.keys())

            # ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ë¥¼ ìˆœí™˜í•˜ë©° ë°°ì¹˜
            for position in range(len(recommendations)):
                # í˜„ì¬ ë¼ìš´ë“œì—ì„œ ì‚¬ìš©í•  ì¹´í…Œê³ ë¦¬ ì„ íƒ
                category_idx = position % len(categories)
                current_category = categories[category_idx]

                # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ì•„ì§ ë°°ì¹˜ë˜ì§€ ì•Šì€ ì•„ì´í…œì´ ìˆëŠ”ì§€ í™•ì¸
                attempts = 0
                while attempts < len(categories):
                    cat_idx = category_indices[current_category]
                    if cat_idx < len(category_groups[current_category]):
                        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì—ì„œ ì•„ì´í…œ ì¶”ê°€
                        result.append(category_groups[current_category][cat_idx])
                        category_indices[current_category] += 1
                        break
                    else:
                        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ê°€ ì†Œì§„ë˜ë©´ ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ
                        category_idx = (category_idx + 1) % len(categories)
                        current_category = categories[category_idx]
                        attempts += 1

                # ëª¨ë“  ì¹´í…Œê³ ë¦¬ê°€ ì†Œì§„ë˜ë©´ ì¢…ë£Œ
                if attempts >= len(categories):
                    break

            # í˜¹ì‹œ ë‚¨ì€ ì•„ì´í…œë“¤ ì¶”ê°€
            for category, items in category_groups.items():
                start_idx = category_indices[category]
                result.extend(items[start_idx:])

            logger.info(f"âœ… Category shuffling completed: {len(result)} items redistributed")
            return result[:len(recommendations)]

        except Exception as e:
            logger.error(f"âŒ Category shuffling failed: {e}")
            return recommendations

    async def _get_place_candidates(
        self,
        region: Optional[str],
        category: Optional[str]
    ) -> List[Dict]:
        """ì¶”ì²œ í›„ë³´ ì¥ì†Œ ì¡°íšŒ (ìµœì í™”ëœ ì¿¼ë¦¬)"""
        try:
            # place_recommendations í…Œì´ë¸”ì—ì„œ í…ìŠ¤íŠ¸ ë²¡í„° ì¡°íšŒ (PostgreSQL vector íƒ€ì…)
            query = """
                SELECT
                    pr.place_id::text as place_id,
                    pr.table_name,
                    pr.vector as vector,
                    COALESCE(pr.bookmark_cnt, 0) as total_likes,
                    COALESCE(pr.bookmark_cnt, 0) as total_bookmarks,
                    COALESCE(pr.bookmark_cnt, 0) as total_clicks,
                    1 as unique_users,
                    COALESCE(pr.bookmark_cnt, 0)::float as popularity_score,
                    COALESCE(pr.bookmark_cnt, 0)::float as engagement_score,
                    pr.name,
                    pr.region,
                    pr.city,
                    pr.latitude,
                    pr.longitude,
                    pr.overview as description,
                    pr.image_urls,
                    pr.bookmark_cnt
                FROM place_recommendations pr
                WHERE
                    pr.vector IS NOT NULL
                    AND pr.name IS NOT NULL
                    AND pr.bookmark_cnt IS NOT NULL
            """

            params = []
            param_count = 0

            # ì§€ì—­ í•„í„°
            if region:
                param_count += 1
                query += f" AND pr.region = ${param_count}"
                params.append(region)

            # ì¹´í…Œê³ ë¦¬ í•„í„°
            if category:
                param_count += 1
                query += f" AND pr.table_name = ${param_count}::text"
                params.append(category)

            # ì„±ëŠ¥ì„ ìœ„í•œ ì œí•œ ë° ì •ë ¬ (ë¶ë§ˆí¬ ì¹´ìš´íŠ¸ ê¸°ì¤€)
            query += " ORDER BY COALESCE(pr.bookmark_cnt, 0) DESC"
            param_count += 1
            query += f" LIMIT ${param_count}"
            params.append(CONFIG.candidate_limit)

            places = await self.db_manager.execute_query(query, *params)

            # ë²¡í„° ë°ì´í„° ê²€ì¦
            valid_places = []
            for place in places:
                if validate_vector_data(place['vector']) is not None:
                    # S3 ì´ë¯¸ì§€ URLì„ HTTPSë¡œ ë³€í™˜
                    place = self._convert_s3_urls_to_https(place)
                    valid_places.append(place)

            logger.info(f"ğŸ“‹ Retrieved {len(valid_places)} valid place candidates")
            return valid_places

        except Exception as e:
            logger.error(f"âŒ Failed to get place candidates: {e}")
            return []

    async def _get_popular_recommendations(
        self,
        region: Optional[str],
        category: Optional[str],
        limit: int,
        fast_mode: bool = False
    ) -> List[Dict]:
        """ì¸ê¸° ê¸°ë°˜ ì¶”ì²œ (ë‹¨ìˆœ ë¶ë§ˆí¬ ì¹´ìš´íŠ¸ ì •ë ¬)"""
        # fast_modeì— ë”°ë¼ ë‹¤ë¥¸ í›„ë³´ ì¡°íšŒ
        if fast_mode:
            places = await self._get_fast_place_candidates(region, category, limit * 2)
        else:
            places = await self._get_place_candidates(region, category)

        if not places:
            return []

        # ë‹¨ìˆœ ë¶ë§ˆí¬ ì¹´ìš´íŠ¸ ê¸°ë°˜ ì •ë ¬
        for place in places:
            try:
                bookmark_count = place.get('bookmark_cnt', 0)
                place['final_score'] = bookmark_count
                place['recommendation_type'] = 'popular_fast' if fast_mode else 'popular'
                place['similarity_score'] = 0.8  # ì¸ê¸° ì¶”ì²œìš© ê¸°ë³¸ê°’
            except Exception as e:
                logger.error(f"âŒ Popular score calculation failed for place {place.get('place_id')}: {e}")
                place['final_score'] = 0

        # ë¶ë§ˆí¬ ì¹´ìš´íŠ¸ìˆœ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
        places.sort(key=lambda x: x.get('bookmark_cnt', 0), reverse=True)
        
        # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
        for place in places[:limit]:
            if 'vector' in place and isinstance(place['vector'], np.ndarray):
                place['vector'] = place['vector'].tolist()
            if 'text_vector' in place and isinstance(place['text_vector'], np.ndarray):
                place['text_vector'] = place['text_vector'].tolist()
            if 'image_vector' in place and isinstance(place['image_vector'], np.ndarray):
                place['image_vector'] = place['image_vector'].tolist()
        
        return places[:limit]

    async def _get_multi_vector_recommendations(
        self,
        user_id: str,
        user_vector: np.ndarray,
        bookmark_preferences: Dict[str, float],
        region: Optional[str],
        category: Optional[str],
        limit: int
    ) -> List[Dict]:
        """
        ë‹¤ì¤‘ ë²¡í„° ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ (ë™ì  ê°€ì¤‘ì¹˜ ì ìš©)
        - ê¸°ì¡´ ì‚¬ìš©ì: ìš°ì„ ìˆœìœ„ ì„ í˜¸ë„ 70% + í–‰ë™ ë°ì´í„° 30%
        - í…ìŠ¤íŠ¸-í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ (ê¸°ì¡´ overview ë²¡í„°)
        - ì´ë¯¸ì§€-ì´ë¯¸ì§€ ìœ ì‚¬ë„ (ìƒˆë¡œìš´ image ë²¡í„°)
        - í¬ë¡œìŠ¤ ëª¨ë‹¬ ìœ ì‚¬ë„ (í…ìŠ¤íŠ¸-ì´ë¯¸ì§€, ì´ë¯¸ì§€-í…ìŠ¤íŠ¸)
        - ë¶ë§ˆí¬ ê¸°ë°˜ ì„ í˜¸ë„ ë°˜ì˜
        """
        try:
            # ì¥ì†Œ í›„ë³´êµ° ì¡°íšŒ (ì´ë¯¸ì§€ ë²¡í„° í¬í•¨)
            places = await self._get_place_candidates_with_images(region, category)

            if not places:
                return []

            # ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”: ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë™ì‹œì— ì¡°íšŒ
            user_data_tasks = [
                self._get_user_preferences(user_id),
                self._get_user_image_preferences(user_id)
            ]

            # ë¹„ë™ê¸° ë³‘ë ¬ ì‹¤í–‰
            user_preferences, user_image_preferences = await asyncio.gather(
                *user_data_tasks, return_exceptions=True
            )

            # ì˜ˆì™¸ ì²˜ë¦¬
            if isinstance(user_preferences, Exception):
                user_preferences = {}
                logger.error(f"Failed to get user preferences: {user_preferences}")

            if isinstance(user_image_preferences, Exception):
                user_image_preferences = {}
                logger.error(f"Failed to get user image preferences: {user_image_preferences}")

            # ì´ë¯¸ì§€ ì„ í˜¸ë„ê°€ ì¤€ë¹„ë˜ë©´ ë‹¤ì¤‘ ë²¡í„° ìœ ì‚¬ë„ ì¬ê³„ì‚°
            multi_scores = await self._calculate_independent_similarities(
                user_id, user_vector, user_image_preferences, places
            )

            # ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì¸ê¸°ë„ ì ìˆ˜ ë¯¸ë¦¬ ê³„ì‚°
            popularity_scores = {}
            engagement_scores = {}
            for place in places:
                place_data = {
                    'total_clicks': place.get('total_clicks', 0),
                    'total_likes': place.get('total_likes', 0),
                    'total_bookmarks': place.get('total_bookmarks', 0)
                }
                place_id = place.get('place_id')
                popularity_scores[place_id] = calculate_weighted_popularity_score(place_data)
                engagement_scores[place_id] = calculate_engagement_score(place_data)

            # ë°°ì¹˜ ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚°
            preference_scores = {}
            for place in places:
                place_id = place.get('place_id')
                preference_scores[place_id] = self._calculate_place_preference_score(place, user_preferences)

            # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° ë° ê²°ê³¼ ìƒì„±
            results = []
            for i, place in enumerate(places):
                place_id = place.get('place_id')

                if i >= len(multi_scores):
                    logger.warning(f"Missing score for place {i}, using defaults")
                    scores = {
                        'behavior_text_similarity': 0.0,
                        'upload_image_similarity': 0.0,
                        'bookmark_text_similarity': 0.0,
                        'bookmark_image_similarity': 0.0,
                        'liked_post_similarity': 0.0,
                        'combined_score': 0.0
                    }
                else:
                    scores = multi_scores[i]

                try:
                    # ë¯¸ë¦¬ ê³„ì‚°ëœ ì ìˆ˜ë“¤ ì‚¬ìš©
                    popularity_score = popularity_scores.get(place_id, 0.0)
                    engagement_score = engagement_scores.get(place_id, 0.0)
                    preference_score = preference_scores.get(place_id, 0.0)

                    # ë¶ë§ˆí¬ ì„ í˜¸ë„ ë³´ë„ˆìŠ¤
                    category_preference = bookmark_preferences.get(place['table_name'], 0)
                    bookmark_bonus = category_preference * 0.5

                    # ë‹¤ì¤‘ ë²¡í„° ì¢…í•© ì ìˆ˜ (í–‰ë™ ë°ì´í„° ê¸°ë°˜)
                    behavior_score = scores.get('combined_score', 0.0)

                    # ë™ì  ê°€ì¤‘ì¹˜ ì ìš© (ê¸°ì¡´ ì‚¬ìš©ì: ì„ í˜¸ë„ 70% + í–‰ë™ ë°ì´í„° 30%)
                    weighted_preference_score = preference_score * CONFIG.experienced_user_preference_weight
                    weighted_behavior_score = behavior_score * CONFIG.experienced_user_behavior_weight

                    # ìµœì¢… í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ (ë™ì  ê°€ì¤‘ì¹˜ ë°˜ì˜)
                    final_score = (
                        weighted_preference_score +
                        weighted_behavior_score +
                        (popularity_score / 100.0) * 0.1 +  # ì¸ê¸°ë„ ì•½ê°„ ë°˜ì˜
                        bookmark_bonus * 0.1  # ë¶ë§ˆí¬ ë³´ë„ˆìŠ¤ ì•½ê°„ ë°˜ì˜
                    )

                    # ì ìˆ˜ê°€ ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ í¬í•¨
                    if behavior_score >= CONFIG.min_similarity_threshold:
                        place['behavior_text_similarity'] = round(scores.get('behavior_text_similarity', 0.0), 4)
                        place['upload_image_similarity'] = round(scores.get('upload_image_similarity', 0.0), 4)
                        place['bookmark_text_similarity'] = round(scores.get('bookmark_text_similarity', 0.0), 4)
                        place['bookmark_image_similarity'] = round(scores.get('bookmark_image_similarity', 0.0), 4)
                        place['liked_post_similarity'] = round(scores.get('liked_post_similarity', 0.0), 4)
                        place['combined_score'] = round(scores.get('combined_score', 0.0), 4)
                        place['multi_vector_score'] = round(behavior_score, 4)
                        place['preference_score'] = round(preference_score, 4)
                        place['weighted_preference_score'] = round(weighted_preference_score, 4)
                        place['weighted_behavior_score'] = round(weighted_behavior_score, 4)
                        place['popularity_score'] = popularity_score
                        place['engagement_score'] = engagement_score
                        place['bookmark_bonus'] = round(bookmark_bonus, 4)
                        place['final_score'] = round(final_score, 4)
                        place['recommendation_type'] = 'five_channel_system'

                        results.append(place)

                except Exception as e:
                    logger.error(f"âŒ Multi-vector score calculation failed for place {i}: {e}")
                    continue

            # ì ìˆ˜ìˆœ ì •ë ¬
            results.sort(key=lambda x: x['final_score'], reverse=True)

            logger.info(f"ğŸ¯ Multi-vector recommendations: {len(results)} candidates")

            # ì¹´í…Œê³ ë¦¬ ê· í˜• ì¡°ì • ì ìš©
            balanced_results = self._apply_category_quotas(results, bookmark_preferences, limit)
            final_results = self._apply_category_shuffling(balanced_results)
            
            # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
            for result in final_results:
                if 'vector' in result and isinstance(result['vector'], np.ndarray):
                    result['vector'] = result['vector'].tolist()
                if 'text_vector' in result and isinstance(result['text_vector'], np.ndarray):
                    result['text_vector'] = result['text_vector'].tolist()
                if 'image_vector' in result and isinstance(result['image_vector'], np.ndarray):
                    result['image_vector'] = result['image_vector'].tolist()

            return final_results

        except Exception as e:
            logger.error(f"âŒ Multi-vector recommendation failed: {e}")
            # Fallback to enhanced vector recommendations
            return await self._get_enhanced_vector_recommendations(
                user_vector, bookmark_preferences, region, category, limit
            )

    async def _get_enhanced_vector_recommendations(
        self,
        user_vector: np.ndarray,
        bookmark_preferences: Dict[str, float],
        region: Optional[str],
        category: Optional[str],
        limit: int
    ) -> List[Dict]:
        """ë¶ë§ˆí¬ ì„ í˜¸ë„ë¥¼ ë°˜ì˜í•œ ê°œì„ ëœ ë²¡í„° ê¸°ë°˜ ì¶”ì²œ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)"""
        places = await self._get_place_candidates(region, category)

        if not places:
            return []

        try:
            # ë²¡í„° ë°°ì¹˜ ì²˜ë¦¬
            place_vectors = []
            valid_places = []

            for place in places:
                vector = validate_vector_data(place['vector'])
                if vector is not None:
                    place_vectors.append(vector)
                    valid_places.append(place)

            if not valid_places:
                logger.warning("âš ï¸ No valid place vectors found, falling back to popular")
                return await self._get_popular_recommendations(region, category, limit)

            # ë²¡í„°í™”ëœ ìœ ì‚¬ë„ ê³„ì‚°
            place_vectors_array = np.array(place_vectors, dtype=np.float32)
            similarities = safe_cosine_similarity(user_vector, place_vectors_array)

            # ë¶ë§ˆí¬ ì„ í˜¸ë„ ê°•í™”ëœ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
            results = []
            for i, place in enumerate(valid_places):
                try:
                    similarity = float(similarities[i])

                    # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš©
                    if similarity < CONFIG.min_similarity_threshold:
                        continue

                    # ê¸°ë³¸ ì¸ê¸°ë„ ì ìˆ˜
                    place_data = {
                        'total_clicks': place.get('total_clicks', 0),
                        'total_likes': place.get('total_likes', 0),
                        'total_bookmarks': place.get('total_bookmarks', 0)
                    }
                    popularity_score = calculate_weighted_popularity_score(place_data)
                    engagement_score = calculate_engagement_score(place_data)

                    # ğŸ”¥ ë¶ë§ˆí¬ ì„ í˜¸ë„ ë³´ë„ˆìŠ¤ ì¶”ê°€ (ì ì ˆí•œ ê°•í™”)
                    category_preference = bookmark_preferences.get(place['table_name'], 0)
                    bookmark_bonus = category_preference * 0.5  # ìµœëŒ€ 50% ë³´ë„ˆìŠ¤ (ê· í˜•ì¡íŒ ì¡°ì •)

                    # ê°œì„ ëœ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜
                    hybrid_score = (
                        similarity * CONFIG.similarity_weight +
                        (popularity_score / 100.0) * CONFIG.popularity_weight * 0.7 +
                        (engagement_score / 100.0) * CONFIG.popularity_weight * 0.3 +
                        bookmark_bonus  # ë¶ë§ˆí¬ ì„ í˜¸ë„ ë³´ë„ˆìŠ¤
                    )

                    place['similarity_score'] = round(similarity, 4)
                    place['popularity_score'] = popularity_score
                    place['engagement_score'] = engagement_score
                    place['bookmark_bonus'] = round(bookmark_bonus, 4)
                    place['final_score'] = round(hybrid_score, 4)
                    place['recommendation_type'] = 'personalized_enhanced'

                    results.append(place)

                except Exception as e:
                    logger.error(f"âŒ Score calculation failed for place {i}: {e}")
                    continue

            # ì ìˆ˜ìˆœ ì •ë ¬
            results.sort(key=lambda x: x['final_score'], reverse=True)

            # ğŸ¯ ì¹´í…Œê³ ë¦¬ë³„ ë³´ì¥ ì¶”ì²œ ì‹œìŠ¤í…œ ì ìš©
            balanced_results = self._apply_category_quotas(results, bookmark_preferences, limit)

            # ğŸ”„ ì¹´í…Œê³ ë¦¬ ë¶„ì‚°ì„ ìœ„í•œ ì…”í”Œë§ ì ìš©
            final_results = self._apply_category_shuffling(balanced_results)

            return final_results

        except Exception as e:
            logger.error(f"âŒ Enhanced vector-based recommendation failed: {e}")
            # Fallback to popular recommendations
            return await self._get_popular_recommendations(region, category, limit)

    async def _get_vector_based_recommendations(
        self,
        user_vector: np.ndarray,
        region: Optional[str],
        category: Optional[str],
        limit: int
    ) -> List[Dict]:
        """ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ê°œì¸í™” ì¶”ì²œ (ìµœì í™”ëœ ë²„ì „)"""
        places = await self._get_place_candidates(region, category)

        if not places:
            return []

        try:
            # ë²¡í„° ë°°ì¹˜ ì²˜ë¦¬
            place_vectors = []
            valid_places = []

            for place in places:
                vector = validate_vector_data(place['vector'])
                if vector is not None:
                    place_vectors.append(vector)
                    valid_places.append(place)

            if not valid_places:
                logger.warning("âš ï¸ No valid place vectors found, falling back to popular")
                return await self._get_popular_recommendations(region, category, limit)

            # ë²¡í„°í™”ëœ ìœ ì‚¬ë„ ê³„ì‚°
            place_vectors_array = np.array(place_vectors, dtype=np.float32)
            similarities = safe_cosine_similarity(user_vector, place_vectors_array)

            # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°
            results = []
            for i, place in enumerate(valid_places):
                try:
                    similarity = float(similarities[i])

                    # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš©
                    if similarity < CONFIG.min_similarity_threshold:
                        continue

                    # ì¸ê¸°ë„ ì ìˆ˜ ê³„ì‚°
                    place_data = {
                        'total_clicks': place.get('total_clicks', 0),
                        'total_likes': place.get('total_likes', 0),
                        'total_bookmarks': place.get('total_bookmarks', 0)
                    }
                    popularity_score = calculate_weighted_popularity_score(place_data)
                    engagement_score = calculate_engagement_score(place_data)

                    # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ (ê°œì¸í™” + ì¸ê¸°ë„ + ì°¸ì—¬ë„)
                    hybrid_score = (
                        similarity * CONFIG.similarity_weight +
                        (popularity_score / 100.0) * CONFIG.popularity_weight * 0.7 +
                        (engagement_score / 100.0) * CONFIG.popularity_weight * 0.3
                    )

                    place['similarity_score'] = round(similarity, 4)
                    place['popularity_score'] = popularity_score
                    place['engagement_score'] = engagement_score
                    place['final_score'] = round(hybrid_score, 4)
                    place['recommendation_type'] = 'personalized'

                    results.append(place)

                except Exception as e:
                    logger.error(f"âŒ Score calculation failed for place {i}: {e}")
                    continue

            # ì ìˆ˜ìˆœ ì •ë ¬
            results.sort(key=lambda x: x['final_score'], reverse=True)

            logger.info(f"ğŸ¯ Generated {len(results)} personalized recommendations")
            
            # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
            for result in results[:limit]:
                if 'vector' in result and isinstance(result['vector'], np.ndarray):
                    result['vector'] = result['vector'].tolist()
                if 'text_vector' in result and isinstance(result['text_vector'], np.ndarray):
                    result['text_vector'] = result['text_vector'].tolist()
                if 'image_vector' in result and isinstance(result['image_vector'], np.ndarray):
                    result['image_vector'] = result['image_vector'].tolist()
            
            return results[:limit]

        except Exception as e:
            logger.error(f"âŒ Vector-based recommendation failed: {e}")
            # Fallback to popular recommendations
            return await self._get_popular_recommendations(region, category, limit)

    def _update_response_time(self, response_time: float):
        """ì‘ë‹µ ì‹œê°„ í†µê³„ ì—…ë°ì´íŠ¸ (ì´ë™í‰ê· )"""
        alpha = 0.1  # ì´ë™í‰ê·  ê°€ì¤‘ì¹˜
        if self.stats['avg_response_time'] == 0.0:
            self.stats['avg_response_time'] = response_time
        else:
            self.stats['avg_response_time'] = (
                alpha * response_time +
                (1 - alpha) * self.stats['avg_response_time']
            )

    def get_stats(self) -> Dict:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        cache_hit_rate = (
            self.stats['cache_hits'] / max(self.stats['total_requests'], 1)
        ) * 100

        return {
            **self.stats,
            'cache_hit_rate': round(cache_hit_rate, 2),
            'cache_size': len(self.vector_cache),
            'personalization_rate': round(
                (self.stats['personalized_requests'] / max(self.stats['total_requests'], 1)) * 100, 2
            )
        }

    async def get_popular_regions_and_categories(self) -> Dict[str, List[str]]:
        """ì¸ê¸°ë„ ê¸°ë°˜ìœ¼ë¡œ ë™ì  ì§€ì—­/ì¹´í…Œê³ ë¦¬ ìˆœì„œ ê²°ì •"""
        try:
            # ì§€ì—­ë³„ ë¶ë§ˆí¬ ì´í•© ì¡°íšŒ
            region_query = """
                SELECT region, SUM(COALESCE(bookmark_cnt, 0)) as total_bookmarks
                FROM place_recommendations
                WHERE region IS NOT NULL
                GROUP BY region
                ORDER BY total_bookmarks DESC
                LIMIT 10
            """

            # ì¹´í…Œê³ ë¦¬ë³„ ë¶ë§ˆí¬ ì´í•© ì¡°íšŒ
            category_query = """
                SELECT table_name as category, SUM(COALESCE(bookmark_cnt, 0)) as total_bookmarks
                FROM place_recommendations
                WHERE table_name IS NOT NULL
                GROUP BY table_name
                ORDER BY total_bookmarks DESC
                LIMIT 10
            """

            regions_data = await self.db_manager.execute_query(region_query)
            categories_data = await self.db_manager.execute_query(category_query)

            regions = [row['region'] for row in regions_data if row['region']]
            categories = [row['category'] for row in categories_data if row['category']]

            logger.info(f"ğŸ“Š Dynamic ordering: {len(regions)} regions, {len(categories)} categories")

            return {
                'regions': regions,
                'categories': categories
            }

        except Exception as e:
            logger.error(f"âŒ Failed to get dynamic regions/categories: {e}")
            # Fallback to config defaults
            return {
                'regions': CONFIG.explore_regions or [],
                'categories': CONFIG.explore_categories or []
            }

    async def health_check(self) -> Dict[str, Any]:
        """ì—”ì§„ í—¬ìŠ¤ì²´í¬"""
        try:
            # ê°„ë‹¨í•œ DB ì—°ê²° í…ŒìŠ¤íŠ¸
            test_result = await self.db_manager.execute_single_query("SELECT 1")
            db_healthy = test_result == 1

            # ìºì‹œ ìƒíƒœ í™•ì¸
            cache_healthy = len(self.vector_cache) < CONFIG.vector_cache_size

            # ì „ì²´ ìƒíƒœ íŒë‹¨
            overall_healthy = db_healthy and cache_healthy

            return {
                'status': 'healthy' if overall_healthy else 'degraded',
                'database': 'connected' if db_healthy else 'disconnected',
                'cache': 'normal' if cache_healthy else 'full',
                'stats': self.get_stats(),
                'config': {
                    'candidate_limit': CONFIG.candidate_limit,
                    'similarity_weight': CONFIG.similarity_weight,
                    'popularity_weight': CONFIG.popularity_weight
                }
            }

        except Exception as e:
            logger.error(f"âŒ Health check failed: {e}")
            return {
                'status': 'unhealthy',
                'error': str(e),
                'stats': self.get_stats()
            }

    async def _get_preference_based_recommendations(
        self,
        user_id: str,
        region: Optional[str] = None,
        category: Optional[str] = None,
        limit: int = 20
    ) -> List[Dict]:
        """
        ìš°ì„ ìˆœìœ„ íƒœê·¸ ê¸°ë°˜ ì¶”ì²œ (behavior_vector í†µí•©)
        user_preferences, user_preference_tags í…Œì´ë¸”ê³¼ user_behavior_vectorsì˜ behavior_vectorë¥¼ í™œìš©
        """
        try:
            # 1. ì‚¬ìš©ì ì„ í˜¸ë„ ì •ë³´ ì¡°íšŒ
            logger.info(f"ğŸ” Getting user preferences for user {user_id}")
            user_preferences = await self._get_user_preferences(user_id)
            if not user_preferences:
                logger.info(f"âŒ No preferences found for user {user_id}")
                return []

            logger.info(f"âœ… Found user preferences for user {user_id}: {list(user_preferences.keys())}")

            # 2. ì‚¬ìš©ì í–‰ë™ ë²¡í„° ì¡°íšŒ (ë¶ë§ˆí¬ íŒ¨í„´ ë¶„ì„ìš©)
            logger.info(f"ğŸ§  Getting user behavior vector for user {user_id}")
            user_behavior_vector = await self._get_user_behavior_vector_cached(user_id)
            if user_behavior_vector is not None:
                logger.info(f"âœ… Found behavior vector for user {user_id}: shape {user_behavior_vector.shape}")
            else:
                logger.info(f"âŒ No behavior vector found for user {user_id}")

            # 3. ìš°ì„ ìˆœìœ„ íƒœê·¸ ë‚´ì—ì„œ behavior_vector í†µí•©ëœ ì ìˆ˜ ê³„ì‚°
            recommendations = await self._calculate_priority_enhanced_scores(
                user_preferences, user_behavior_vector, region, category, limit
            )

            logger.info(f"âœ… Generated {len(recommendations)} priority-enhanced recommendations for user {user_id}")
            return recommendations

        except Exception as e:
            logger.error(f"âŒ Priority-enhanced recommendation failed for user {user_id}: {e}")
            return []

    async def _get_user_preferences(self, user_id: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì„ í˜¸ë„ ì •ë³´ ì¡°íšŒ (user_preferences í…Œì´ë¸”ì—ì„œ ì¡°íšŒ)"""
        try:
            # user_preferences í…Œì´ë¸”ì—ì„œ ì„ í˜¸ë„ ì •ë³´ ì¡°íšŒ (ì˜¬ë°”ë¥¸ ìŠ¤í‚¤ë§ˆ)
            preferences_query = """
                SELECT
                    priority,
                    accommodation,
                    exploration,
                    persona
                FROM user_preferences
                WHERE user_id = $1
            """

            # user_preference_tags í…Œì´ë¸”ì—ì„œ íƒœê·¸ ì •ë³´ ì¡°íšŒ (í˜„ì¬ ìŠ¤í‚¤ë§ˆ)
            tags_query = """
                SELECT
                    tag,
                    weight
                FROM user_preference_tags
                WHERE user_id = $1
                ORDER BY weight DESC
            """

            # ë³‘ë ¬ë¡œ ë‘ ì¿¼ë¦¬ ì‹¤í–‰
            async with self.db_manager.get_connection() as conn:
                preferences_data = await conn.fetchrow(preferences_query, user_id)
                tags_data = await conn.fetch(tags_query, user_id)

            if not preferences_data and not tags_data:
                return {}

            # ê²°ê³¼ êµ¬ì„± (í˜„ì¬ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ)
            result = {
                'user_id': user_id,  # user_id ì¶”ê°€
                'priority': preferences_data.get('priority') if preferences_data else None,
                'accommodation': preferences_data.get('accommodation') if preferences_data else None,
                'exploration': preferences_data.get('exploration') if preferences_data else None,
                'persona': preferences_data.get('persona') if preferences_data else None,
                'preference_tags': {
                    row['tag']: row['weight']
                    for row in tags_data
                }
            }

            return result

        except Exception as e:
            logger.error(f"âŒ Failed to get user preferences for {user_id}: {e}")
            return {}

    async def _calculate_priority_enhanced_scores(
        self,
        user_preferences: Dict[str, Any],
        user_behavior_vector: Optional[np.ndarray],
        region: Optional[str] = None,
        category: Optional[str] = None,
        limit: int = 20
    ) -> List[Dict]:
        """
        ğŸ¯ ìš°ì„ ìˆœìœ„ íƒœê·¸ ë‚´ì—ì„œ behavior_vectorë¥¼ í™œìš©í•œ í–¥ìƒëœ ì ìˆ˜ ê³„ì‚°
        1. ìš°ì„ ìˆœìœ„ íƒœê·¸ë¡œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§
        2. í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ë‚´ì—ì„œ behavior_vectorë¡œ ê°œì¸í™”
        3. ì„ í˜¸ë„ íƒœê·¸ì™€ í–‰ë™ íŒ¨í„´ì„ ì¢…í•©í•œ ì ìˆ˜ ì‚°ì¶œ
        """
        try:
            priority = user_preferences.get('priority')

            # ìš°ì„ ìˆœìœ„ íƒœê·¸ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë¡œ í•„í„°ë§
            target_category = category
            if priority:
                # ì²´í—˜ ìš°ì„ ìˆœìœ„ëŠ” nature/humanities/leisure_sports ì¤‘ì—ì„œ ì„ íƒ
                if priority == 'experience':
                    if category not in ['nature', 'humanities', 'leisure_sports']:
                        target_category = 'nature'  # ê¸°ë³¸ê°’
                else:
                    # ë‹¤ë¥¸ ìš°ì„ ìˆœìœ„ëŠ” í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë¡œ ê³ ì •
                    target_category = priority

            logger.info(f"ğŸ¯ Priority filtering: {priority} â†’ target_category: {target_category}")

            # ìš°ì„ ìˆœìœ„ ì¹´í…Œê³ ë¦¬ ë‚´ì—ì„œ ì¥ì†Œ í›„ë³´êµ° ì¡°íšŒ (ë²¡í„° í¬í•¨)
            places_query = """
                SELECT
                    place_id, table_name, region, name,
                    latitude, longitude, overview, image_urls, bookmark_cnt,
                    vector as text_vector,
                    COALESCE(bookmark_cnt, 0) as popularity_score
                FROM place_recommendations
                WHERE name IS NOT NULL
                    AND ($1::text IS NULL OR region = $1)
                    AND ($2::text IS NULL OR table_name = $2)
                ORDER BY bookmark_cnt DESC
                LIMIT $3
            """

            async with self.db_manager.get_connection() as conn:
                places_data = await conn.fetch(
                    places_query,
                    region,
                    target_category,
                    CONFIG.candidate_limit
                )

            if not places_data:
                logger.warning(f"No places found for priority: {priority}, region: {region}, category: {target_category}")
                return []

            # ìš°ì„ ìˆœìœ„ íƒœê·¸ ë‚´ì—ì„œ behavior_vector ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
            scored_places = []
            popularity_normalizer = CONFIG.preference_weights['popularity_normalizer']

            for place in places_data:
                # 1. ê¸°ë³¸ ì„ í˜¸ë„ ì ìˆ˜ (ìš°ì„ ìˆœìœ„ íƒœê·¸ ë§¤ì¹­)
                preference_score = self._calculate_place_preference_score(place, user_preferences)

                # 2. behavior_vector ê¸°ë°˜ ê°œì¸í™” ì ìˆ˜ (ìš°ì„ ìˆœìœ„ ì¹´í…Œê³ ë¦¬ ë‚´ì—ì„œ)
                behavior_score = 0.0
                if user_behavior_vector is not None and place.get('text_vector'):
                    place_text_vector = validate_vector_data(place['text_vector'])
                    if place_text_vector is not None:
                        similarity = safe_cosine_similarity(user_behavior_vector, place_text_vector)
                        behavior_score = float(similarity[0]) if len(similarity) > 0 else 0.0
                        logger.info(f"ğŸ§  {place['name']}: behavior_score={behavior_score:.4f}")
                    else:
                        logger.info(f"âš ï¸ {place['name']}: invalid text_vector")
                else:
                    if user_behavior_vector is None:
                        logger.info(f"âŒ {place['name']}: no behavior_vector for user")
                    else:
                        logger.info(f"âŒ {place['name']}: no text_vector for place")

                # 3. ìš°ì„ ìˆœìœ„ íƒœê·¸ ë‚´ ì¢…í•© ì ìˆ˜ ê³„ì‚°
                if preference_score > 0 or behavior_score > 0:
                    place_dict = dict(place)
                    popularity_normalized = min(place['popularity_score'] / popularity_normalizer, 1.0)

                    # ğŸ¯ ìš°ì„ ìˆœìœ„ íƒœê·¸ ë‚´ì—ì„œ ì„ í˜¸ë„(70%) + í–‰ë™íŒ¨í„´(20%) + ì¸ê¸°ë„(10%) ê°€ì¤‘ì¹˜
                    priority_weight = 0.7   # ìš°ì„ ìˆœìœ„ íƒœê·¸ ê¸°ë°˜ ì„ í˜¸ë„
                    behavior_weight = 0.2   # ë¶ë§ˆí¬ í–‰ë™ íŒ¨í„´
                    popularity_weight = 0.1 # ì¼ë°˜ì  ì¸ê¸°ë„

                    final_score = (
                        preference_score * priority_weight +
                        behavior_score * behavior_weight +
                        popularity_normalized * popularity_weight
                    )

                    place_dict['preference_score'] = preference_score
                    place_dict['behavior_score'] = behavior_score
                    place_dict['final_score'] = final_score
                    place_dict['source'] = 'priority_enhanced'
                    scored_places.append(place_dict)

            # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
            scored_places.sort(key=lambda x: x['final_score'], reverse=True)

            # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
            for place in scored_places[:limit]:
                if 'text_vector' in place and isinstance(place['text_vector'], np.ndarray):
                    place['text_vector'] = place['text_vector'].tolist()
                if 'image_vector' in place and isinstance(place['image_vector'], np.ndarray):
                    place['image_vector'] = place['image_vector'].tolist()

            behavior_used = user_behavior_vector is not None
            logger.info(f"ğŸš€ Priority-enhanced scoring completed: {len(scored_places[:limit])} results, behavior_vector: {'âœ…' if behavior_used else 'âŒ'}")

            return scored_places[:limit]

        except Exception as e:
            logger.error(f"âŒ Failed to calculate priority-enhanced scores: {e}")
            return []

    async def get_user_priority_tag(self, user_id: str) -> Optional[str]:
        """ì‚¬ìš©ìì˜ ì—¬í–‰ ìš°ì„ ìˆœìœ„ íƒœê·¸ ì¡°íšŒ"""
        try:
            async with self.db_manager.get_connection() as conn:
                query = """
                    SELECT priority
                    FROM user_preferences
                    WHERE user_id = $1
                """
                result = await conn.fetchval(query, user_id)
                return result
        except Exception as e:
            logger.error(f"âŒ Failed to get user priority tag for {user_id}: {e}")
            return None

    async def _calculate_preference_scores(
        self,
        user_preferences: Dict[str, Any],
        region: Optional[str] = None,
        category: Optional[str] = None,
        limit: int = 20
    ) -> List[Dict]:
        """ì„ í˜¸ë„ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° ë° ì¶”ì²œ ìƒì„±"""
        try:
            # ì¥ì†Œ í›„ë³´êµ° ì¡°íšŒ
            places_query = """
                SELECT
                    place_id, table_name, region, name,
                    latitude, longitude, overview, image_urls, bookmark_cnt,
                    COALESCE(bookmark_cnt, 0) as popularity_score
                FROM place_recommendations
                WHERE name IS NOT NULL
                    AND ($1::text IS NULL OR region = $1)
                    AND ($2::text IS NULL OR table_name = $2)
                ORDER BY bookmark_cnt DESC
                LIMIT $3
            """

            async with self.db_manager.get_connection() as conn:
                places_data = await conn.fetch(
                    places_query,
                    region,
                    category,
                    CONFIG.candidate_limit
                )

            if not places_data:
                return []

            # ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° ë° ì •ë ¬
            scored_places = []
            popularity_normalizer = CONFIG.preference_weights['popularity_normalizer']

            for place in places_data:
                preference_score = self._calculate_place_preference_score(place, user_preferences)

                if preference_score > 0:
                    place_dict = dict(place)
                    popularity_normalized = min(place['popularity_score'] / popularity_normalizer, 1.0)
                    final_score = (preference_score * CONFIG.similarity_weight) + (popularity_normalized * CONFIG.popularity_weight)

                    place_dict['preference_score'] = preference_score
                    place_dict['final_score'] = final_score
                    scored_places.append(place_dict)

            scored_places.sort(key=lambda x: x['final_score'], reverse=True)
            
            # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
            for place in scored_places[:limit]:
                if 'vector' in place and isinstance(place['vector'], np.ndarray):
                    place['vector'] = place['vector'].tolist()
                if 'text_vector' in place and isinstance(place['text_vector'], np.ndarray):
                    place['text_vector'] = place['text_vector'].tolist()
                if 'image_vector' in place and isinstance(place['image_vector'], np.ndarray):
                    place['image_vector'] = place['image_vector'].tolist()
            
            return scored_places[:limit]

        except Exception as e:
            logger.error(f"âŒ Failed to calculate preference scores: {e}")
            return []

    def _calculate_place_preference_score(
        self,
        place: Dict[str, Any],
        user_preferences: Dict[str, Any]
    ) -> float:
        """ê°œë³„ ì¥ì†Œì— ëŒ€í•œ ì„ í˜¸ë„ ì ìˆ˜ ê³„ì‚° (í˜„ì¬ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ìˆ˜ì •)"""
        score = 0.0

        try:
            weights = CONFIG.preference_weights

            # í˜ë¥´ì†Œë‚˜ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ì„ í˜¸ë„
            persona = user_preferences.get('persona')
            if persona and place['table_name']:
                # í˜ë¥´ì†Œë‚˜ë³„ ì¹´í…Œê³ ë¦¬ ë³´ë„ˆìŠ¤
                persona_bonuses = {
                    'culture_lover': {'humanities': 0.3, 'culture': 0.3},
                    'nature_lover': {'nature': 0.3, 'leisure_sports': 0.2},
                    'foodie': {'restaurants': 0.4},
                    'shopper': {'shopping': 0.3},
                    'luxury_traveler': {'accommodation': 0.2, 'restaurants': 0.2}
                }

                if persona in persona_bonuses:
                    category_bonus = persona_bonuses[persona].get(place['table_name'], 0)
                    score += category_bonus

            # ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì ìˆ˜ (ì¹´í…Œê³ ë¦¬ ìš°ì„ ìˆœìœ„ ì§€ì›)
            priority = user_preferences.get('priority')
            if priority:
                # ì¹´í…Œê³ ë¦¬ ìš°ì„ ìˆœìœ„ ì²˜ë¦¬ (ì´ˆê°•ë ¥ í¸í–¥)
                if priority == place['table_name']:
                    score += 10.0  # ì¹´í…Œê³ ë¦¬ ì •í™•íˆ ì¼ì¹˜ ì‹œ ë§¤ìš° ê°•ë ¥í•œ ë³´ë„ˆìŠ¤
                    logger.info(f"ğŸ¯ CATEGORY MATCH BOOST: {place.get('name', 'Unknown')} gets +10.0 for matching {priority} priority")

                # ì¹´í…Œê³ ë¦¬ ë§¤í•‘ì„ í†µí•œ ì¶”ê°€ ë§¤ì¹­
                priority_category_map = {
                    'accommodation': ['accommodation'],
                    'restaurants': ['restaurants'],
                    'shopping': ['shopping'],
                    'nature': ['nature'],
                    'culture': ['humanities'],
                    'leisure': ['leisure_sports']
                }

                if priority in priority_category_map:
                    if place['table_name'] in priority_category_map[priority]:
                        score += 10.0  # ë§¤í•‘ëœ ì¹´í…Œê³ ë¦¬ ì¼ì¹˜ ì‹œì—ë„ ê°•ë ¥í•œ ë³´ë„ˆìŠ¤
                        logger.info(f"ğŸ¯ MAPPED CATEGORY BOOST: {place.get('name', 'Unknown')} gets +10.0 for {priority} -> {place['table_name']} mapping")

                # ê¸°ì¡´ popular/unique ì²˜ë¦¬ (ê¸°ë³¸ ë³´ë„ˆìŠ¤)
                if priority == 'popular' and place.get('bookmark_cnt', 0) > 1000:
                    score += 0.5
                elif priority == 'unique' and place.get('bookmark_cnt', 0) < 500:
                    score += 0.5

            # ì´ˆê°•ë ¥ íƒœê·¸ ë§¤ì¹­ ì‹œìŠ¤í…œ (ê³µê²©ì  í¸í–¥)
            preference_tags = user_preferences.get('preference_tags', {})
            if preference_tags:
                place_description = (place.get('description', '') or '').lower()
                place_name = (place.get('name', '') or '').lower()
                combined_text = place_description + ' ' + place_name

                tag_score, tag_count, max_weight = 0.0, 0, 0

                for tag_name, tag_weight in preference_tags.items():
                    tag_lower = tag_name.lower()

                    # ë‹¤ì–‘í•œ ë§¤ì¹­ ì „ëµ (ë” ê³µê²©ì )
                    match_found = False
                    match_strength = 0.0

                    # 1. ì™„ì „ ì¼ì¹˜ (100% ë§¤ì¹­)
                    if tag_lower in combined_text:
                        match_strength = 1.0
                        match_found = True

                    # 2. ë¶€ë¶„ ë§¤ì¹­ (ì–´ê·¼ ë§¤ì¹­ 70%)
                    elif any(word in combined_text for word in tag_lower.split()):
                        match_strength = 0.7
                        match_found = True

                    # 3. ìœ ì‚¬ ë‹¨ì–´ ë§¤ì¹­ (ë°”ì´ì–´ìŠ¤ 60%)
                    else:
                        # ê¸°ë³¸ ìœ ì‚¬ ì—°ê²° ì‚¬ì „
                        similar_words = {
                            'ìì—°': ['ì‚°', 'ë°”ë‹¤', 'í˜¸ìˆ˜', 'ê³µì›', 'ìˆ²', 'í•˜ì´í‚¹', 'íŠ¸ë ˆí‚¹'],
                            'ë¬¸í™”': ['ë°•ë¬¼ê´€', 'ë¯¸ìˆ ê´€', 'ì ˆ', 'ê¶ê¶', 'ì „í†µ', 'ì—­ì‚¬', 'í™”ê°€'],
                            'ë§›ì§‘': ['ìŒì‹', 'ë ˆìŠ¤í† ë‘', 'ì¹´í˜', 'ë°¥ì§‘', 'í•œì‹', 'ì–‘ì‹'],
                            'ì‡¼í•‘': ['ë§ˆíŠ¸', 'ë°±í™”ì ', 'ì•„ìš¸ë ›', 'ì‹œì¥', 'ìƒê°€'],
                            'ì²´í—˜': ['ì•¡í‹°ë¹„í‹°', 'ë ˆì €', 'ë†€ì´', 'ì¶•ì œ', 'ê³µì—°']
                        }

                        for similar_key, similar_list in similar_words.items():
                            if tag_lower == similar_key and any(word in combined_text for word in similar_list):
                                match_strength = 0.6
                                match_found = True
                                break

                    if match_found:
                        # ê°€ì¤‘ì¹˜ ë°˜ì˜: 1-10 ìŠ¤ì¼€ì¼ì„ ë” ê³µê²©ì ìœ¼ë¡œ í™œìš©
                        raw_weight = tag_weight / 10.0  # 0.1 ~ 1.0

                        # ì´ˆê°•ë ¥ ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ
                        if tag_weight >= 8:  # ìµœê³  ìš°ì„ ìˆœìœ„ (80% ì´ìƒ)
                            boosted_weight = raw_weight * 3.0 * match_strength  # 3ë°° ë¶€ìŠ¤íŠ¸
                        elif tag_weight >= 6:  # ë†’ì€ ìš°ì„ ìˆœìœ„ (60% ì´ìƒ)
                            boosted_weight = raw_weight * 2.5 * match_strength  # 2.5ë°° ë¶€ìŠ¤íŠ¸
                        elif tag_weight >= 4:  # ì¤‘ê°„ ìš°ì„ ìˆœìœ„ (40% ì´ìƒ)
                            boosted_weight = raw_weight * 2.0 * match_strength  # 2ë°° ë¶€ìŠ¤íŠ¸
                        else:
                            boosted_weight = raw_weight * match_strength  # ê¸°ë³¸ ê°€ì¤‘ì¹˜

                        tag_score += boosted_weight
                        tag_count += 1
                        max_weight = max(max_weight, boosted_weight)

                if tag_count > 0:
                    # ì´ˆê°•ë ¥ íƒœê·¸ ì ìˆ˜ ì ìš©
                    # 1. ê¸°ë³¸ ì ìˆ˜: í‰ê·  ëŒ€ì‹  ìµœëŒ€ê°’ ì‚¬ìš© (ë” ê³µê²©ì )
                    primary_score = min(max_weight, 2.0)  # ìµœëŒ€ 2.0ì 

                    # 2. ë‹¤ì¤‘ ë§¤ì¹­ ë³´ë„ˆìŠ¤ (ì—¬ëŸ¬ íƒœê·¸ ë§¤ì¹­ ì‹œ ì¶”ê°€ ì ìˆ˜)
                    multi_match_bonus = min((tag_count - 1) * 0.3, 1.0)  # ìµœëŒ€ 1.0ì  ë³´ë„ˆìŠ¤

                    # 3. ìµœì¢… íƒœê·¸ ì ìˆ˜
                    final_tag_score = (primary_score + multi_match_bonus) * weights['tag']

                    # 4. ì¶”ê°€ ë¶€ìŠ¤íŠ¸ (CONFIGì—ì„œ ì„¤ì •í•œ ë§¤ê°œë³€ìˆ˜)
                    if 'tag_boost_multiplier' in weights:
                        final_tag_score *= weights['tag_boost_multiplier']

                    score += final_tag_score

                    # ë””ë²„ê¹… ë¡œê·¸
                    logger.debug(f"íƒœê·¸ ë§¤ì¹­ - ì¥ì†Œ: {place.get('name')}, ë§¤ì¹­ìˆ˜: {tag_count}, ìµœëŒ€ê°€ì¤‘ì¹˜: {max_weight:.3f}, ìµœì¢…ì ìˆ˜: {final_tag_score:.3f}")

            # íƒí—˜ ì„±í–¥ ë°˜ì˜
            exploration = user_preferences.get('exploration')
            if exploration == 'adventurous' and place['table_name'] in ['nature', 'leisure_sports']:
                score += 0.1
            elif exploration == 'comfort' and place['table_name'] in ['accommodation', 'restaurants']:
                score += 0.1

            return min(score, 1.0)

        except Exception as e:
            logger.error(f"âŒ Failed to calculate preference score for place {place.get('place_id')}: {e}")
            return 0.0

    async def _get_place_candidates_with_images(
        self,
        region: Optional[str],
        category: Optional[str]
    ) -> List[Dict]:
        """ì´ë¯¸ì§€ ë²¡í„°ë¥¼ í¬í•¨í•œ ì¥ì†Œ í›„ë³´êµ° ì¡°íšŒ"""
        try:
            query = """
                SELECT
                    pr.place_id::text as place_id,
                    pr.table_name,
                    pr.vector as text_vector,
                    pr.image_vector,
                    COALESCE(pr.bookmark_cnt, 0) as total_likes,
                    COALESCE(pr.bookmark_cnt, 0) as total_bookmarks,
                    COALESCE(pr.bookmark_cnt, 0) as total_clicks,
                    1 as unique_users,
                    COALESCE(pr.bookmark_cnt, 0)::float as popularity_score,
                    COALESCE(pr.bookmark_cnt, 0)::float as engagement_score,
                    pr.name,
                    pr.region,
                    pr.city,
                    pr.latitude,
                    pr.longitude,
                    pr.overview as description,
                    pr.image_urls,
                    pr.bookmark_cnt
                FROM place_recommendations pr
                WHERE
                    pr.vector IS NOT NULL
                    AND pr.name IS NOT NULL
                    AND pr.bookmark_cnt IS NOT NULL
            """

            params = []
            param_count = 0

            if region:
                param_count += 1
                query += f" AND pr.region = ${param_count}"
                params.append(region)

            if category:
                param_count += 1
                query += f" AND pr.table_name = ${param_count}::text"
                params.append(category)

            query += " ORDER BY COALESCE(pr.bookmark_cnt, 0) DESC"
            param_count += 1
            query += f" LIMIT ${param_count}"
            params.append(CONFIG.candidate_limit)

            places = await self.db_manager.execute_query(query, *params)

            # í…ìŠ¤íŠ¸ ë²¡í„°ëŠ” í•„ìˆ˜, ì´ë¯¸ì§€ ë²¡í„°ëŠ” ì„ íƒì 
            valid_places = []
            for place in places:
                text_vector = validate_vector_data(place['text_vector'])
                if text_vector is not None:
                    place['text_vector'] = text_vector

                    # ì´ë¯¸ì§€ ë²¡í„°ëŠ” ìˆìœ¼ë©´ ì¶”ê°€, ì—†ìœ¼ë©´ None
                    image_vector = validate_vector_data(place.get('image_vector'))
                    place['image_vector'] = image_vector

                    # S3 ì´ë¯¸ì§€ URLì„ HTTPSë¡œ ë³€í™˜
                    place = self._convert_s3_urls_to_https(place)
                    valid_places.append(place)

            logger.info(f"ğŸ“‹ Retrieved {len(valid_places)} places with text vectors ({sum(1 for p in valid_places if p['image_vector'] is not None)} with image vectors)")
            return valid_places

        except Exception as e:
            logger.error(f"âŒ Failed to get place candidates with images: {e}")
            return []

    async def _get_user_image_preferences(self, user_id: str) -> Dict[str, np.ndarray]:
        """ì‚¬ìš©ìì˜ ì´ë¯¸ì§€ ì„ í˜¸ë„ ë²¡í„° ìˆ˜ì§‘ (ë¶ë§ˆí¬, ì¢‹ì•„ìš” ê¸°ë°˜)"""
        try:

            # 1. ë¶ë§ˆí¬í•œ ì¥ì†Œë“¤ì˜ ì´ë¯¸ì§€ ë²¡í„° ìˆ˜ì§‘
            bookmark_query = """
                SELECT pr.image_vector
                FROM saved_locations sl
                JOIN place_recommendations pr ON pr.place_id = CAST(SPLIT_PART(sl.places, ':', 2) AS INTEGER)
                    AND pr.table_name = SPLIT_PART(sl.places, ':', 1)
                WHERE sl.user_id = $1
                    AND pr.image_vector IS NOT NULL
                LIMIT 20
            """

            # 2. ì¢‹ì•„ìš”í•œ í¬ìŠ¤íŠ¸ë“¤ì˜ ì´ë¯¸ì§€ ë²¡í„° ìˆ˜ì§‘ (posts.image_vectorëŠ” PostgreSQL vector íƒ€ì…)
            liked_posts_query = """
                SELECT p.image_vector
                FROM user_actions ua
                JOIN posts p ON p.id = CAST(ua.place_id AS INTEGER)
                WHERE ua.user_id = $1
                    AND ua.action_type = 'like'
                    AND ua.place_category = 'posts'
                    AND p.image_vector IS NOT NULL
                LIMIT 20
            """

            # 3. ì‚¬ìš©ìê°€ ì§ì ‘ ì—…ë¡œë“œí•œ í¬ìŠ¤íŠ¸ë“¤ì˜ ì´ë¯¸ì§€ ë²¡í„° ìˆ˜ì§‘ (ìì‹ ì˜ ì„ í˜¸ë„ ë°˜ì˜)
            user_posts_query = """
                SELECT image_vector
                FROM posts
                WHERE user_id = $1
                    AND image_vector IS NOT NULL
                LIMIT 30
            """

            bookmark_vectors = await self.db_manager.execute_query(bookmark_query, user_id)
            liked_post_vectors = await self.db_manager.execute_query(liked_posts_query, user_id)
            user_post_vectors = await self.db_manager.execute_query(user_posts_query, user_id)

            # ë²¡í„° ìˆ˜ì§‘ ë° ê²€ì¦ (ë¶„ë¦¬ëœ ë¦¬ìŠ¤íŠ¸ë¡œ)
            bookmark_image_vectors = []
            liked_post_image_vectors = []
            user_upload_image_vectors = []

            # 1. ë¶ë§ˆí¬í•œ ì¥ì†Œ ì´ë¯¸ì§€ ë²¡í„°
            for row in bookmark_vectors:
                vector = validate_vector_data(row['image_vector'])
                if vector is not None:
                    bookmark_image_vectors.append(vector)

            # 2. ì¢‹ì•„ìš”í•œ í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ ë²¡í„° (ë…ë¦½ì ìœ¼ë¡œ ìˆ˜ì§‘)
            for row in liked_post_vectors:
                vector = validate_vector_data(row['image_vector'])
                if vector is not None:
                    liked_post_image_vectors.append(vector)

            # 3. ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ ë²¡í„° (ë…ë¦½ì ìœ¼ë¡œ ìˆ˜ì§‘)
            for row in user_post_vectors:
                vector = validate_vector_data(row['image_vector'])
                if vector is not None:
                    user_upload_image_vectors.append(vector)

            total_vectors = len(bookmark_image_vectors) + len(liked_post_image_vectors) + len(user_upload_image_vectors)

            if total_vectors == 0:
                logger.info(f"No image preferences found for user {user_id}")
                return {}

            logger.info(f"ğŸ“¸ User {user_id} image preferences: {total_vectors} total vectors (ë¶ë§ˆí¬: {len(bookmark_image_vectors)}, ì¢‹ì•„ìš”: {len(liked_post_image_vectors)}, ì—…ë¡œë“œ: {len(user_upload_image_vectors)})")

            return {
                'bookmarks': bookmark_image_vectors,       # ë¶ë§ˆí¬ ì¥ì†Œ ì´ë¯¸ì§€ (ì±„ë„4 ì‚¬ìš©)
                'liked_posts': liked_post_image_vectors,   # ì¢‹ì•„ìš” í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ (ì±„ë„5 ì‚¬ìš©)
                'user_uploads': user_upload_image_vectors, # ì—…ë¡œë“œ í¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ (ì±„ë„2 ì‚¬ìš©)
                'source_breakdown': {
                    'bookmarks': len(bookmark_image_vectors),
                    'liked_posts': len(liked_post_image_vectors),
                    'user_posts': len(user_upload_image_vectors)
                }
            }

        except Exception as e:
            logger.error(f"âŒ Failed to get user image preferences for {user_id}: {e}")
            return {}

    async def _calculate_independent_similarities(
        self,
        user_id: str,
        user_behavior_vector: np.ndarray,
        user_image_preferences: Dict[str, Any],
        places: List[Dict]
    ) -> List[Dict[str, float]]:
        """
        ë…ë¦½ì ì¸ ê²€ìƒ‰ ì±„ë„ ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° (5ê°œ ì±„ë„)
        1. í–‰ë™ë²¡í„°(í´ë¦­/ë¶ë§ˆí¬) â†’ ì¥ì†Œ í…ìŠ¤íŠ¸
        2. ì‚¬ìš©ì ì—…ë¡œë“œ í¬ìŠ¤íŒ… ì´ë¯¸ì§€ â†’ ì¥ì†Œ ì´ë¯¸ì§€
        3. ë¶ë§ˆí¬ ì¥ì†Œ í…ìŠ¤íŠ¸ â†’ ë‹¤ë¥¸ ì¥ì†Œ í…ìŠ¤íŠ¸
        4. ë¶ë§ˆí¬ ì¥ì†Œ ì´ë¯¸ì§€ â†’ ë‹¤ë¥¸ ì¥ì†Œ ì´ë¯¸ì§€
        5. ì¢‹ì•„ìš”í•œ í¬ìŠ¤íŒ… ì´ë¯¸ì§€ â†’ ì¥ì†Œ ì´ë¯¸ì§€
        """
        results = []

        try:
            # ì´ë¯¸ì§€ ì„ í˜¸ë„ ë¶„ë¦¬ (ì—…ë¡œë“œ vs ì¢‹ì•„ìš”)
            user_upload_images = user_image_preferences.get('user_uploads', [])
            liked_post_images = user_image_preferences.get('liked_posts', [])

            # í‰ê·  ë²¡í„° ê³„ì‚° (ì•ˆì „í•œ ì²˜ë¦¬)
            user_upload_vector = None
            if user_upload_images and len(user_upload_images) > 0:
                try:
                    user_upload_vector = np.mean(user_upload_images, axis=0)
                except Exception as e:
                    logger.warning(f"Failed to calculate user upload vector mean: {e}")

            liked_posts_vector = None
            if liked_post_images and len(liked_post_images) > 0:
                try:
                    liked_posts_vector = np.mean(liked_post_images, axis=0)
                except Exception as e:
                    logger.warning(f"Failed to calculate liked posts vector mean: {e}")

            # ì‚¬ìš©ì ë¶ë§ˆí¬ ì¥ì†Œ ê¸°ë°˜ ì„ í˜¸ë„ ì¶”ì¶œ
            bookmark_preferences = await self._get_detailed_bookmark_preferences(user_id)

            for place in places:
                scores = {
                    'behavior_text_similarity': 0.0,     # í–‰ë™ë²¡í„°(í´ë¦­/ë¶ë§ˆí¬) â†’ ì¥ì†Œí…ìŠ¤íŠ¸
                    'upload_image_similarity': 0.0,      # ì—…ë¡œë“œ í¬ìŠ¤íŒ…ì´ë¯¸ì§€ â†’ ì¥ì†Œì´ë¯¸ì§€
                    'bookmark_text_similarity': 0.0,     # ë¶ë§ˆí¬ì¥ì†Œí…ìŠ¤íŠ¸ â†’ ì¥ì†Œí…ìŠ¤íŠ¸
                    'bookmark_image_similarity': 0.0,    # ë¶ë§ˆí¬ì¥ì†Œì´ë¯¸ì§€ â†’ ì¥ì†Œì´ë¯¸ì§€
                    'liked_post_similarity': 0.0,        # ì¢‹ì•„ìš” í¬ìŠ¤íŒ…ì´ë¯¸ì§€ â†’ ì¥ì†Œì´ë¯¸ì§€
                    'combined_score': 0.0
                }

                # 1. í–‰ë™ ë²¡í„°(í´ë¦­/ë¶ë§ˆí¬) â†’ ì¥ì†Œ í…ìŠ¤íŠ¸ (384ì°¨ì›)
                place_text_vector = place.get('text_vector')
                if place_text_vector is not None and user_behavior_vector is not None:
                    text_sim = safe_cosine_similarity(user_behavior_vector, place_text_vector)
                    scores['behavior_text_similarity'] = float(text_sim[0]) if len(text_sim) > 0 else 0.0

                # 2. ì—…ë¡œë“œ í¬ìŠ¤íŒ… ì´ë¯¸ì§€ â†’ ì¥ì†Œ ì´ë¯¸ì§€ (512ì°¨ì›)
                place_image_vector = place.get('image_vector')
                if user_upload_vector is not None and place_image_vector is not None:
                    upload_sim = safe_cosine_similarity(user_upload_vector, place_image_vector)
                    scores['upload_image_similarity'] = float(upload_sim[0]) if len(upload_sim) > 0 else 0.0

                # 3. ë¶ë§ˆí¬ ì¥ì†Œ í…ìŠ¤íŠ¸ â†’ ì¥ì†Œ í…ìŠ¤íŠ¸ (384ì°¨ì›)
                if bookmark_preferences.get('avg_text_vector') is not None and place_text_vector is not None:
                    bookmark_text_sim = safe_cosine_similarity(
                        bookmark_preferences['avg_text_vector'], place_text_vector
                    )
                    scores['bookmark_text_similarity'] = float(bookmark_text_sim[0]) if len(bookmark_text_sim) > 0 else 0.0

                # 4. ë¶ë§ˆí¬ ì¥ì†Œ ì´ë¯¸ì§€ â†’ ì¥ì†Œ ì´ë¯¸ì§€ (512ì°¨ì›)
                if bookmark_preferences.get('avg_image_vector') is not None and place_image_vector is not None:
                    bookmark_image_sim = safe_cosine_similarity(
                        bookmark_preferences['avg_image_vector'], place_image_vector
                    )
                    scores['bookmark_image_similarity'] = float(bookmark_image_sim[0]) if len(bookmark_image_sim) > 0 else 0.0

                # 5. ì¢‹ì•„ìš”í•œ í¬ìŠ¤íŒ… ì´ë¯¸ì§€ â†’ ì¥ì†Œ ì´ë¯¸ì§€ (512ì°¨ì›)
                if liked_posts_vector is not None and place_image_vector is not None:
                    liked_sim = safe_cosine_similarity(liked_posts_vector, place_image_vector)
                    scores['liked_post_similarity'] = float(liked_sim[0]) if len(liked_sim) > 0 else 0.0

                # 6. 5ê°œ ë…ë¦½ì  ì±„ë„ë“¤ì˜ ì¡°í•© ì ìˆ˜ ê³„ì‚°
                channel_scores = [
                    scores['behavior_text_similarity'] * 0.25,     # í–‰ë™ê¸°ë°˜ í…ìŠ¤íŠ¸
                    scores['upload_image_similarity'] * 0.25,      # ì—…ë¡œë“œ í¬ìŠ¤íŒ… ì´ë¯¸ì§€
                    scores['bookmark_text_similarity'] * 0.2,      # ë¶ë§ˆí¬ í…ìŠ¤íŠ¸
                    scores['bookmark_image_similarity'] * 0.15,    # ë¶ë§ˆí¬ ì´ë¯¸ì§€
                    scores['liked_post_similarity'] * 0.15         # ì¢‹ì•„ìš” í¬ìŠ¤íŒ… ì´ë¯¸ì§€
                ]

                # ìœ íš¨í•œ ì±„ë„ë“¤ë§Œ ì¡°í•©
                valid_scores = [score for score in channel_scores if score > 0]
                if valid_scores:
                    scores['combined_score'] = sum(valid_scores) / len(valid_scores)
                    # ë‹¤ì¤‘ ì±„ë„ ë³´ë„ˆìŠ¤
                    if len(valid_scores) > 1:
                        scores['combined_score'] += 0.1 * (len(valid_scores) - 1)
                else:
                    scores['combined_score'] = 0.0

                results.append(scores)

            logger.info(f"ğŸ”„ Calculated independent channel similarities for {len(results)} places")
            return results

        except Exception as e:
            logger.error(f"âŒ Independent similarity calculation failed: {e}")
            # ë¹ˆ ì ìˆ˜ ë°˜í™˜
            return [{
                'behavior_text_similarity': 0.0,
                'upload_image_similarity': 0.0,
                'bookmark_text_similarity': 0.0,
                'bookmark_image_similarity': 0.0,
                'liked_post_similarity': 0.0,
                'combined_score': 0.0
            } for _ in places]

    async def _get_detailed_bookmark_preferences(self, user_id: str) -> Dict[str, np.ndarray]:
        """ë¶ë§ˆí¬í•œ ì¥ì†Œë“¤ì˜ ìƒì„¸ ë²¡í„° ì„ í˜¸ë„ ì¶”ì¶œ"""
        try:
            # ë¶ë§ˆí¬í•œ ì¥ì†Œë“¤ì˜ í…ìŠ¤íŠ¸ ë° ì´ë¯¸ì§€ ë²¡í„° ì¡°íšŒ
            query = """
                SELECT pr.vector as text_vector, pr.image_vector
                FROM saved_locations sl
                JOIN place_recommendations pr ON pr.place_id = CAST(SPLIT_PART(sl.places, ':', 2) AS INTEGER)
                    AND pr.table_name = SPLIT_PART(sl.places, ':', 1)
                WHERE sl.user_id = $1
                    AND (pr.vector IS NOT NULL OR pr.image_vector IS NOT NULL)
                LIMIT 30
            """

            bookmark_data = await self.db_manager.execute_query(query, user_id)

            text_vectors = []
            image_vectors = []

            for row in bookmark_data:
                # í…ìŠ¤íŠ¸ ë²¡í„° ìˆ˜ì§‘
                if row['text_vector']:
                    text_vector = validate_vector_data(row['text_vector'])
                    if text_vector is not None:
                        text_vectors.append(text_vector)

                # ì´ë¯¸ì§€ ë²¡í„° ìˆ˜ì§‘
                if row['image_vector']:
                    image_vector = validate_vector_data(row['image_vector'])
                    if image_vector is not None:
                        image_vectors.append(image_vector)

            result = {}

            # í‰ê·  í…ìŠ¤íŠ¸ ë²¡í„° ê³„ì‚° (ì•ˆì „í•œ ì²˜ë¦¬)
            if text_vectors and len(text_vectors) > 0:
                try:
                    result['avg_text_vector'] = np.mean(text_vectors, axis=0)
                except Exception as e:
                    logger.warning(f"Failed to calculate avg text vector: {e}")

            # í‰ê·  ì´ë¯¸ì§€ ë²¡í„° ê³„ì‚° (ì•ˆì „í•œ ì²˜ë¦¬)
            if image_vectors and len(image_vectors) > 0:
                try:
                    result['avg_image_vector'] = np.mean(image_vectors, axis=0)
                except Exception as e:
                    logger.warning(f"Failed to calculate avg image vector: {e}")

            logger.info(f"ğŸ“š User {user_id} bookmark preferences: {len(text_vectors)} text, {len(image_vectors)} image vectors")
            return result

        except Exception as e:
            logger.error(f"âŒ Failed to get detailed bookmark preferences for {user_id}: {e}")
            return {}

    async def _get_fast_place_candidates(
        self,
        region: Optional[str],
        category: Optional[str],
        limit: int = 50
    ) -> List[Dict]:
        """ë©”ì¸ í˜ì´ì§€ìš© ê³ ì† ì¥ì†Œ í›„ë³´ ì¡°íšŒ (ìµœì†Œ ì»¬ëŸ¼ë§Œ)"""
        try:
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"fast_places:{region or 'all'}:{category or 'all'}:{limit}"

            # ìºì‹œ í™•ì¸
            if self._is_cache_valid(cache_key, 'place_batch'):
                self.stats['cache_hits'] += 1
                return self.place_batch_cache[cache_key]

            # DBì—ì„œ í•µì‹¬ ì»¬ëŸ¼ ì¡°íšŒ (ì´ë¯¸ì§€ ë²¡í„°ëŠ” ì œì™¸í•˜ë˜ ì´ë¯¸ì§€ URLì€ í¬í•¨)
            query = """
                SELECT
                    pr.place_id::text as place_id,
                    pr.table_name,
                    pr.vector as vector,
                    pr.name,
                    pr.region,
                    pr.city,
                    pr.latitude,
                    pr.longitude,
                    pr.bookmark_cnt,
                    pr.image_urls,  -- ë©”ì¸ í˜ì´ì§€ ì´ë¯¸ì§€ í‘œì‹œìš©
                    pr.overview,    -- ê°„ë‹¨í•œ ì„¤ëª…
                    COALESCE(pr.bookmark_cnt, 0) as total_likes,
                    COALESCE(pr.bookmark_cnt, 0) as total_bookmarks,
                    COALESCE(pr.bookmark_cnt, 0) as total_clicks,
                    COALESCE(pr.bookmark_cnt, 0)::float as popularity_score,
                    COALESCE(pr.bookmark_cnt, 0)::float as engagement_score
                FROM place_recommendations pr
                WHERE
                    pr.vector IS NOT NULL
                    AND pr.name IS NOT NULL
                    AND pr.bookmark_cnt IS NOT NULL
                    AND pr.bookmark_cnt > 0
            """

            params = []
            param_count = 0

            # ì§€ì—­ í•„í„°
            if region:
                param_count += 1
                query += f" AND pr.region = ${param_count}"
                params.append(region)

            # ì¹´í…Œê³ ë¦¬ í•„í„°
            if category:
                param_count += 1
                query += f" AND pr.table_name = ${param_count}::text"
                params.append(category)

            # ì„±ëŠ¥ ìµœì í™”: ë¶ë§ˆí¬ ê¸°ì¤€ ì •ë ¬ë¡œ ìƒìœ„ë§Œ ì¡°íšŒ
            query += " ORDER BY COALESCE(pr.bookmark_cnt, 0) DESC"
            param_count += 1
            query += f" LIMIT ${param_count}"
            params.append(limit)

            places = await self.db_manager.execute_query(query, *params)

            # ë²¡í„° ê²€ì¦ ë° ì´ë¯¸ì§€ URL ë³€í™˜
            valid_places = []
            for place in places:
                if place['vector'] is not None:  # ê°„ë‹¨í•œ null ì²´í¬ë§Œ
                    # S3 ì´ë¯¸ì§€ URLì„ HTTPSë¡œ ë³€í™˜ (ê³µí†µ í•¨ìˆ˜ ì‚¬ìš©)
                    place = self._convert_s3_urls_to_https(place)
                    valid_places.append(place)

            # ìºì‹œì— ì €ì¥
            self._update_cache(cache_key, valid_places, 'place_batch')

            logger.info(f"ğŸ“‹ Fast retrieval: {len(valid_places)} places for {region or 'all'}/{category or 'all'}")
            return valid_places

        except Exception as e:
            logger.error(f"âŒ Failed to get fast place candidates: {e}")
            return []

    async def _get_fast_vector_recommendations(
        self,
        user_id: str,
        user_vector: np.ndarray,
        region: Optional[str],
        category: Optional[str],
        limit: int
    ) -> List[Dict]:
        """ë©”ì¸ í˜ì´ì§€ìš© ê³ ì† ë²¡í„° ê¸°ë°˜ ì¶”ì²œ (ë‹¨ì¼ ì±„ë„ë§Œ)"""
        try:
            # ìºì‹œëœ ìœ ì‚¬ë„ ê²°ê³¼ í™•ì¸
            similarity_cache_key = f"similarity:{user_id}:{region or 'all'}:{category or 'all'}:{limit}"
            if self._is_cache_valid(similarity_cache_key, 'similarity'):
                logger.info(f"âš¡ Using cached similarities for user {user_id}")
                cached_results = self.similarity_cache[similarity_cache_key]
                return cached_results[:limit]

            # ê³ ì† ì¥ì†Œ í›„ë³´ ì¡°íšŒ (ì œí•œëœ ìˆ˜)
            places = await self._get_fast_place_candidates(region, category, min(limit * 3, 150))

            if not places:
                logger.warning("âš ï¸ No fast candidates found, falling back to popular")
                return await self._get_popular_recommendations(region, category, limit, fast_mode=True)

            # ë²¡í„° ë°°ì¹˜ ì²˜ë¦¬ (ìµœì í™”)
            place_vectors = []
            valid_places = []

            for place in places:
                vector = validate_vector_data(place['vector'])
                if vector is not None:
                    place_vectors.append(vector)
                    # S3 ì´ë¯¸ì§€ URLì„ HTTPSë¡œ ë³€í™˜
                    place = self._convert_s3_urls_to_https(place)
                    valid_places.append(place)

            if not valid_places:
                return await self._get_popular_recommendations(region, category, limit, fast_mode=True)

            # ë²¡í„°í™”ëœ ìœ ì‚¬ë„ ê³„ì‚° (ë‹¨ì¼ ì±„ë„)
            place_vectors_array = np.array(place_vectors, dtype=np.float32)
            similarities = safe_cosine_similarity(user_vector, place_vectors_array)

            # ê°„ì†Œí™”ëœ ì ìˆ˜ ê³„ì‚° (ë³µì¡í•œ ê°€ì¤‘ì¹˜ ì—†ìŒ)
            results = []
            for i, place in enumerate(valid_places):
                try:
                    similarity = float(similarities[i])

                    # ì„ê³„ê°’ ì ìš©
                    if similarity < CONFIG.min_similarity_threshold:
                        continue

                    # ê°„ë‹¨í•œ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ (ë¹ ë¥¸ ê³„ì‚°)
                    bookmark_count = place.get('bookmark_cnt', 0)
                    popularity_factor = min(bookmark_count / 100.0, 1.0)  # ê°„ë‹¨í•œ ì •ê·œí™”

                    final_score = similarity * 0.7 + popularity_factor * 0.3

                    place['similarity_score'] = round(similarity, 4)
                    place['final_score'] = round(final_score, 4)
                    place['recommendation_type'] = 'fast_personalized'

                    results.append(place)

                except Exception as e:
                    logger.error(f"âŒ Fast score calculation failed for place {i}: {e}")
                    continue

            # ì ìˆ˜ìˆœ ì •ë ¬
            results.sort(key=lambda x: x['final_score'], reverse=True)
            final_results = results[:limit]

            # ìœ ì‚¬ë„ ê²°ê³¼ ìºì‹œ
            self._update_cache(similarity_cache_key, final_results, 'similarity')

            logger.info(f"âš¡ Fast recommendations: {len(final_results)} results for user {user_id}")

            # ì´ë¯¸ì§€ URL í¬í•¨ ì—¬ë¶€ ë””ë²„ê¹…
            image_count = sum(1 for place in final_results if place.get('image_urls'))
            logger.info(f"ğŸ“¸ ì´ë¯¸ì§€ í¬í•¨ ì¥ì†Œ: {image_count}/{len(final_results)}ê°œ")

            # ì²« ë²ˆì§¸ ê²°ê³¼ì˜ ì´ë¯¸ì§€ URL ë¡œê¹…
            if final_results and final_results[0].get('image_urls'):
                first_place = final_results[0]
                logger.info(f"ğŸ–¼ï¸ ì²« ë²ˆì§¸ ì¥ì†Œ '{first_place.get('name')}' ì´ë¯¸ì§€: {first_place.get('image_urls')}")

            return final_results

        except Exception as e:
            logger.error(f"âŒ Fast vector recommendation failed: {e}")
            return await self._get_popular_recommendations(region, category, limit, fast_mode=True)


    async def _get_hybrid_fast_recommendations(
        self,
        user_id: str,
        user_priority: str,
        region: Optional[str],
        category: Optional[str],
        limit: int
    ) -> List[Dict]:
        """Fast modeìš© í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ (95% ì„ í˜¸ë„ + 5% í–‰ë™ ë°ì´í„°)"""
        try:
            # ë” ë§ì€ ê²°ê³¼ë¥¼ ê°€ì ¸ì™€ì„œ í˜¼í•©
            extended_limit = min(limit * 4, 100)

            # 1. ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ì²œ (95%)
            preference_results = await self._get_preference_based_recommendations(
                user_id, region, category, extended_limit
            )

            # 2. í–‰ë™ ë²¡í„° ê¸°ë°˜ ì¶”ì²œ (5%)
            user_vector = await self._get_user_behavior_vector_cached(user_id)
            behavior_results = []
            if user_vector is not None:
                behavior_results = await self._get_fast_vector_recommendations(
                    user_id, user_vector, region, category, extended_limit
                )

            # 3. ê²°ê³¼ í˜¼í•© (95:5 ë¹„ìœ¨) - í•˜ë“œì½”ë”©ìœ¼ë¡œ ì„ì‹œ í•´ê²°
            preference_weight = 0.95  # experienced_user_preference_weight
            behavior_weight = 0.05    # experienced_user_behavior_weight

            # ì ìˆ˜ ì¬ê³„ì‚° ë° í˜¼í•©
            combined_results = {}

            # ì„ í˜¸ë„ ê²°ê³¼ ì¶”ê°€ (95% ê°€ì¤‘ì¹˜)
            for place in preference_results:
                place_id = place.get('place_id') or place.get('id')
                if place_id:
                    adjusted_score = place.get('final_score', 0) * preference_weight
                    place_copy = place.copy()
                    place_copy['final_score'] = adjusted_score
                    place_copy['source'] = 'preference'
                    combined_results[place_id] = place_copy

            # í–‰ë™ ë°ì´í„° ê²°ê³¼ ì¶”ê°€ (5% ê°€ì¤‘ì¹˜, ì¤‘ë³µ ì‹œ ì ìˆ˜ í•©ì‚°)
            for place in behavior_results:
                place_id = place.get('place_id') or place.get('id')
                if place_id:
                    adjusted_score = place.get('final_score', 0) * behavior_weight

                    if place_id in combined_results:
                        # ê¸°ì¡´ ì„ í˜¸ë„ ì ìˆ˜ì— í–‰ë™ ì ìˆ˜ ì¶”ê°€
                        combined_results[place_id]['final_score'] += adjusted_score
                        combined_results[place_id]['source'] = 'hybrid'
                    else:
                        # ìƒˆë¡œìš´ í–‰ë™ ê¸°ë°˜ ê²°ê³¼
                        place_copy = place.copy()
                        place_copy['final_score'] = adjusted_score
                        place_copy['source'] = 'behavior'
                        combined_results[place_id] = place_copy

            # ìµœì¢… ê²°ê³¼ ì •ë ¬ ë° ì œí•œ
            final_results = list(combined_results.values())
            final_results.sort(key=lambda x: x['final_score'], reverse=True)
            final_results = final_results[:limit]

            # í†µê³„ ë¡œê¹…
            preference_count = sum(1 for r in final_results if r.get('source') in ['preference', 'hybrid'])
            behavior_count = sum(1 for r in final_results if r.get('source') == 'behavior')
            hybrid_count = sum(1 for r in final_results if r.get('source') == 'hybrid')

            logger.info(f"ğŸ”„ Hybrid results: {len(final_results)} total "
                      f"(preference: {preference_count-hybrid_count}, behavior: {behavior_count}, hybrid: {hybrid_count})")

            return final_results

        except Exception as e:
            logger.error(f"âŒ Hybrid fast recommendation failed: {e}")
            # ì‹¤íŒ¨ ì‹œ ì„ í˜¸ë„ ê¸°ë°˜ìœ¼ë¡œ í´ë°±
            return await self._get_preference_based_recommendations(user_id, region, category, limit)

    async def _get_regional_preference_recommendations(
        self,
        user_id: str,
        limit: int = 50
    ) -> List[Dict]:
        """
        ì§€ì—­ë³„ ì‚¬ìš©ì ì„ í˜¸ íƒœê·¸ ê¸°ë°˜ ì¶”ì²œ (ì§€ì—­ë³„ ì¶”ì²œ ìˆ˜ëŸ‰ìœ¼ë¡œ ì •ë ¬)
        - ì‚¬ìš©ì ì„ í˜¸ íƒœê·¸ë¥¼ í†µí•´ ê° ì§€ì—­ë³„ ì¶”ì²œ ìˆ˜ëŸ‰ ê³„ì‚°
        - ì¶”ì²œ ìˆ˜ëŸ‰ì´ ë§ì€ ì§€ì—­ë¶€í„° ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        - ê° ì§€ì—­ ë‚´ì—ì„œëŠ” ì‚¬ìš©ì ìš°ì„ ìˆœìœ„ ì¹´í…Œê³ ë¦¬ë¥¼ ìµœìƒë‹¨ ë°°ì¹˜
        """
        try:
            # 1. ì‚¬ìš©ì ì„ í˜¸ë„ ì •ë³´ ì¡°íšŒ
            logger.info(f"ğŸ” [Regional] Getting user preferences for user {user_id}")
            user_preferences = await self._get_user_preferences(user_id)
            if not user_preferences:
                logger.info(f"âŒ [Regional] No preferences found for user {user_id}")
                return []

            user_priority = user_preferences.get('priority')
            if not user_priority:
                logger.info(f"âŒ [Regional] No priority found for user {user_id}")
                return []

            logger.info(f"âœ… [Regional] Found user preferences for user {user_id}: priority={user_priority}")

            # 2. ì‚¬ìš©ì í–‰ë™ ë²¡í„° ì¡°íšŒ (ë¶ë§ˆí¬ íŒ¨í„´ ë¶„ì„ìš©)
            logger.info(f"ğŸ§  [Regional] Getting user behavior vector for user {user_id}")
            user_behavior_vector = await self._get_user_behavior_vector_cached(user_id)
            if user_behavior_vector is not None:
                logger.info(f"âœ… [Regional] Found behavior vector for user {user_id}: shape {user_behavior_vector.shape}")
            else:
                logger.info(f"âŒ [Regional] No behavior vector found for user {user_id}")

            # 2. ê° ì§€ì—­ë³„ë¡œ ì‚¬ìš©ì ì„ í˜¸ ë²¡í„° ê¸°ë°˜ ì¶”ì²œ ìˆ˜ëŸ‰ ê³„ì‚°
            regional_scores = await self._calculate_regional_recommendation_scores(user_preferences)

            # 3. ì¶”ì²œ ìˆ˜ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ì§€ì—­ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
            sorted_regions = sorted(regional_scores.items(), key=lambda x: x[1], reverse=True)

            logger.info(f"ğŸ“Š Regional recommendation scores: {dict(sorted_regions[:5])}")  # ìƒìœ„ 5ê°œ ì§€ì—­ë§Œ ë¡œê¹…

            # 4. ê° ì§€ì—­ë³„ë¡œ ì¹´í…Œê³ ë¦¬ ìš°ì„ ìˆœìœ„ ì ìš©í•˜ì—¬ ì¶”ì²œ ìƒì„±
            final_recommendations = []
            items_per_region = max(3, limit // len(sorted_regions)) if sorted_regions else limit

            for region, score in sorted_regions:
                if len(final_recommendations) >= limit:
                    break

                # í•´ë‹¹ ì§€ì—­ì˜ ì¶”ì²œ ìƒì„± (behavior_vector í†µí•©ëœ ìš°ì„ ìˆœìœ„ ê¸°ë°˜)
                logger.info(f"ğŸ¯ [Regional] Generating recommendations for region {region} with behavior vector integration")
                region_recommendations = await self._calculate_priority_enhanced_scores(
                    user_preferences, user_behavior_vector, region, None, items_per_region
                )

                if region_recommendations:
                    # ì§€ì—­ ì •ë³´ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                    for rec in region_recommendations:
                        rec['region_score'] = score
                        rec['region_rank'] = len(final_recommendations) // items_per_region + 1

                    final_recommendations.extend(region_recommendations[:items_per_region])

            logger.info(f"âœ… Generated {len(final_recommendations)} regional preference recommendations for user {user_id}")
            return final_recommendations[:limit]

        except Exception as e:
            logger.error(f"âŒ Regional preference recommendation failed for user {user_id}: {e}")
            return []

    async def _calculate_regional_recommendation_scores(
        self,
        user_preferences: Dict[str, Any]
    ) -> Dict[str, float]:
        """
        ê° ì§€ì—­ë³„ ì‚¬ìš©ì ì„ í˜¸ íƒœê·¸ ê¸°ë°˜ ì¶”ì²œ ìˆ˜ëŸ‰ ì ìˆ˜ ê³„ì‚°
        """
        try:
            regional_scores = {}

            # ì§€ì—­ë³„ ì¥ì†Œ ë°ì´í„°ì™€ ì‚¬ìš©ì ì„ í˜¸ë„ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
            regions_query = """
                SELECT DISTINCT region, COUNT(*) as place_count
                FROM place_recommendations
                WHERE region IS NOT NULL
                GROUP BY region
                ORDER BY place_count DESC
            """

            async with self.db_manager.pool.acquire() as conn:
                regions_data = await conn.fetch(regions_query)

                for region_row in regions_data:
                    region = region_row['region']
                    place_count = region_row['place_count']

                    # í•´ë‹¹ ì§€ì—­ì˜ ì‚¬ìš©ì ì„ í˜¸ë„ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
                    region_score = await self._calculate_region_preference_score(
                        user_preferences, region, conn
                    )

                    # ì¥ì†Œ ìˆ˜ì™€ ì„ í˜¸ë„ ì ìˆ˜ë¥¼ ê²°í•©í•œ ìµœì¢… ì ìˆ˜
                    final_score = region_score * (1 + place_count / 1000)  # ì¥ì†Œ ìˆ˜ ê°€ì¤‘ì¹˜ ì ìš©
                    regional_scores[region] = final_score

            return regional_scores

        except Exception as e:
            logger.error(f"âŒ Regional scores calculation failed: {e}")
            return {}

    async def _calculate_region_preference_score(
        self,
        user_preferences: Dict[str, Any],
        region: str,
        conn
    ) -> float:
        """
        íŠ¹ì • ì§€ì—­ì— ëŒ€í•œ ì‚¬ìš©ì ìš°ì„ ìˆœìœ„ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
        ì˜¤ì§ ìš°ì„ ìˆœìœ„ ì¹´í…Œê³ ë¦¬ì˜ ì¥ì†Œ ìˆ˜ë§Œ ê³„ì‚°
        """
        try:
            preference_score = 0.0
            user_priority = user_preferences.get('priority')

            # ìš°ì„ ìˆœìœ„ ì¹´í…Œê³ ë¦¬ì˜ ì¥ì†Œ ìˆ˜ë§Œ ê³„ì‚°
            if user_priority:
                # experience íƒœê·¸ì¸ ê²½ìš° nature, humanities, leisure_sports í¬í•¨
                if user_priority == 'experience':
                    experience_categories = ['nature', 'humanities', 'leisure_sports']
                    priority_query = """
                        SELECT COUNT(*) as count
                        FROM place_recommendations
                        WHERE region = $1 AND table_name = ANY($2)
                    """
                    priority_result = await conn.fetchrow(priority_query, region, experience_categories)
                else:
                    # ì¼ë°˜ ì¹´í…Œê³ ë¦¬ (accommodation, restaurants, shopping)
                    priority_query = """
                        SELECT COUNT(*) as count
                        FROM place_recommendations
                        WHERE region = $1 AND table_name = $2
                    """
                    priority_result = await conn.fetchrow(priority_query, region, user_priority)

                if priority_result:
                    preference_score = float(priority_result['count'])

            return preference_score

        except Exception as e:
            logger.error(f"âŒ Region preference score calculation failed for {region}: {e}")
            return 0.0

    async def _get_priority_ordered_recommendations(
        self,
        user_preferences: Dict[str, Any],
        region: str,
        user_priority: str,
        limit: int
    ) -> List[Dict]:
        """
        ì§€ì—­ ë‚´ì—ì„œ ì‚¬ìš©ì ìš°ì„ ìˆœìœ„ ì¹´í…Œê³ ë¦¬ë§Œ ì¶”ì²œ ìƒì„±
        """
        try:
            recommendations = []

            # experience íƒœê·¸ì¸ ê²½ìš° nature, humanities, leisure_sportsë§Œ ì¶”ì²œ
            if user_priority == 'experience':
                experience_categories = ['nature', 'humanities', 'leisure_sports']
                for category in experience_categories:
                    category_recommendations = await self._calculate_preference_scores(
                        user_preferences, region, category, limit // len(experience_categories) + 1
                    )

                    if category_recommendations:
                        for rec in category_recommendations:
                            rec['category_priority'] = 'high'
                            rec['recommendation_reason'] = f'ì²´í—˜ ìš°ì„ ìˆœìœ„: {category}'
                        recommendations.extend(category_recommendations)
            else:
                # ì¼ë°˜ ì¹´í…Œê³ ë¦¬ëŠ” í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë§Œ ì¶”ì²œ
                priority_recommendations = await self._calculate_preference_scores(
                    user_preferences, region, user_priority, limit
                )

                if priority_recommendations:
                    for rec in priority_recommendations:
                        rec['category_priority'] = 'high'
                        rec['recommendation_reason'] = f'ì‚¬ìš©ì ìš°ì„ ìˆœìœ„: {user_priority}'
                    recommendations.extend(priority_recommendations)

            logger.info(f"ğŸ¯ Generated {len(recommendations)} priority-only recommendations for {region} ({user_priority})")
            return recommendations[:limit]

        except Exception as e:
            logger.error(f"âŒ Priority ordered recommendations failed for {region}: {e}")
            return []


# ============================================================================
# ğŸš€ ì „ì—­ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
# ============================================================================

_engine_instance: Optional[UnifiedRecommendationEngine] = None

async def get_engine() -> UnifiedRecommendationEngine:
    """ì „ì—­ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì§€ì—° ì´ˆê¸°í™”)"""
    global _engine_instance

    if _engine_instance is None:
        _engine_instance = UnifiedRecommendationEngine()
        await _engine_instance.initialize()

    return _engine_instance

async def close_engine():
    """ì „ì—­ ì—”ì§„ ì¸ìŠ¤í„´ìŠ¤ ì •ë¦¬"""
    global _engine_instance

    if _engine_instance:
        await _engine_instance.close()
        _engine_instance = None


