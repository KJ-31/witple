#!/usr/bin/env python3
"""
ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œì„ ìœ„í•œ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
UserAction, UserBehaviorVector, PlaceVector í…Œì´ë¸” ì¶”ê°€
"""
import psycopg2
from config import settings
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def migrate_data_collection_tables():
    """ë°ì´í„° ìˆ˜ì§‘ ê´€ë ¨ í…Œì´ë¸”ë“¤ì„ ì¶”ê°€"""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        conn = psycopg2.connect(settings.DATABASE_URL)
        cursor = conn.cursor()
        
        logger.info("Connected to database for data collection migration")
        
        # 1. user_actions í…Œì´ë¸” ìƒì„±
        logger.info("Creating user_actions table...")
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_actions (
                id SERIAL PRIMARY KEY,
                user_id VARCHAR NOT NULL REFERENCES users(user_id),
                place_category VARCHAR NOT NULL,
                place_id VARCHAR NOT NULL,
                action_type VARCHAR NOT NULL,
                action_value INTEGER,
                action_detail JSONB,
                session_id VARCHAR,
                
                -- ì„œë²„ ë©”íƒ€ë°ì´í„°
                server_timestamp TIMESTAMP WITH TIME ZONE,
                client_ip VARCHAR,
                user_agent TEXT,
                request_id VARCHAR,
                
                -- AWS Batch ì²˜ë¦¬ ìƒíƒœ
                batch_processed BOOLEAN DEFAULT FALSE,
                batch_processed_at TIMESTAMP WITH TIME ZONE,
                batch_id VARCHAR,
                
                created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
            );
        """)
        logger.info("âœ“ user_actions table created")
        
        # 2. user_behavior_vectors í…Œì´ë¸” ìƒì„±  
        logger.info("Creating user_behavior_vectors table...")
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS user_behavior_vectors (
                user_id VARCHAR PRIMARY KEY REFERENCES users(user_id),
                
                -- BERT ë²¡í„° (384ì°¨ì›) - PostgreSQL ARRAY íƒ€ìž…
                behavior_vector FLOAT[],
                
                -- í–‰ë™ ì ìˆ˜ë“¤ (0.0~100.0)
                like_score FLOAT DEFAULT 0.0,
                bookmark_score FLOAT DEFAULT 0.0,
                click_score FLOAT DEFAULT 0.0,
                dwell_time_score FLOAT DEFAULT 0.0,
                
                -- í†µê³„ ë©”íƒ€ë°ì´í„°
                total_actions INTEGER DEFAULT 0,
                total_likes INTEGER DEFAULT 0,
                total_bookmarks INTEGER DEFAULT 0,
                total_clicks INTEGER DEFAULT 0,
                
                -- ìµœì‹ ì„± ì •ë³´
                last_action_date TIMESTAMP WITH TIME ZONE,
                vector_updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
            );
        """)
        logger.info("âœ“ user_behavior_vectors table created")
        
        # 3. place_vectors í…Œì´ë¸” ìƒì„±
        logger.info("Creating place_vectors table...")
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS place_vectors (
                id SERIAL PRIMARY KEY,
                place_id VARCHAR NOT NULL,
                place_category VARCHAR NOT NULL,
                
                -- ìž¥ì†Œ íŠ¹ì„± ë²¡í„°ë“¤
                content_vector FLOAT[],
                behavior_vector FLOAT[],
                combined_vector FLOAT[],
                
                -- ìž¥ì†Œë³„ í†µê³„ ì •ë³´
                total_likes INTEGER DEFAULT 0,
                total_bookmarks INTEGER DEFAULT 0,
                total_clicks INTEGER DEFAULT 0,
                unique_users INTEGER DEFAULT 0,
                avg_dwell_time FLOAT DEFAULT 0.0,
                
                -- ì¸ê¸°ë„ ì ìˆ˜ (0.0~100.0)
                popularity_score FLOAT DEFAULT 0.0,
                engagement_score FLOAT DEFAULT 0.0,
                
                -- ë²¡í„° ì—…ë°ì´íŠ¸ ì •ë³´
                vector_updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                stats_updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
            );
        """)
        logger.info("âœ“ place_vectors table created")
        
        # 4. user_actions í…Œì´ë¸” ì¸ë±ìŠ¤ ìƒì„±
        logger.info("Creating user_actions indexes...")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_actions_user_id ON user_actions(user_id);")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_actions_place_category ON user_actions(place_category);")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_actions_place_id ON user_actions(place_id);")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_actions_action_type ON user_actions(action_type);")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_actions_session_id ON user_actions(session_id);")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_actions_batch_processed ON user_actions(batch_processed);")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_actions_created_at ON user_actions(created_at);")
        logger.info("âœ“ user_actions indexes created")
        
        # 5. place_vectors í…Œì´ë¸” ì¸ë±ìŠ¤ ìƒì„±
        logger.info("Creating place_vectors indexes...")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_place_vectors_place_id ON place_vectors(place_id);")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_place_vectors_place_category ON place_vectors(place_category);")
        cursor.execute("CREATE UNIQUE INDEX IF NOT EXISTS idx_place_vectors_place_unique ON place_vectors(place_id, place_category);")
        logger.info("âœ“ place_vectors indexes created")
        
        # 6. ë³µí•© ì¸ë±ìŠ¤ ìƒì„± (ì¿¼ë¦¬ ì„±ëŠ¥ ìµœì í™”)
        logger.info("Creating composite indexes...")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_actions_composite ON user_actions(user_id, place_category, action_type);")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_user_actions_batch_processing ON user_actions(batch_processed, created_at) WHERE batch_processed = FALSE;")
        logger.info("âœ“ Composite indexes created")
        
        # ì»¤ë°‹
        conn.commit()
        logger.info("âœ“ Data collection tables migration completed successfully!")
        
        # í…Œì´ë¸” ì •ë³´ í™•ì¸
        logger.info("Verifying created tables...")
        cursor.execute("""
            SELECT table_name, column_name, data_type 
            FROM information_schema.columns 
            WHERE table_name IN ('user_actions', 'user_behavior_vectors', 'place_vectors')
            ORDER BY table_name, ordinal_position;
        """)
        
        results = cursor.fetchall()
        current_table = None
        for table_name, column_name, data_type in results:
            if current_table != table_name:
                logger.info(f"\nðŸ“‹ Table: {table_name}")
                current_table = table_name
            logger.info(f"   â””â”€ {column_name}: {data_type}")
        
        # ì¸ë±ìŠ¤ ì •ë³´ í™•ì¸
        logger.info("\nVerifying created indexes...")
        cursor.execute("""
            SELECT tablename, indexname 
            FROM pg_indexes 
            WHERE tablename IN ('user_actions', 'user_behavior_vectors', 'place_vectors')
            ORDER BY tablename, indexname;
        """)
        
        indexes = cursor.fetchall()
        current_table = None
        for table_name, index_name in indexes:
            if current_table != table_name:
                logger.info(f"\nðŸ—‚ï¸  Indexes for {table_name}:")
                current_table = table_name
            logger.info(f"   â””â”€ {index_name}")
        
    except Exception as e:
        logger.error(f"Data collection migration failed: {str(e)}")
        if conn:
            conn.rollback()
        raise
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

def rollback_data_collection_tables():
    """ë°ì´í„° ìˆ˜ì§‘ í…Œì´ë¸”ë“¤ì„ ë¡¤ë°± (ê°œë°œìš©)"""
    try:
        conn = psycopg2.connect(settings.DATABASE_URL)
        cursor = conn.cursor()
        
        logger.info("Rolling back data collection tables...")
        
        # ìˆœì„œëŒ€ë¡œ í…Œì´ë¸” ì‚­ì œ (ì™¸ëž˜ í‚¤ ì œì•½ ê³ ë ¤)
        cursor.execute("DROP TABLE IF EXISTS place_vectors CASCADE;")
        cursor.execute("DROP TABLE IF EXISTS user_behavior_vectors CASCADE;") 
        cursor.execute("DROP TABLE IF EXISTS user_actions CASCADE;")
        
        conn.commit()
        logger.info("âœ“ Data collection tables rolled back successfully!")
        
    except Exception as e:
        logger.error(f"Rollback failed: {str(e)}")
        if conn:
            conn.rollback()
        raise
    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "rollback":
        rollback_data_collection_tables()
    else:
        migrate_data_collection_tables()