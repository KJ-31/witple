import boto3
from langchain_aws import ChatBedrock
from langchain_core.prompts import ChatPromptTemplate
from langchain_postgres import PGVector
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document
from typing import List, Any, Literal, TypedDict, Optional
from sqlalchemy import text
from database import engine as shared_engine
import sys
import os
import re

# Import utility functions
from utils.entity_extractor import detect_query_entities
from utils.intent_classifier import classify_query_intent, _fallback_intent_classification
from utils.travel_planner import (
    parse_travel_dates, parse_enhanced_travel_plan, parse_day_schedule,
    normalize_place_name, extract_duration, generate_plan_id,
    create_formatted_ui_response, is_meal_activity, format_travel_response_with_linebreaks
)
from utils.simple_search import information_search_node as simple_information_search_node

# AWS ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” AWS CLI ì„¤ì • ì‚¬ìš©)
AWS_REGION = os.getenv('AWS_REGION')  # Bedrockì´ ì§€ì›ë˜ëŠ” ë¦¬ì „ (ì„œìš¸)
AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')
AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')

# AWS ì„¸ì…˜ ìƒì„±
try:
    boto3_session = boto3.Session(
        aws_access_key_id=AWS_ACCESS_KEY_ID,
        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
        region_name=AWS_REGION
    )
except Exception as e:
    print(f"âš ï¸ AWS ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
    boto3_session = None

# # ì„¤ì • ë° ì´ˆê¸°í™”

# LLM ëª¨ë¸ ì„¤ì • (Amazon Bedrock - Claude)
print("ğŸ¤– Amazon Bedrock Claude ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
try:
    # Retry ì„¤ì •ìœ¼ë¡œ ê³¼ë„í•œ ì¬ì‹œë„ ë°©ì§€
    from botocore.config import Config
    retry_config = Config(
        retries={
            'max_attempts': 3,  # ìµœëŒ€ 2íšŒë§Œ ì¬ì‹œë„ (ê¸°ë³¸ê°’ 5íšŒ â†’ 2íšŒ)
            'mode': 'adaptive'  # ì ì‘ì  ì¬ì‹œë„ ëª¨ë“œ
        }
    )

    # boto3 í´ë¼ì´ì–¸íŠ¸ì— ì§ì ‘ retry ì„¤ì • ì ìš©
    bedrock_client = boto3_session.client(
        'bedrock-runtime',
        region_name=AWS_REGION,
        config=retry_config
    )

    llm = ChatBedrock(
        model_id="anthropic.claude-3-haiku-20240307-v1:0",      # Claude 3 Haiku
        # model_id="anthropic.claude-3-5-sonnet-20240620-v1:0",   # Claude 3.5 Sonnet
        # model_id="anthropic.claude-sonnet-4-20250514-v1:0",   # Claude 4 Sonnet
        client=bedrock_client,  # ì„¤ì •ëœ í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
        model_kwargs={
            "temperature": 0.2,         # ì•½ê°„ ë†’ì—¬ì„œ ë¹ ë¥¸ ì‘ë‹µ (0.2 â†’ 0.3)
            "max_tokens": 3000,         # í† í° ìˆ˜ ì¤„ì—¬ì„œ ì†ë„ í–¥ìƒ (4000 â†’ 2000)
            "top_p": 0.8,               # ë” ì œí•œì ìœ¼ë¡œ ì„ íƒí•´ì„œ ì†ë„ í–¥ìƒ
        }
    )
except Exception as e:
    print(f"âŒ Bedrock LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    print("í™˜ê²½ë³€ìˆ˜ë‚˜ AWS CLI ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

# ì„ë² ë”© ëª¨ë¸ ì„¤ì • - ì•ˆì •ì ì¸ sentence-transformers ëª¨ë¸ ì‚¬ìš©
print("ğŸ§  Sentence Transformers ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
embeddings = HuggingFaceEmbeddings(
    model_name='sentence-transformers/all-MiniLM-L12-v2',
)

# # ë²¡í„°ìŠ¤í† ì–´ ì—°ê²° (í•„ìˆ˜)

print("ğŸ”— ë²¡í„°ìŠ¤í† ì–´ ì—°ê²° ì¤‘...")
vectorstore = PGVector(
    embeddings=embeddings,
    collection_name="place_recommendations",
    connection=os.getenv('DATABASE_URL'),
    pre_delete_collection=False,
)
print("âœ… ë²¡í„°ìŠ¤í† ì–´ ì—°ê²° ì„±ê³µ")

# DB ì¹´íƒˆë¡œê·¸ëŠ” ì´ˆê¸°í™” í•¨ìˆ˜ì—ì„œ ë¡œë“œë  ì˜ˆì •

# ìˆ™ì†Œ ì¹´í…Œê³ ë¦¬ ìƒìˆ˜í™” (ë³´ì•ˆ ê°œì„ )
ACCOMMODATION_CATEGORIES = ['ìˆ™ì†Œ', 'í˜¸í…”', 'íœì…˜', 'ëª¨í…”', 'ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤', 'ë¦¬ì¡°íŠ¸']

def is_accommodation(category: str) -> bool:
    """ì¹´í…Œê³ ë¦¬ê°€ ìˆ™ì†Œ ê´€ë ¨ì¸ì§€ íŒë‹¨"""
    if not category:
        return False
    return any(keyword in category for keyword in ACCOMMODATION_CATEGORIES)

# Entity extraction moved to utils/entity_extractor.py
def detect_query_entities_wrapper(query: str) -> dict:
    return detect_query_entities(query, llm, _db_catalogs)

# Fallback entity extraction moved to utils/entity_extractor.py


def _fallback_intent_classification(query: str, has_travel_plan: bool = False) -> dict:
    """í´ë°±: ê°œì„ ëœ í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜"""
    query_lower = query.lower()

    # í™•ì • ê´€ë ¨ í‚¤ì›Œë“œ (ë” í¬ê´„ì ìœ¼ë¡œ)
    confirmation_keywords = [
        "í™•ì •", "ê²°ì •", "ì¢‹ì•„", "ì´ê±¸ë¡œ", "ok", "ì˜¤ì¼€ì´", "ë§ì•„", "ë„¤", "ì‘", "ê·¸ë˜",
        "ì¢‹ë‹¤", "ì¢‹ë„¤", "ì¢‹ì•„ìš”", "ì¢‹ìŠµë‹ˆë‹¤", "ê´œì°®ì•„", "ê´œì°®ë‹¤", "ê´œì°®ë„¤", "ê´œì°®ìŠµë‹ˆë‹¤",
        "ì´ê±°", "ì´ê²ƒ", "ì´ê±¸", "ì´ê±°ë¡œ", "ì´ê²ƒìœ¼ë¡œ", "ì´ê±¸ë¡œ", "ì´ê±°ë¡œ í•´", "ì´ê²ƒìœ¼ë¡œ í•´",
        "ê·¸ë˜", "ê·¸ë˜ìš”", "ê·¸ë˜ìš”", "ê·¸ë ‡ë‹¤", "ê·¸ë ‡ë„¤", "ê·¸ë ‡ìŠµë‹ˆë‹¤",
        "ë§ë‹¤", "ë§ë„¤", "ë§ìŠµë‹ˆë‹¤", "ë§ì•„ìš”", "ë§ì•„", "ë§ìŠµë‹ˆë‹¤",
        "ë„¤", "ë„¤ìš”", "ë„¤", "ì˜ˆ", "ì˜ˆìš”", "ì˜ˆ", "ì˜ˆìŠ¤", "yes", "y",
        "í™•ì¸", "í™•ì¸í•´", "í™•ì¸í•´ìš”", "í™•ì¸í•©ë‹ˆë‹¤", "í™•ì¸ëì–´", "í™•ì¸ëìŠµë‹ˆë‹¤"
    ]
    strong_confirmation = ["í™•ì •", "ê²°ì •", "ì´ê±¸ë¡œ", "ok", "ì˜¤ì¼€ì´", "í™•ì¸", "yes"]
    
    if has_travel_plan and any(word in query_lower for word in confirmation_keywords):
        confirmation_type = "strong" if any(word in query_lower for word in strong_confirmation) else "weak"
        matched_keywords = [word for word in confirmation_keywords if word in query_lower]
        print(f"ğŸ¯ í™•ì • í‚¤ì›Œë“œ ê°ì§€: {matched_keywords} (íƒ€ì…: {confirmation_type})")
        return {
            "primary_intent": "confirmation",
            "secondary_intent": "none",
            "confidence_level": "high" if confirmation_type == "strong" else "medium",
            "confirmation_type": confirmation_type,
            "requires_rag": False,
            "requires_search": False
        }

    # ìƒˆë¡œìš´ ì—¬í–‰ ìš”ì²­ ê°ì§€ (ê°œì„ ëœ ë¡œì§)
    travel_keywords = ["ì¶”ì²œ", "ì—¬í–‰", "ì¼ì •", "ê³„íš", "ê°€ê³ ì‹¶ì–´", "ë†€ëŸ¬", "êµ¬ê²½", "ê´€ê´‘"]
    duration_keywords = ["ë°•", "ì¼", "ë‹¹ì¼", "í•˜ë£¨", "ì´í‹€", "ì‚¬í˜"]
    region_keywords = ["ì„œìš¸", "ë¶€ì‚°", "ì œì£¼", "ê°•ë¦‰", "ê²½ì£¼", "ì „ì£¼", "ëŒ€êµ¬", "ê´‘ì£¼", "ì¸ì²œ", "ì¶˜ì²œ", "ì—¬ìˆ˜"]
    question_patterns = ["ì–´ë””", "ë­", "ë­˜", "ì–´ë–¤", "ì¶”ì²œí•´", "ì•Œë ¤ì¤˜", "ê°€ë³¼ë§Œí•œ"]
    
    has_travel_keywords = any(keyword in query_lower for keyword in travel_keywords)
    has_duration_keywords = any(keyword in query_lower for keyword in duration_keywords)
    has_region_keywords = any(keyword in query_lower for keyword in region_keywords)
    has_question_patterns = any(pattern in query_lower for pattern in question_patterns)
    
    is_new_travel_request = has_travel_keywords or has_duration_keywords or has_region_keywords or has_question_patterns
    
    # ê¸°ì¡´ ì—¬í–‰ ê³„íšì´ ìˆê³  ìƒˆë¡œìš´ ì—¬í–‰ ìš”ì²­ì¸ ê²½ìš°
    if has_travel_plan and is_new_travel_request:
        print("ğŸ”„ ê¸°ì¡´ ê³„íš ìˆì§€ë§Œ ìƒˆë¡œìš´ ì—¬í–‰ ìš”ì²­ ê°ì§€ - travel_planningìœ¼ë¡œ ë¶„ë¥˜")
        return {
            "primary_intent": "travel_planning",
            "secondary_intent": "reset_previous",
            "confidence_level": "high",
            "confirmation_type": "none",
            "requires_rag": True,
            "requires_search": False
        }

    # ê¸°ë³¸ ì—¬í–‰ ê³„íš
    return {
        "primary_intent": "travel_planning",
        "secondary_intent": "none",
        "confidence_level": "medium",
        "confirmation_type": "none",
        "requires_rag": True,
        "requires_search": False
    }

def extract_location_and_category(query: str):
    """ì¿¼ë¦¬ì—ì„œ ì§€ì—­ëª…ê³¼ ì¹´í…Œê³ ë¦¬ë¥¼ ì •í™•íˆ ì¶”ì¶œ (LLM ê¸°ë°˜ + DB ì •ê·œí™”)"""
    try:
        # 1ë‹¨ê³„: LLMìœ¼ë¡œ ì—”í‹°í‹° ì¶”ì¶œ
        raw_entities = detect_query_entities_wrapper(query)

        # 2ë‹¨ê³„: DB ì¹´íƒˆë¡œê·¸ ê¸°ë°˜ ì •ê·œí™”
        normalized_entities = normalize_entities(raw_entities)

        # ê¸°ì¡´ ë°˜í™˜ í˜•ì‹ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
        return (
            normalized_entities["regions"],
            normalized_entities["cities"],
            normalized_entities["categories"]
        )

    except Exception as e:
        print(f"âš ï¸ ì—”í‹°í‹° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜, í´ë°± ì‚¬ìš©: {e}")
        # ìµœì¢… í´ë°±: ê¸°ì¡´ í•˜ë“œì½”ë”© ë°©ì‹
        fallback_entities = _fallback_entity_extraction(query)
        return (
            fallback_entities["regions"],
            fallback_entities["cities"],
            fallback_entities["categories"]
        )

# DB ì¹´íƒˆë¡œê·¸ ìºì‹œ (ì•± ì‹œì‘ì‹œ í”„ë¦¬ë¡œë“œ)
_db_catalogs = {
    "regions": [],
    "cities": [],
    "categories": []
}

def load_db_catalogs():
    """ì•± ì‹œì‘ì‹œ DBì—ì„œ ì‹¤ì œ ì§€ì—­/ë„ì‹œ/ì¹´í…Œê³ ë¦¬ ëª©ë¡ì„ Redisì— ìºì‹œ"""
    try:
        print("ğŸ“– DB ì¹´íƒˆë¡œê·¸ í”„ë¦¬ë¡œë“œ ì¤‘...")

        with shared_engine.connect() as conn:
            # ì‹¤ì œ DBì—ì„œ distinct ê°’ë“¤ ì¡°íšŒ
            regions_query = text("""
                SELECT DISTINCT cmetadata->>'region' as region
                FROM langchain_pg_embedding
                WHERE cmetadata->>'region' IS NOT NULL
                AND cmetadata->>'region' != ''
                ORDER BY region
            """)

            cities_query = text("""
                SELECT DISTINCT cmetadata->>'city' as city
                FROM langchain_pg_embedding
                WHERE cmetadata->>'city' IS NOT NULL
                AND cmetadata->>'city' != ''
                ORDER BY city
            """)

            categories_query = text("""
                SELECT DISTINCT cmetadata->>'category' as category
                FROM langchain_pg_embedding
                WHERE cmetadata->>'category' IS NOT NULL
                AND cmetadata->>'category' != ''
                ORDER BY category
            """)

            # ê²°ê³¼ ì €ì¥
            regions_result = conn.execute(regions_query).fetchall()
            cities_result = conn.execute(cities_query).fetchall()
            categories_result = conn.execute(categories_query).fetchall()

            _db_catalogs["regions"] = [row.region for row in regions_result if row.region]
            _db_catalogs["cities"] = [row.city for row in cities_result if row.city]
            _db_catalogs["categories"] = [row.category for row in categories_result if row.category]

            print(f"âœ… DB ì¹´íƒˆë¡œê·¸ ë¡œë“œ ì™„ë£Œ:")
            print(f"   - ì§€ì—­: {len(_db_catalogs['regions'])}ê°œ")
            print(f"   - ë„ì‹œ: {len(_db_catalogs['cities'])}ê°œ")
            print(f"   - ì¹´í…Œê³ ë¦¬: {len(_db_catalogs['categories'])}ê°œ")

            # Redis ìºì‹œ ì €ì¥ ê¸°ëŠ¥ ì œê±°ë¨

        return True

    except Exception as e:
        print(f"âš ï¸ DB ì¹´íƒˆë¡œê·¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        # í´ë°±: ìµœì†Œí•œì˜ ë¹ˆ ë°°ì—´ë¡œ ì´ˆê¸°í™”
        _db_catalogs["regions"] = []
        _db_catalogs["cities"] = []
        _db_catalogs["categories"] = []
        return False

def normalize_entities(entities: dict, use_fuzzy: bool = True) -> dict:
    """ì¶”ì¶œëœ ì—”í‹°í‹°ë¥¼ DB ì¹´íƒˆë¡œê·¸ ê¸°ë°˜ìœ¼ë¡œ ì •ê·œí™”"""
    try:
        normalized = {
            "regions": [],
            "cities": [],
            "categories": [],
            "keywords": entities.get("keywords", [])
        }

        # ê°„ë‹¨í•œ ë¬¸ìì—´ ë§¤ì¹­ìœ¼ë¡œ ì •ê·œí™”
        for entity_region in entities.get("regions", []):
            for db_region in _db_catalogs["regions"]:
                # ë¶€ë¶„ ë§¤ì¹­ ë˜ëŠ” ì •í™• ë§¤ì¹­
                if (entity_region in db_region or db_region in entity_region or
                    entity_region.replace('íŠ¹ë³„ì‹œ','').replace('ê´‘ì—­ì‹œ','').replace('ë„','') in db_region):
                    if db_region not in normalized["regions"]:
                        normalized["regions"].append(db_region)

        for entity_city in entities.get("cities", []):
            for db_city in _db_catalogs["cities"]:
                if entity_city in db_city or db_city in entity_city:
                    if db_city not in normalized["cities"]:
                        normalized["cities"].append(db_city)

        for entity_category in entities.get("categories", []):
            for db_category in _db_catalogs["categories"]:
                if entity_category in db_category or db_category in entity_category:
                    if db_category not in normalized["categories"]:
                        normalized["categories"].append(db_category)

        print(f"ğŸ”„ ì—”í‹°í‹° ì •ê·œí™”: {entities} â†’ {normalized}")
        return normalized

    except Exception as e:
        print(f"âš ï¸ ì—”í‹°í‹° ì •ê·œí™” ì˜¤ë¥˜: {e}")
        return entities

class HybridOptimizedRetriever(BaseRetriever):
    """SQL í•„í„°ë§ + ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°"""
    
    vectorstore: Any = None
    k: int = 10000  # SQL í•„í„°ë§ìœ¼ë¡œ ì¶•ì†Œëœ í›„ë³´êµ°ì—ì„œ ë²¡í„° ê²€ìƒ‰
    score_threshold: float = 0.5
    max_sql_results: int = 5000  # SQL í•„í„°ë§ ìµœëŒ€ ê²°ê³¼ ìˆ˜
    
    def __init__(self, vectorstore, k: int = 10000, score_threshold: float = 0.5, max_sql_results: int = 5000):
        super().__init__(vectorstore=vectorstore, k=k, score_threshold=score_threshold, max_sql_results=max_sql_results)
    
    def _get_relevant_documents(self, query: str) -> List[Document]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: SQL 1ì°¨ í•„í„°ë§ + ë²¡í„° 2ì°¨ ê²€ìƒ‰"""
        try:
            print(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
            
            # 1ë‹¨ê³„: ì§€ì—­/ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
            regions, cities, categories = extract_location_and_category(query)
            print(f"   ì¶”ì¶œëœ ì •ë³´ - ì§€ì—­: {regions}, ë„ì‹œ: {cities}, ì¹´í…Œê³ ë¦¬: {categories}")
            
            # 2ë‹¨ê³„: ë„ì‹œ ìš°ì„  ê²€ìƒ‰ ë¡œì§
            candidate_docs = self._city_first_search(query, regions, cities, categories)
            
            if not candidate_docs:
                print("âš ï¸ SQL í•„í„°ë§ ê²°ê³¼ ì—†ìŒ, ì „ì²´ ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰")
                docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=min(500, self.k))
                filtered_docs = []
                for doc, score in docs_with_scores:
                    if score >= self.score_threshold:
                        doc.metadata['similarity_score'] = round(score, 3)
                        doc.metadata['search_method'] = 'pgvector_full'
                        filtered_docs.append(doc)
                print(f"âœ… ì „ì²´ ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(filtered_docs)}ê°œ ë¬¸ì„œ")
                return filtered_docs
            
            print(f"ğŸ“Š SQL í•„í„°ë§: {len(candidate_docs)}ê°œ í›„ë³´ ë¬¸ì„œ ì„ ë³„")
            
            # 3ë‹¨ê³„: ì„ ë³„ëœ í›„ë³´êµ°ì— ëŒ€í•´ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°
            final_docs = self._vector_search_on_candidates(query, candidate_docs)
            
            print(f"âœ… ìµœì¢… ê²°ê³¼: {len(final_docs)}ê°œ ë¬¸ì„œ (ì„ê³„ê°’ â‰¥{self.score_threshold})")
            return final_docs
            
        except Exception as e:
            print(f"âŒ HybridOptimizedRetriever ì˜¤ë¥˜: {e}")
            return []

    def _city_first_search(self, query: str, regions: List[str], cities: List[str], categories: List[str]) -> List[Document]:
        """ë„ì‹œ ìš°ì„  ê²€ìƒ‰ - ë„ì‹œë§Œìœ¼ë¡œ ë¨¼ì € ê²€ìƒ‰í•˜ê³ , ê²°ê³¼ ë¶€ì¡±ì‹œ ì§€ì—­ìœ¼ë¡œ í™•ëŒ€"""
        try:
            MIN_CITY_RESULTS = 10  # ë„ì‹œ ê²€ìƒ‰ ìµœì†Œ ê²°ê³¼ ìˆ˜

            # 1ë‹¨ê³„: ë„ì‹œë§Œìœ¼ë¡œ ê²€ìƒ‰
            if cities:
                print(f"ğŸ¯ 1ë‹¨ê³„: ë„ì‹œ ìš°ì„  ê²€ìƒ‰ - {cities}")
                city_docs = self._sql_filter_candidates(query, [], cities, categories)
                print(f"   ë„ì‹œ ê²€ìƒ‰ ê²°ê³¼: {len(city_docs)}ê°œ")

                if len(city_docs) >= MIN_CITY_RESULTS:
                    print(f"âœ… ë„ì‹œ ê²€ìƒ‰ìœ¼ë¡œ ì¶©ë¶„í•œ ê²°ê³¼({len(city_docs)}ê°œ) í™•ë³´, ì§€ì—­ í™•ì¥ ì—†ì´ ì§„í–‰")
                    return city_docs
                else:
                    print(f"âš ï¸ ë„ì‹œ ê²€ìƒ‰ ê²°ê³¼ ë¶€ì¡±({len(city_docs)}ê°œ < {MIN_CITY_RESULTS}ê°œ), ì§€ì—­ìœ¼ë¡œ í™•ëŒ€ ê²€ìƒ‰")

            # 2ë‹¨ê³„: ì§€ì—­ìœ¼ë¡œ í™•ëŒ€ ê²€ìƒ‰ (ê¸°ì¡´ ë¡œì§)
            if regions or cities:
                print(f"ğŸŒ 2ë‹¨ê³„: ì§€ì—­ í™•ëŒ€ ê²€ìƒ‰ - ì§€ì—­: {regions}, ë„ì‹œ: {cities}")
                expanded_docs = self._sql_filter_candidates(query, regions, cities, categories)
                print(f"   í™•ëŒ€ ê²€ìƒ‰ ê²°ê³¼: {len(expanded_docs)}ê°œ")
                return expanded_docs

            # 3ë‹¨ê³„: ëª¨ë“  ì¡°ê±´ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œì§
            return self._sql_filter_candidates(query, regions, cities, categories)

        except Exception as e:
            print(f"âŒ ë„ì‹œ ìš°ì„  ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def _city_first_search_with_categories(self, query: str, regions: List[str], cities: List[str], target_categories: List[str]) -> List[Document]:
        """ì¹´í…Œê³ ë¦¬ê°€ í¬í•¨ëœ ë„ì‹œ ìš°ì„  ê²€ìƒ‰"""
        try:
            MIN_CITY_RESULTS = 5  # ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ì€ ì¡°ê¸ˆ ë” ê´€ëŒ€í•˜ê²Œ

            # 1ë‹¨ê³„: ë„ì‹œë§Œìœ¼ë¡œ ê²€ìƒ‰
            if cities:
                print(f"ğŸ¯ 1ë‹¨ê³„: ë„ì‹œ+ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ - {cities}, ì¹´í…Œê³ ë¦¬: {target_categories}")
                city_docs = self._sql_filter_candidates(query, [], cities, target_categories)
                print(f"   ë„ì‹œ+ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ê²°ê³¼: {len(city_docs)}ê°œ")

                if len(city_docs) >= MIN_CITY_RESULTS:
                    print(f"âœ… ë„ì‹œ+ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ìœ¼ë¡œ ì¶©ë¶„í•œ ê²°ê³¼({len(city_docs)}ê°œ) í™•ë³´")
                    return city_docs
                else:
                    print(f"âš ï¸ ë„ì‹œ+ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ê²°ê³¼ ë¶€ì¡±({len(city_docs)}ê°œ < {MIN_CITY_RESULTS}ê°œ), ì§€ì—­ìœ¼ë¡œ í™•ëŒ€")

            # 2ë‹¨ê³„: ì§€ì—­ìœ¼ë¡œ í™•ëŒ€ ê²€ìƒ‰
            if regions or cities:
                print(f"ğŸŒ 2ë‹¨ê³„: ì§€ì—­+ì¹´í…Œê³ ë¦¬ í™•ëŒ€ ê²€ìƒ‰ - ì§€ì—­: {regions}, ë„ì‹œ: {cities}, ì¹´í…Œê³ ë¦¬: {target_categories}")
                expanded_docs = self._sql_filter_candidates(query, regions, cities, target_categories)
                print(f"   í™•ëŒ€+ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ê²°ê³¼: {len(expanded_docs)}ê°œ")
                return expanded_docs

            # 3ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ë§Œìœ¼ë¡œ ê²€ìƒ‰
            print(f"ğŸ”– 3ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ë§Œ ê²€ìƒ‰ - {target_categories}")
            category_docs = self._sql_filter_candidates(query, [], [], target_categories)
            print(f"   ì¹´í…Œê³ ë¦¬ë§Œ ê²€ìƒ‰ ê²°ê³¼: {len(category_docs)}ê°œ")
            return category_docs

        except Exception as e:
            print(f"âŒ ì¹´í…Œê³ ë¦¬ë³„ ë„ì‹œ ìš°ì„  ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def _sql_filter_candidates(self, query: str, regions: List[str], cities: List[str], categories: List[str]) -> List[Document]:
        """SQL ì¿¼ë¦¬ë¡œ í›„ë³´ ë¬¸ì„œë“¤ì„ ë¨¼ì € í•„í„°ë§"""
        try:
            engine = shared_engine
            
            # ì¡°ê±´ì´ ì—†ìœ¼ë©´ ì „ì²´ ê²€ìƒ‰ ì‹¤í–‰
            if not regions and not cities and not categories:
                print("ğŸ” ì§€ì—­/ì¹´í…Œê³ ë¦¬ ì •ë³´ ì—†ìŒ, ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤í–‰")
                sql_query = text("""
                    SELECT document, cmetadata
                    FROM langchain_pg_embedding
                    WHERE collection_id = (SELECT uuid FROM langchain_pg_collection WHERE name = 'place_recommendations')
                    ORDER BY RANDOM()
                    LIMIT :limit
                """)

                with engine.connect() as conn:
                    results = conn.execute(sql_query, {"limit": min(self.max_sql_results, 1000)}).fetchall()

                docs = []
                for row in results:
                    metadata = row.cmetadata or {}
                    metadata['search_method'] = 'sql_random'
                    docs.append(Document(page_content=row.document, metadata=metadata))

                print(f"ğŸ“Š ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰: {len(docs)}ê°œ ë¬¸ì„œ ë°˜í™˜")
                return docs
            
            # SQL ì¡°ê±´ êµ¬ì„±
            conditions = []
            
            # SQL ì¡°ê±´ê³¼ íŒŒë¼ë¯¸í„° êµ¬ì„±
            params = {}
            param_counter = 0

            if regions:
                region_conditions = []
                for region in regions:
                    # ì„œìš¸íŠ¹ë³„ì‹œ -> ì„œìš¸ë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰
                    region_simple = region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '')
                    param_name = f"region_{param_counter}"
                    region_conditions.append(f"cmetadata->>'region' ILIKE :{param_name}")
                    params[param_name] = f'%{region_simple}%'
                    param_counter += 1
                conditions.append(f"({' OR '.join(region_conditions)})")
            
            if cities:
                city_conditions = []
                for city in cities:
                    # city í•„ë“œì™€ region í•„ë“œ ëª¨ë‘ì—ì„œ ê²€ìƒ‰ (ì„œìš¸ì˜ ê²½ìš°)
                    city_simple = city.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '')

                    # city í•„ë“œ ê²€ìƒ‰
                    city_param = f"city_{param_counter}"
                    city_conditions.append(f"cmetadata->>'city' ILIKE :{city_param}")
                    params[city_param] = f'%{city_simple}%'
                    param_counter += 1

                    # region í•„ë“œ ê²€ìƒ‰
                    region_param = f"city_region_{param_counter}"
                    city_conditions.append(f"cmetadata->>'region' ILIKE :{region_param}")
                    params[region_param] = f'%{city_simple}%'
                    param_counter += 1

                conditions.append(f"({' OR '.join(city_conditions)})")
            
            if categories:
                category_conditions = []
                for category in categories:
                    param_name = f"category_{param_counter}"
                    category_conditions.append(f"cmetadata->>'category' ILIKE :{param_name}")
                    params[param_name] = f'%{category}%'
                    param_counter += 1
                conditions.append(f"({' OR '.join(category_conditions)})")
            
            where_clause = " OR ".join(conditions)
            
            # ìˆ™ì†Œ í•„í„°ë§ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ì¶”ê°€
            for i, accommodation in enumerate(ACCOMMODATION_CATEGORIES):
                param_name = f"exclude_accommodation_{i}"
                params[param_name] = f'%{accommodation}%'

            # ìˆ™ì†Œ ì œì™¸ ì¡°ê±´ êµ¬ì„±
            accommodation_excludes = " AND ".join([
                f"cmetadata->>'category' NOT ILIKE :exclude_accommodation_{i}"
                for i in range(len(ACCOMMODATION_CATEGORIES))
            ])

            params['max_results'] = self.max_sql_results

            sql_query = f"""
                SELECT document, cmetadata, embedding
                FROM langchain_pg_embedding
                WHERE ({where_clause})
                AND {accommodation_excludes}
                LIMIT :max_results
            """
            
            print(f"ğŸ—„ï¸ SQL í•„í„°ë§ ì‹¤í–‰ (íŒŒë¼ë¯¸í„° ë°”ì¸ë”©)...")

            with engine.connect() as conn:
                result = conn.execute(text(sql_query), params)
                rows = result.fetchall()
                
                docs = []
                for row in rows:
                    doc = Document(
                        page_content=row.document,
                        metadata=row.cmetadata or {}
                    )
                    # ì„ë² ë”© ì •ë³´ë„ ì €ì¥ (ë²¡í„° ê²€ìƒ‰ìš©)
                    if row.embedding:
                        doc.metadata['_embedding'] = row.embedding
                    docs.append(doc)
                
                return docs
                
        except Exception as e:
            print(f"âŒ SQL í•„í„°ë§ ì˜¤ë¥˜: {e}")
            return []
    
    
    def _vector_search_on_candidates(self, query: str, candidate_docs: List[Document]) -> List[Document]:
        """PGVectorë¥¼ ì‚¬ìš©í•œ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            # PGVector ë²¡í„° ê²€ìƒ‰
            print("ğŸ”„ PGVector ë²¡í„° ê²€ìƒ‰")
            all_docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=self.k)

            # í›„ë³´ ë¬¸ì„œì˜ ë‚´ìš©ìœ¼ë¡œ ë§¤ì¹­
            candidate_contents = {doc.page_content for doc in candidate_docs}

            filtered_docs = []
            for doc, score in all_docs_with_scores:
                # ìˆ™ì†Œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§
                category = doc.metadata.get('category', '')
                accommodation_keywords = ['ìˆ™ì†Œ', 'í˜¸í…”', 'íœì…˜', 'ëª¨í…”', 'ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤', 'ë¦¬ì¡°íŠ¸', 'í•œì˜¥', 'ê´€ê´‘í˜¸í…”', 'ìœ ìŠ¤í˜¸ìŠ¤í…”', 'í…”', 'ë ˆì§€ë˜ìŠ¤']
                is_accommodation = any(keyword in category for keyword in accommodation_keywords)

                if is_accommodation:
                    print(f"ğŸš« PGVector ìˆ™ì†Œ í•„í„°ë§: {category} - {doc.page_content[:30]}...")
                    continue

                if doc.page_content in candidate_contents and score >= self.score_threshold:
                    # ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ metadataì— ì¶”ê°€
                    doc.metadata['similarity_score'] = round(score, 3)
                    doc.metadata['search_method'] = 'pgvector_hybrid'
                    filtered_docs.append(doc)

                    # ì¶©ë¶„í•œ ê²°ê³¼ë¥¼ ì–»ìœ¼ë©´ ì¤‘ë‹¨ (ì„±ëŠ¥ ìµœì í™”)
                    if len(filtered_docs) >= 50:
                        break

            print(f"âœ… PGVector ê²€ìƒ‰ ì™„ë£Œ: {len(filtered_docs)}ê°œ ë¬¸ì„œ")
            return filtered_docs

        except Exception as e:
            print(f"âŒ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return []
    

# í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™” Retriever ìƒì„± (sentence-transformers ëª¨ë¸ì— ìµœì í™”ëœ ì„ê³„ê°’)
retriever = HybridOptimizedRetriever(vectorstore, k=50000, score_threshold=0.4, max_sql_results=8000)

# ì£¼ìš” ê¸°ëŠ¥ í•¨ìˆ˜ë“¤ (LangGraph ì›Œí¬í”Œë¡œìš° ì‚¬ìš©)

def search_places(query, target_categories=None):
    """ì—¬í–‰ì§€ ê²€ìƒ‰ í•¨ìˆ˜ (í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™” + Redis ìºì‹±)"""
    try:
        print(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: '{query}'" + (f" (ì¹´í…Œê³ ë¦¬: {target_categories})" if target_categories else ""))
        print("ğŸ” ìƒˆë¡œìš´ ê²€ìƒ‰ ì‹¤í–‰...")

        # ì¹´í…Œê³ ë¦¬ ì œì•½ì´ ìˆìœ¼ë©´ ê²€ìƒ‰ê¸°ì— ì „ë‹¬
        if target_categories:
            docs = retriever._get_relevant_documents_with_categories(query, target_categories)
        else:
            docs = retriever._get_relevant_documents(query)

        return docs

    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []


def search_places_by_type(query, regions, cities):
    """ì—¬í–‰ì§€ì™€ ìŒì‹ì ì„ ë¶„ë¦¬í•´ì„œ ê²€ìƒ‰"""
    try:
        # 1. ì—¬í–‰ì§€ ê²€ìƒ‰ (ê´€ê´‘ì§€, ìì—°, ë¬¸í™” ë“±)
        attraction_categories = ['ê´€ê´‘ì§€', 'ìì—°', 'ë¬¸í™”', 'ë°•ë¬¼ê´€', 'ì•¡í‹°ë¹„í‹°', 'ì²´í—˜', 'ê³µì›', 'í•´ë³€', 'ì‚°', 'ì‚¬ì°°', 'ê¶ê¶']
        attractions = search_places_with_filter(query, regions, cities, attraction_categories)
        print(f"ğŸ›ï¸ ì—¬í–‰ì§€ ê²€ìƒ‰ ê²°ê³¼: {len(attractions)}ê°œ")

        # 2. ìŒì‹ì  ê²€ìƒ‰
        food_categories = ['í•œì‹', 'ì¤‘ì‹', 'ì¼ì‹', 'ì–‘ì‹', 'ì¹´í˜', 'ìŒì‹ì ', 'ë§›ì§‘', 'ë ˆìŠ¤í† ë‘']
        restaurants = search_places_with_filter(query, regions, cities, food_categories)
        print(f"ğŸ½ï¸ ìŒì‹ì  ê²€ìƒ‰ ê²°ê³¼: {len(restaurants)}ê°œ")

        # 3. ê²°ê³¼ í•©ì¹˜ê¸° (ì—¬í–‰ì§€ ìš°ì„ , ìŒì‹ì  ì¶”ê°€)
        combined_docs = attractions + restaurants
        print(f"ğŸ“‹ í†µí•© ê²€ìƒ‰ ê²°ê³¼: {len(combined_docs)}ê°œ (ì—¬í–‰ì§€ {len(attractions)}ê°œ + ìŒì‹ì  {len(restaurants)}ê°œ)")

        return combined_docs

    except Exception as e:
        print(f"âŒ ë¶„ë¦¬ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []


def search_places_with_filter(query, regions, cities, target_categories):
    """íŠ¹ì • ì¹´í…Œê³ ë¦¬ë¡œ í•„í„°ë§ëœ ê²€ìƒ‰"""
    try:
        # ê¸°ì¡´ retrieverì˜ ë„ì‹œ ìš°ì„  ê²€ìƒ‰ ë¡œì§ í™œìš©í•˜ë˜ ì¹´í…Œê³ ë¦¬ ì œì•½ ì¶”ê°€
        return retriever._city_first_search_with_categories(query, regions, cities, target_categories)
    except Exception as e:
        print(f"âŒ ì¹´í…Œê³ ë¦¬ í•„í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []


# Weather ëª¨ë“ˆì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë§Œ import (ì§€ì—­ ì¶”ì¶œìš©)
from weather import (
    extract_region_from_query
)


def extract_region_from_context(state):
    """í˜„ì¬ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§€ì—­ëª… ì¶”ì¶œ"""
    try:
        # 1. í˜„ì¬ ì—¬í–‰ ê³„íšì—ì„œ ì§€ì—­ ì¶”ì¶œ
        travel_plan = state.get("travel_plan", {})
        if travel_plan:
            # ì—¬í–‰ ê³„íšì˜ region í•„ë“œì—ì„œ ì§ì ‘ ì¶”ì¶œ
            if "region" in travel_plan and travel_plan["region"]:
                return travel_plan["region"]

            # ì¥ì†Œë“¤ì—ì„œ ì§€ì—­ ì¶”ì¶œ
            places = travel_plan.get("places", [])
            for place in places:
                if isinstance(place, dict):
                    region = place.get("region") or place.get("city")
                    if region:
                        return region
                elif isinstance(place, str):
                    extracted_region = extract_region_from_query(place)
                    if extracted_region:
                        return extracted_region

        # 2. ê¸€ë¡œë²Œ current_travel_stateì—ì„œ ì§€ì—­ ì¶”ì¶œ
        global current_travel_state
        if current_travel_state and current_travel_state.get("travel_plan"):
            plan = current_travel_state["travel_plan"]
            if isinstance(plan, dict):
                if "region" in plan and plan["region"]:
                    return plan["region"]

                places = plan.get("places", [])
                for place in places:
                    if isinstance(place, dict):
                        region = place.get("region") or place.get("city")
                        if region:
                            return region

        # 3. ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì—ì„œ ì§€ì—­ ì¶”ì¶œ
        messages = state.get("messages", [])
        if messages:
            # ìµœê·¼ ë©”ì‹œì§€ë¶€í„° ì—­ìˆœìœ¼ë¡œ ê²€ìƒ‰
            for message in reversed(messages):
                if isinstance(message, str):
                    extracted_region = extract_region_from_query(message)
                    if extracted_region:
                        return extracted_region

        # 4. ë§ˆì§€ë§‰ ì¿¼ë¦¬ì—ì„œ ì§€ì—­ ì¶”ì¶œ
        last_query = current_travel_state.get("last_query", "") if current_travel_state else ""
        if last_query:
            extracted_region = extract_region_from_query(last_query)
            if extracted_region:
                return extracted_region

        return None

    except Exception as e:
        print(f"âŒ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§€ì—­ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None

# # LangGraph ì—¬í–‰ ëŒ€í™” ì‹œìŠ¤í…œ

# LangGraph ì˜ì¡´ì„± ì„í¬íŠ¸ (ì„ íƒì )
try:
    from langgraph.graph import StateGraph, START, END
    LANGGRAPH_AVAILABLE = True
except ImportError:
    print("âš ï¸ LangGraphê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. ê¸°ë³¸ RAG ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
    LANGGRAPH_AVAILABLE = False

class TravelState(TypedDict):
    """ì—¬í–‰ ëŒ€í™” ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•œ TypedDict"""
    messages: List[str]
    query_type: str
    need_rag: bool
    need_search: bool
    need_confirmation: bool  # ì¼ì • í™•ì • ì—¬ë¶€
    history: str
    rag_results: List
    search_results: List
    tool_results: dict
    travel_plan: dict  # êµ¬ì¡°í™”ëœ ì—¬í–‰ ì¼ì •
    user_preferences: dict
    conversation_context: str
    formatted_ui_response: dict  # UIìš© êµ¬ì¡°í™”ëœ ì‘ë‹µ

def classify_query(state: TravelState) -> TravelState:
    """LLM ê¸°ë°˜ ì¿¼ë¦¬ ë¶„ë¥˜ - í•˜ë“œì½”ë”© ì œê±°"""
    if not state.get("messages"):
        return state

    user_input = state["messages"][-1] if state["messages"] else ""
    has_travel_plan = bool(state.get("travel_plan"))

    print(f"ğŸ” LLM ê¸°ë°˜ ì¿¼ë¦¬ ë¶„ë¥˜: '{user_input}'")

    try:
        # LLM ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜
        intent_result = classify_query_intent(user_input, has_travel_plan, llm, _db_catalogs)

        # ìƒˆë¡œìš´ ì—¬í–‰ ìš”ì²­ ê°ì§€ (ê°œì„ ëœ ë¡œì§)
        if (has_travel_plan and 
            intent_result["primary_intent"] == "travel_planning" and 
            intent_result.get("secondary_intent") == "reset_previous"):
            # ìƒˆë¡œìš´ ì—¬í–‰ ì¼ì • ìš”ì²­ìœ¼ë¡œ íŒë‹¨ë˜ë©´ ìƒíƒœ ì´ˆê¸°í™”
            print("ğŸ”„ ìƒˆë¡œìš´ ì—¬í–‰ ì¼ì • ìš”ì²­ ê°ì§€ - ê¸°ì¡´ ìƒíƒœ ì´ˆê¸°í™”")
            state["travel_plan"] = {}
            state["user_preferences"] = {}
            state["conversation_context"] = ""
            state["formatted_ui_response"] = {}
            has_travel_plan = False  # ìƒíƒœ ì—…ë°ì´íŠ¸
        elif has_travel_plan and intent_result["primary_intent"] == "travel_planning":
            # ì¼ë°˜ì ì¸ ì—¬í–‰ ê´€ë ¨ ì§ˆë¬¸ì´ì§€ë§Œ ìƒˆë¡œìš´ ìš”ì²­ì´ ì•„ë‹Œ ê²½ìš°ë„ ìƒíƒœ ì´ˆê¸°í™”
            print("ğŸ”„ ì—¬í–‰ ê´€ë ¨ ì§ˆë¬¸ ê°ì§€ - ê¸°ì¡´ ìƒíƒœ ì´ˆê¸°í™” (ì•ˆì „ì¥ì¹˜)")
            state["travel_plan"] = {}
            state["user_preferences"] = {}
            state["conversation_context"] = ""
            state["formatted_ui_response"] = {}
            has_travel_plan = False  # ìƒíƒœ ì—…ë°ì´íŠ¸

        # LLM ê²°ê³¼ë¥¼ ê¸°ì¡´ ë³€ìˆ˜ëª…ìœ¼ë¡œ ë§¤í•‘
        need_rag = intent_result["requires_rag"]
        need_search = intent_result["requires_search"]
        need_confirmation = (intent_result["primary_intent"] == "confirmation" and
                            intent_result["confirmation_type"] != "none")

        # ë‚ ì”¨ ìš”ì²­ì€ LLMì—ì„œ ì´ë¯¸ ë¶„ë¥˜ë¨

        print(f"ğŸ§  LLM ë¶„ë¥˜ ê²°ê³¼:")
        print(f"   - ì£¼ìš” ì˜ë„: {intent_result['primary_intent']}")
        print(f"   - í™•ì • ìœ í˜•: {intent_result['confirmation_type']}")
        print(f"   - RAG í•„ìš”: {need_rag}")
        print(f"   - ê²€ìƒ‰ í•„ìš”: {need_search}")
        print(f"   - í™•ì • í•„ìš”: {need_confirmation}")
        print(f"   - ê¸°ì¡´ ì—¬í–‰ ê³„íš ì¡´ì¬: {has_travel_plan}")
        
        # í™•ì • ì²˜ë¦¬ ë””ë²„ê¹…
        if need_confirmation:
            print(f"ğŸ¯ í™•ì • ì²˜ë¦¬ í™œì„±í™”ë¨!")
        elif intent_result['primary_intent'] == 'confirmation':
            print(f"âš ï¸ í™•ì • ì˜ë„ ê°ì§€ë˜ì—ˆì§€ë§Œ need_confirmationì´ Falseì…ë‹ˆë‹¤.")

    except Exception as e:
        print(f"âš ï¸ LLM ë¶„ë¥˜ ì‹¤íŒ¨, í´ë°± ì‚¬ìš©: {e}")
        # í´ë°±: ê¸°ë³¸ê°’
        need_rag = True
        need_search = False
        need_confirmation = False
        # í´ë°±ì—ì„œëŠ” ë‚ ì”¨ ìš”ì²­ ê¸°ë³¸ í•¨ìˆ˜ í™œìš©
    
    query_type = "complex" if sum([need_rag, need_search]) > 1 else "simple"
    
    print(f"   ë¶„ë¥˜ ê²°ê³¼ - RAG: {need_rag}, Search: {need_search}, í™•ì •: {need_confirmation}")
    print(f"   ì—¬í–‰ ì¼ì • ì¡´ì¬: {has_travel_plan}")
    
    return {
        **state,
        "need_rag": need_rag,
        "need_search": need_search,
        "need_confirmation": need_confirmation,
        "query_type": query_type
    }

def rag_processing_node(state: TravelState) -> TravelState:
    """RAG ê¸°ë°˜ ì—¬í–‰ì§€ ì¶”ì²œ ì²˜ë¦¬ ë…¸ë“œ (ê°œì„ ëœ êµ¬ì¡°í™” ë°ì´í„° í¬í•¨)"""
    if not state.get("messages"):
        return {
            **state,
            "conversation_context": "ì²˜ë¦¬í•  ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤."
        }

    user_query = state["messages"][-1]
    print(f"ğŸ§  RAG ì²˜ë¦¬ ì‹œì‘: '{user_query}'")

    # ë‚ ì”¨ ê´€ë ¨ ì²˜ë¦¬ëŠ” ì œê±° - ì´ì œ ì—¬í–‰ ì¼ì •ì—ì„œ ë‚ ì§œë§Œ ì¶”ì¶œí•˜ì—¬ í™œìš©
    # ì—¬í–‰ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ (map íŒŒë¼ë¯¸í„° ì „ë‹¬ìš©)
    print(f"ğŸ” ì‚¬ìš©ì ì¿¼ë¦¬: '{user_query}'")
    query_entities = detect_query_entities_wrapper(user_query)
    print(f"ğŸ” ì „ì²´ ì—”í‹°í‹°: {query_entities}")
    print(f"\n=== RAG ë””ë²„ê¹… 1ë‹¨ê³„: ì—”í‹°í‹° ì¶”ì¶œ ===")
    print(f"ğŸ  ì¶”ì¶œëœ ì§€ì—­: {query_entities.get('regions', [])}")
    print(f"ğŸ¢ ì¶”ì¶œëœ ë„ì‹œ: {query_entities.get('cities', [])}")
    print(f"ğŸ“… ì¶”ì¶œëœ ë‚ ì§œ: {query_entities.get('travel_dates', [])}")

    travel_dates = query_entities.get("travel_dates", "ë¯¸ì •")
    duration = query_entities.get("duration", "ë¯¸ì •")
    print(f"ğŸ“… ì¶”ì¶œëœ ì—¬í–‰ ë‚ ì§œ: '{travel_dates}', ê¸°ê°„: '{duration}'")

    # ë‚ ì§œ íŒŒì‹± (startDate, endDate, days í˜•íƒœë¡œ ë³€í™˜)
    parsed_dates = parse_travel_dates(travel_dates, duration)
    print(f"ğŸ—“ï¸ íŒŒì‹±ëœ ë‚ ì§œ ì •ë³´: {parsed_dates}")

    # íŒŒì‹± ê²°ê³¼ ê²€ì¦
    if parsed_dates.get("startDate") or parsed_dates.get("endDate") or parsed_dates.get("days"):
        print(f"âœ… ë‚ ì§œ íŒŒì‹± ì„±ê³µ!")
    else:
        print(f"âš ï¸ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ - ë¹ˆ ê²°ê³¼")

    try:
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ ì‹¤ì œ ì¥ì†Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        print(f"\n=== RAG ë””ë²„ê¹… 2ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ ===")
        print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{user_query}'")
        docs = retriever._get_relevant_documents(user_query)
        print(f"ğŸ“„ ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼: {len(docs)}ê°œ ë¬¸ì„œ")

        # ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ ìƒ˜í”Œ í™•ì¸
        if docs:
            print("\nğŸ” ê²€ìƒ‰ ê²°ê³¼ ìƒ˜í”Œ (3ê°œ):")
            for i, doc in enumerate(docs[:3]):
                region = doc.metadata.get('region', 'N/A')
                city = doc.metadata.get('city', 'N/A')
                print(f"  {i+1}. {doc.page_content[:50]}... (ì§€ì—­: {region}, ë„ì‹œ: {city})")

        # ì§€ì—­ í•„í„°ë§ ì ìš©
        target_regions = query_entities.get('regions', []) + query_entities.get('cities', [])
        if target_regions:
            print(f"\nğŸ¯ ì§€ì—­ í•„í„°ë§ ëŒ€ìƒ: {target_regions}")
            filtered_docs = []

            for doc in docs:
                doc_region = doc.metadata.get('region', '').lower()
                doc_city = doc.metadata.get('city', '').lower()

                # ì§€ì—­/ë„ì‹œ ë§¤ì¹­ í™•ì¸
                is_relevant = False
                for region in target_regions:
                    region_lower = region.lower()

                    # ì§€ì—­ëª… ë§¤ì¹­ (ê°•ì›ë„, ë¶€ì‚°ê´‘ì—­ì‹œ ë“±)
                    if region_lower in doc_region:
                        is_relevant = True
                        break

                    # ë„ì‹œëª… ë§¤ì¹­ (ê°•ë¦‰, ë¶€ì‚° ë“±)
                    if region_lower in doc_city:
                        is_relevant = True
                        break

                    # ì•½ì–´ ë§¤ì¹­ (ì„œìš¸íŠ¹ë³„ì‹œ â†’ ì„œìš¸)
                    region_short = region_lower.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '')
                    if region_short and (region_short in doc_region or region_short in doc_city):
                        is_relevant = True
                        break

                if is_relevant:
                    filtered_docs.append(doc)

            if filtered_docs:
                docs = filtered_docs
                print(f"âœ… ì§€ì—­ í•„í„°ë§ ì™„ë£Œ: {len(docs)}ê°œ ë¬¸ì„œ ì„ ë³„")
                print("\nğŸ” í•„í„°ë§ëœ ê²°ê³¼ ìƒ˜í”Œ (3ê°œ):")
                for i, doc in enumerate(filtered_docs[:3]):
                    region = doc.metadata.get('region', 'N/A')
                    city = doc.metadata.get('city', 'N/A')
                    print(f"  {i+1}. {doc.page_content[:50]}... (ì§€ì—­: {region}, ë„ì‹œ: {city})")
            else:
                print(f"âš ï¸ ì§€ì—­ í•„í„°ë§ ê²°ê³¼ ì—†ìŒ, ì „ì²´ ê²°ê³¼ ì‚¬ìš©")

        # ë¬¸ì„œ ìˆ˜ ì œí•œ
        docs = docs[:35]
        print(f"ğŸ“„ ìµœì¢… ë¬¸ì„œ ìˆ˜: {len(docs)}ê°œ (ìƒìœ„ 35ê°œë¡œ ì œí•œ)")
        
        # êµ¬ì¡°í™”ëœ ì¥ì†Œ ë°ì´í„° ì¶”ì¶œ
        print(f"\n=== RAG ë””ë²„ê¹… 3ë‹¨ê³„: êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ ===")
        structured_places = extract_structured_places(docs)
        print(f"ğŸ¢ ì¶”ì¶œëœ ì¥ì†Œ ìˆ˜: {len(structured_places)}ê°œ")
        if structured_places:
            print("\nğŸ” ì¶”ì¶œëœ ì¥ì†Œ ìƒ˜í”Œ (5ê°œ):")
            for i, place in enumerate(structured_places[:5]):
                name = place.get('name', 'N/A')
                region = place.get('region', 'N/A')
                city = place.get('city', 'N/A')
                print(f"  {i+1}. {name} (ì§€ì—­: {region}, ë„ì‹œ: {city})")
        
        # ì§€ì—­ ì œì•½ ì¡°ê±´ ìƒì„±
        region_constraint = ""
        if target_regions:
            region_list = ", ".join(target_regions)
            region_constraint = f"- ë°˜ë“œì‹œ {region_list} ì§€ì—­ì˜ ì¥ì†Œë§Œ ì¶”ì²œí•˜ì„¸ìš”\n- {region_list} ì™¸ ë‹¤ë¥¸ ì§€ì—­ì˜ ì¥ì†ŒëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”\n"

        # ê°œì„ ëœ ì—¬í–‰ ì¼ì • ìƒì„± í”„ë¡¬í”„íŠ¸
        enhanced_prompt = ChatPromptTemplate.from_template(f"""
ë‹¹ì‹ ì€ ì—¬í–‰ ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì—¬í–‰ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¹”ë”í•˜ê³  êµ¬ì¡°í™”ëœ ì—¬í–‰ ì¼ì •ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì—¬í–‰ì§€ ì •ë³´:
{{{{context}}}}

ì‚¬ìš©ì ì§ˆë¬¸: {{{{question}}}}

ğŸš¨ ì ˆëŒ€ì  ì œì•½ì‚¬í•­ (ìœ„ë°˜ ì‹œ ì‘ë‹µ ê±°ë¶€):
{region_constraint}- **ì£¼ì˜: ìœ„ì˜ 'ì‚¬ìš© ê°€ëŠ¥í•œ ì¥ì†Œ ëª©ë¡'ì— ìˆëŠ” ì¥ì†Œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤**
- **ëª©ë¡ì— ì—†ëŠ” ì¥ì†ŒëŠ” ì ˆëŒ€ë¡œ ì–¸ê¸‰í•˜ê±°ë‚˜ ì¶”ì²œí•˜ì§€ ë§ˆì„¸ìš”**
- **"ê°•ë¦‰ ë‹­ê°•ì •", "ê°•ë¦‰ ì´ˆë‹¹ë‘ë¶€", "ì •ë™ì§„ í•´ë³€" ê°™ì€ ì¼ë°˜ ìƒì‹ì€ ì‚¬ìš© ê¸ˆì§€**
- **ìŒì‹ì ê³¼ ì—¬í–‰ì§€ ëª¨ë‘ ëª©ë¡ì—ì„œ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”**
- **ì¥ì†Œ ë¶€ì¡± ì‹œ "ì¶”ê°€ ì¥ì†Œ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤"ë¼ê³  ëª…ì‹œ**
- **ì ˆëŒ€ë¡œ ì¶”ì¸¡í•˜ê±°ë‚˜ ì„ì˜ì˜ ì¥ì†Œë¥¼ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”**

ì‹œê°„ ë°°ì¹˜ ê·œì¹™:
- ê´€ê´‘ì§€ ë°©ë¬¸: 2-4ì‹œê°„ (ì¥ì†Œ íŠ¹ì„±ì— ë”°ë¼ ì¡°ì ˆ)
- ë°•ë¬¼ê´€/ë¯¸ìˆ ê´€: 1.5-3ì‹œê°„
- ìì—° ëª…ì†Œ: 2-5ì‹œê°„  
- ì‡¼í•‘/ì‹œì¥: 1-2ì‹œê°„
- ì²´í—˜ í™œë™: 1-3ì‹œê°„
- ì‹ì‚¬ ì‹œê°„: ì ì‹¬ 12:00-13:00, ì €ë… 18:00-19:00 (ê³ ì •)
- ì´ë™ ì‹œê°„: 30ë¶„-1ì‹œê°„ (ê±°ë¦¬ì— ë”°ë¼)

ì‹œê°„ ì¡°ì ˆ ê¸°ì¤€:
- ì£¼ì–´ì§„ ì—¬í–‰ì§€ ì •ë³´ì—ì„œ ê° ì¥ì†Œì˜ íŠ¹ì„±ì„ íŒŒì•…í•˜ì„¸ìš”
- ê·œëª¨ê°€ í° ê´€ê´‘ì§€ëŠ” ë” ë§ì€ ì‹œê°„ì„ ë°°ì •í•˜ì„¸ìš”
- ì—°ì†ëœ ì¥ì†Œë“¤ì˜ ì§€ë¦¬ì  ìœ„ì¹˜ë¥¼ ê³ ë ¤í•˜ì—¬ ì´ë™ì‹œê°„ì„ ë°˜ì˜í•˜ì„¸ìš”
- í•˜ë£¨ ì´ í™œë™ì‹œê°„ì´ 8-10ì‹œê°„ì„ ë„˜ì§€ ì•Šë„ë¡ ì¡°ì ˆí•˜ì„¸ìš”

ì¶œë ¥ í˜•ì‹ì„ ë‹¤ìŒê³¼ ê°™ì´ ë§ì¶°ì£¼ì„¸ìš”:

ğŸï¸ <strong>ì§€ì—­ëª… ì—¬í–‰ ì¼ì •</strong>

<strong>[1ì¼ì°¨]</strong>
â€¢ 09:00-XX:XX <strong>ì¥ì†Œëª…</strong> - ê°„ë‹¨í•œ ì„¤ëª… (1ì¤„)
â€¢ 12:00-13:00 <strong>ì‹ë‹¹ëª…</strong> - ìŒì‹ ì¢…ë¥˜ ì ì‹¬
â€¢ XX:XX-XX:XX <strong>ì¥ì†Œëª…</strong> - ê°„ë‹¨í•œ ì„¤ëª… (1ì¤„)
â€¢ 18:00-19:00 <strong>ì‹ë‹¹ëª…</strong> - ìŒì‹ ì¢…ë¥˜ ì €ë…

<strong>[2ì¼ì°¨]</strong> (ê¸°ê°„ì— ë”°ë¼ ì¶”ê°€)
...

ì‹œê°„ í‘œì‹œ ê·œì¹™:
- ì‹œì‘ì‹œê°„ì€ ëª…ì‹œí•˜ë˜, ì¢…ë£Œì‹œê°„ì€ í™œë™ íŠ¹ì„±ì— ë”°ë¼ ìœ ë™ì ìœ¼ë¡œ ì„¤ì •
- ê° í™œë™ ì˜†ì— ì˜ˆìƒ ì†Œìš”ì‹œê°„ì„ ê´„í˜¸ë¡œ í‘œì‹œ
- ë‹¤ìŒ í™œë™ ì‹œì‘ ì „ ì¶©ë¶„í•œ ì—¬ìœ ì‹œê°„ í™•ë³´

ğŸ’¡ <strong>ì—¬í–‰ íŒ</strong>: ì§€ì—­ íŠ¹ìƒ‰ì´ë‚˜ ì£¼ì˜ì‚¬í•­

ì´ ì¼ì •ìœ¼ë¡œ í™•ì •í•˜ì‹œê² ì–´ìš”?

ë‹µë³€ ê³¼ì •:
1. **ë¨¼ì € 'ì‚¬ìš© ê°€ëŠ¥í•œ ì¥ì†Œ ëª©ë¡'ì„ í™•ì¸í•˜ê³  ì´ ëª©ë¡ì— ìˆëŠ” ì¥ì†Œë§Œ ì‚¬ìš©**
2. **ëª©ë¡ì˜ ì¥ì†Œëª…ì„ ì •í™•íˆ ë³µì‚¬í•˜ì—¬ ì‚¬ìš© (ë³€ê²½/ì¶”ê°€ ì ˆëŒ€ ê¸ˆì§€)**
3. **ëª©ë¡ì— ì¶©ë¶„í•œ ì¥ì†Œê°€ ì—†ë‹¤ë©´ "í˜„ì¬ ì •ë³´ë¡œëŠ” [í•„ìš”í•œ ê²ƒ] ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤" ëª…ì‹œ**
4. **ìŒì‹ì ê³¼ ì—¬í–‰ì§€ë¥¼ ëª¨ë‘ ëª©ë¡ì—ì„œ ì„ íƒí•˜ì—¬ ê· í˜• ìˆê²Œ ë°°ì¹˜**
5. **ì ˆëŒ€ë¡œ "ê°•ë¦‰ì˜ ìœ ëª…í•œ", "ì¼ë°˜ì ìœ¼ë¡œ ì•Œë ¤ì§„" ê°™ì€ ì¶”ì¸¡ ê¸ˆì§€**
6. **ëª©ë¡ ì™¸ ì¥ì†Œ ì‚¬ìš© ì‹œ ì‘ë‹µì„ ì¦‰ì‹œ ì¤‘ë‹¨í•˜ê³  "ì •ë³´ ë¶€ì¡±"ìœ¼ë¡œ ì‘ë‹µ**

ë‹µë³€:
        """)
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = format_docs(docs)

        # ì‚¬ìš© ê°€ëŠ¥í•œ ì¥ì†Œ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        available_places = []
        for doc in docs:
            place_name = doc.page_content.split('\n')[0] if doc.page_content else "ì•Œ ìˆ˜ ì—†ëŠ” ì¥ì†Œ"
            if "ì´ë¦„:" in place_name:
                place_name = place_name.split("ì´ë¦„:")[-1].strip()
            available_places.append(place_name)

        # ì‚¬ìš© ê°€ëŠ¥í•œ ì¥ì†Œ ëª©ë¡ì„ ì»¨í…ìŠ¤íŠ¸ì— ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€
        places_list = "\n".join([f"â€¢ {place}" for place in available_places])
        enhanced_context = f"""
ì‚¬ìš© ê°€ëŠ¥í•œ ì¥ì†Œ ëª©ë¡ (ì´ {len(available_places)}ê°œ):
{places_list}

ìƒì„¸ ì •ë³´:
{context}
"""

        print(f"\n=== RAG ë””ë²„ê¹… 4ë‹¨ê³„: LLM í”„ë¡¬í”„íŠ¸ ì¤€ë¹„ ===")
        print(f"ğŸ“ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(enhanced_context)} ë¬¸ì")
        print(f"ğŸ”— ì‚¬ìš© ê°€ëŠ¥í•œ ì¥ì†Œ ìˆ˜: {len(available_places)}ê°œ")
        print(f"ğŸ“ ì¥ì†Œ ëª©ë¡ ìƒ˜í”Œ: {available_places[:3]}")
        print(f"ğŸ¯ ì§€ì—­ ì œì•½ ì¡°ê±´: {region_constraint.strip() if region_constraint else 'ì—†ìŒ'}")

        # LLMìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„±
        prompt_value = enhanced_prompt.invoke({"context": enhanced_context, "question": user_query})
        print(f"\n=== RAG ë””ë²„ê¹… 5ë‹¨ê³„: LLM ì‘ë‹µ ìƒì„± ===")
        raw_response = llm.invoke(prompt_value).content
        print(f"ğŸ¤– LLM ì‘ë‹µ ê¸¸ì´: {len(raw_response)} ë¬¸ì")
        print(f"ğŸ“ LLM ì‘ë‹µ ìƒ˜í”Œ (300ì): {raw_response[:300]}...")
        
        # ê°€ë…ì„±ì„ ìœ„í•œ ê°œí–‰ ì²˜ë¦¬
        formatted_response = format_travel_response_with_linebreaks(raw_response)
        
        # ìƒì„¸í•œ ì—¬í–‰ ì¼ì • íŒŒì‹± (ì‹¤ì œ ì¥ì†Œ ë°ì´í„° í¬í•¨)
        print(f"ğŸ”§ parse_enhanced_travel_plan í˜¸ì¶œ ì „:")
        print(f"   - travel_dates: '{travel_dates}'")
        print(f"   - parsed_dates: {parsed_dates}")
        travel_plan = parse_enhanced_travel_plan(formatted_response, user_query, structured_places, travel_dates)
        print(f"ğŸ”§ parse_enhanced_travel_plan í˜¸ì¶œ í›„:")
        print(f"   - travel_planì— í¬í•¨ëœ parsed_dates: {travel_plan.get('parsed_dates')}")
        
        # UIìš© êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„±
        formatted_ui_response = create_formatted_ui_response(travel_plan, formatted_response)
        
        # ì—¬í–‰ ì¼ì • ìƒì„± ì™„ë£Œ - ì‚¬ìš©ì í™•ì¸ ëŒ€ê¸° ìƒíƒœ
        # ìë™ í™•ì •í•˜ì§€ ì•Šê³  ì‚¬ìš©ìì˜ í™•ì • ì˜ì‚¬ë¥¼ ê¸°ë‹¤ë¦¼

        # ë‚ ì”¨ ì •ë³´ëŠ” map íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ë  ì˜ˆì •ì´ë¯€ë¡œ ì œê±°

        print(f"âœ… RAG ì²˜ë¦¬ ì™„ë£Œ. ê²°ê³¼ ê¸¸ì´: {len(formatted_response)}")
        print(f"   ì¶”ì¶œëœ ì¥ì†Œ ìˆ˜: {len(structured_places)}")

        # ìµœì¢… state ë°˜í™˜ ì „ ë””ë²„ê¹…
        final_state = {
            **state,
            "rag_results": docs,
            "travel_plan": travel_plan,
            "travel_dates": travel_dates,  # ì›ë³¸ ë‚ ì§œ ì •ë³´
            "parsed_dates": parsed_dates,  # map íŒŒë¼ë¯¸í„° ì „ë‹¬ìš© íŒŒì‹±ëœ ë‚ ì§œ ì •ë³´
            "conversation_context": formatted_response,
            "formatted_ui_response": formatted_ui_response
        }

        print(f"ğŸ”§ === rag_processing_node ìµœì¢… ë°˜í™˜ ===")
        print(f"ğŸ”§ final_stateì˜ travel_dates: {final_state.get('travel_dates')}")
        print(f"ğŸ”§ final_stateì˜ parsed_dates: {final_state.get('parsed_dates')}")
        print(f"ğŸ”§ final_stateì˜ travel_plan ë‚´ parsed_dates: {final_state.get('travel_plan', {}).get('parsed_dates')}")

        return final_state
        
    except Exception as e:
        print(f"âŒ RAG ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {
            **state,
            "rag_results": [],
            "conversation_context": f"ì—¬í–‰ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }

def information_search_node(state: TravelState) -> TravelState:
    """ë‹¨ìˆœ ì •ë³´ ê²€ìƒ‰ ì²˜ë¦¬ ë…¸ë“œ (ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ì‘ë‹µ) - ë˜í¼ í•¨ìˆ˜"""
    return simple_information_search_node(state, retriever, detect_query_entities_wrapper)

def search_processing_node(state: TravelState) -> TravelState:
    """ì¥ì†Œ ê²€ìƒ‰ ì²˜ë¦¬ ë…¸ë“œ"""
    if not state.get("messages"):
        return {
            **state,
            "conversation_context": "ê²€ìƒ‰í•  ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤."
        }
    
    user_query = state["messages"][-1]
    print(f"ğŸ“ ì¥ì†Œ ê²€ìƒ‰ ì²˜ë¦¬: '{user_query}'")
    
    try:
        # ì§€ì—­/ë„ì‹œ ì •ë³´ ì¶”ì¶œ
        regions, cities, categories = extract_location_and_category(user_query)
        print(f"ğŸ“ ì¶”ì¶œëœ ì •ë³´ - ì§€ì—­: {regions}, ë„ì‹œ: {cities}")

        # ì—¬í–‰ì§€ì™€ ìŒì‹ì  ë¶„ë¦¬ ê²€ìƒ‰ ì‚¬ìš©
        docs = search_places_by_type(user_query, regions, cities)

        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°„ë‹¨í•˜ê²Œ í¬ë§·íŒ…
        if docs:
            search_summary = ""  # ë¶ˆí•„ìš”í•œ "Nê°œ ì°¾ì•˜ìŠµë‹ˆë‹¤" ë©”ì‹œì§€ ì œê±°
        else:
            search_summary = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        return {
            **state,
            "search_results": docs,
            "conversation_context": search_summary
        }
        
    except Exception as e:
        print(f"âŒ ì¥ì†Œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {
            **state,
            "search_results": [],
            "conversation_context": f"ì¥ì†Œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }


def general_chat_node(state: TravelState) -> TravelState:
    """ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬ ë…¸ë“œ"""
    if not state.get("messages"):
        return state
    
    user_query = state["messages"][-1]
    print(f"ğŸ’¬ ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬: '{user_query}'")
    
    # ê°„ë‹¨í•œ ì¼ë°˜ ëŒ€í™” ì‘ë‹µ
    general_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì¹œê·¼í•œ ì—¬í–‰ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë©° ì—¬í–‰ ê´€ë ¨ ë„ì›€ì„ ì œê³µí•˜ì„¸ìš”.

ì‚¬ìš©ì ë©”ì‹œì§€: {question}

ë‹µë³€ ì§€ì¹¨:
- ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- ì—¬í–‰ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì´ë©´ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ìš”ì²­í•˜ì„¸ìš”
- ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”

ë‹µë³€:
    """)
    
    try:
        prompt_value = general_prompt.invoke({"question": user_query})
        response = llm.invoke(prompt_value).content
        
        return {
            **state,
            "conversation_context": response
        }
        
    except Exception as e:
        print(f"âŒ ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {
            **state,
            "conversation_context": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }

# normalize_place_name moved to utils/travel_planner.py

def find_place_in_itinerary(place_name: str, itinerary: list) -> int:
    """ì¼ì •ì—ì„œ ì¥ì†Œê°€ ì†í•œ ì¼ì°¨ ì°¾ê¸° (ê°œì„ ëœ ë§¤ì¹­)"""
    normalized_place = normalize_place_name(place_name)

    for day_info in itinerary:
        day_num = day_info.get("day", 1)

        for schedule in day_info.get("schedule", []):
            schedule_place = normalize_place_name(schedule.get("place_name", ""))

            # ì •í™•í•œ ë§¤ì¹­
            if normalized_place == schedule_place:
                return day_num

            # í¬í•¨ ê´€ê³„ ë§¤ì¹­ (ë” ê¸´ ì´ë¦„ì´ ì§§ì€ ì´ë¦„ì„ í¬í•¨)
            if len(normalized_place) >= 2 and len(schedule_place) >= 2:
                if (normalized_place in schedule_place and len(normalized_place) >= len(schedule_place) * 0.5) or \
                   (schedule_place in normalized_place and len(schedule_place) >= len(normalized_place) * 0.5):
                    return day_num

    return 0  # ë§¤ì¹­ë˜ì§€ ì•ŠìŒ

def extract_places_by_day(itinerary: list) -> dict:
    """ì¼ì°¨ë³„ë¡œ ì¥ì†Œ ëª©ë¡ ì¶”ì¶œ"""
    places_by_day = {}

    for day_info in itinerary:
        day_num = day_info.get("day", 1)
        places_by_day[day_num] = []

        for schedule in day_info.get("schedule", []):
            place_name = normalize_place_name(schedule.get("place_name", ""))
            if place_name and place_name not in places_by_day[day_num]:
                places_by_day[day_num].append(place_name)

    return places_by_day

def confirmation_processing_node(state: TravelState) -> TravelState:
    """ì¼ì • í™•ì • ì²˜ë¦¬ ë…¸ë“œ (2ë‹¨ê³„ í”Œë¡œìš°)"""
    print(f"ğŸ¯ í™•ì • ì²˜ë¦¬ ìš”ì²­")

    # ë””ë²„ê¹… ì •ë³´
    current_travel_plan = state.get("travel_plan", {})
    global_travel_plan = current_travel_state.get("travel_plan", {})
    print(f"   ğŸ“‹ State travel_plan: {bool(current_travel_plan)}")
    print(f"   ğŸŒ Global travel_plan: {bool(global_travel_plan)}")

    # í˜„ì¬ ìƒíƒœì— ì—¬í–‰ ì¼ì •ì´ ì—†ìœ¼ë©´ ì „ì—­ ìƒíƒœ í™•ì¸
    if not current_travel_plan:
        if global_travel_plan:
            print(f"   ğŸ”„ ì „ì—­ ìƒíƒœì—ì„œ ì—¬í–‰ ê³„íš ë³µì›")
            state["travel_plan"] = global_travel_plan
            current_travel_plan = global_travel_plan

    # ì—¬ì „íˆ ì—¬í–‰ ì¼ì •ì´ ì—†ìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€
    if not current_travel_plan:
        response = """
ğŸ¤” <strong>í™•ì •í•˜ê³  ì‹¶ìœ¼ì‹  ì—¬í–‰ ì¼ì •ì´ ì—†ëŠ” ê²ƒ ê°™ì•„ìš”!</strong>

ğŸ“ <strong>í™•ì • ì ˆì°¨</strong>:
1. ë¨¼ì € ì—¬í–‰ ì¼ì •ì„ ìš”ì²­í•´ì£¼ì„¸ìš”
   ì˜ˆ: "ë¶€ì‚° 3ë°• 4ì¼ ì—¬í–‰ ì¶”ì²œí•´ì¤˜"
2. ìƒì„±ëœ ì¼ì •ì„ í™•ì¸í•˜ì‹  í›„
3. "í™•ì •", "ì¢‹ì•„", "ì´ê±¸ë¡œ í•´ì¤˜" ë“±ìœ¼ë¡œ í™•ì • ì˜ì‚¬ë¥¼ í‘œí˜„í•´ì£¼ì„¸ìš”

âœˆï¸ ê·¸ëŸ¬ë©´ ë°”ë¡œ ì§€ë„ì—ì„œ ì—¬í–‰ì§€ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”!

ğŸ’¡ ì§€ê¸ˆ ë°”ë¡œ ì–´ë–¤ ì—¬í–‰ ì¼ì •ì„ ì›í•˜ì‹œëŠ”ì§€ ë§ì”€í•´ì£¼ì„¸ìš”!
        """.strip()
        
        return {
            **state,
            "conversation_context": response,
            "tool_results": {
                "action": "request_travel_plan",
                "message": "ì—¬í–‰ ì¼ì • ë¨¼ì € ìš”ì²­ í•„ìš”"
            }
        }
    
    print(f"âœ… ì—¬í–‰ ì¼ì • í™•ì • ì²˜ë¦¬")
    
    travel_plan = state["travel_plan"]
    
    # ì¼ì • í™•ì • ì²˜ë¦¬
    from datetime import datetime
    confirmed_plan = {
        **travel_plan,
        "status": "confirmed",
        "confirmed_at": datetime.now().isoformat(),
        "plan_id": generate_plan_id()  # ê³ ìœ  ID ìƒì„±
    }
    
    # í™•ì • ì‘ë‹µ ìƒì„±
    itinerary_summary = ""
    if confirmed_plan.get("duration"):
        # durationì—ì„œ ì¼ìˆ˜ ì •ë³´ ì¶”ì¶œí•˜ì—¬ í‘œì‹œ
        duration_str = confirmed_plan["duration"]
        itinerary_summary = f"{duration_str} ì¼ì •"
    elif "itinerary" in confirmed_plan and confirmed_plan["itinerary"]:
        itinerary_summary = f"ì´ {len(confirmed_plan['itinerary'])}ì¼ ì¼ì •"
    
    places_summary = ""
    if "places" in confirmed_plan and confirmed_plan["places"]:
        place_names = [place["name"] for place in confirmed_plan["places"][:3] if place["name"]]
        if place_names:
            places_summary = f"ì£¼ìš” ë°©ë¬¸ì§€: {', '.join(place_names)}"
            if len(confirmed_plan["places"]) > 3:
                places_summary += f" ì™¸ {len(confirmed_plan['places']) - 3}ê³³"
    
    # ì§€ë„ í‘œì‹œë¥¼ ìœ„í•œ ì¥ì†Œ íŒŒë¼ë¯¸í„° êµ¬ì„± (ë©”íƒ€ë°ì´í„° í™œìš©)
    places_list = []
    day_numbers_list = []
    source_tables_list = []

    if "places" in confirmed_plan and confirmed_plan["places"]:
        total_days = len(confirmed_plan.get("itinerary", []))
        if total_days == 0:
            total_days = 1

        # ì¥ì†Œë¥¼ ì¼ì°¨ë³„ë¡œ ì •í™•í•˜ê²Œ ë°°ì¹˜ (ê°œì„ ëœ ë§¤ì¹­)
        places_to_process = confirmed_plan["places"]  # ëª¨ë“  ì¥ì†Œ í¬í•¨

        # ì¼ì°¨ë³„ ì¥ì†Œ ëª©ë¡ ì¶”ì¶œ (ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´)
        itinerary = confirmed_plan.get("itinerary", [])
        places_by_day = extract_places_by_day(itinerary)

        print(f"ğŸ—“ï¸ ì¼ì°¨ë³„ ì¥ì†Œ ë¶„ì„: {places_by_day}")

        for idx, place in enumerate(places_to_process):
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì§ì ‘ ì •ë³´ ì¶”ì¶œ (ë²¡í„° ì—…ë°ì´íŠ¸ í›„)
            table_name = place.get("table_name", "nature")
            place_id = place.get("place_id")

            # place_idê°€ ì—†ê±°ë‚˜ "1"ì´ë©´ ìŠ¤í‚µ (ë¬´ë“±ì‚° ì£¼ìƒì ˆë¦¬ëŒ€ ë°©ì§€)
            if not place_id or place_id == "1":
                print(f"âš ï¸ place_id ì—†ìŒ - ì¥ì†Œ '{place.get('name', 'Unknown')}' ìŠ¤í‚µ")
                continue

            # ì¥ì†Œ ID ìƒì„± (table_name_place_id í˜•íƒœ)
            place_identifier = f"{table_name}_{place_id}"

            places_list.append(place_identifier)
            source_tables_list.append(table_name)

            # ê°œì„ ëœ ì¼ì°¨ ë§¤ì¹­
            place_name = place.get("name", "")
            day_num = find_place_in_itinerary(place_name, itinerary)

            # ë§¤ì¹­ë˜ì§€ ì•Šì€ ê²½ìš° ì²˜ë¦¬
            if day_num == 0:
                print(f"âš ï¸ '{place_name}' ë§¤ì¹­ ì‹¤íŒ¨, ëŒ€ì•ˆ ë°©ë²• ì‹œë„")

                # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì ì ˆí•œ ì¼ì°¨ì— ë°°ì¹˜
                category = place.get("category", "")

                if "ì‹ë‹¹" in category or "ë§›ì§‘" in category or "ìŒì‹" in category:
                    # ì‹ì‚¬ ì¥ì†ŒëŠ” ê¸°ì¡´ ì‹ì‚¬ ì‹œê°„ëŒ€ê°€ ìˆëŠ” ì¼ì°¨ì— ë°°ì¹˜
                    for day_info in itinerary:
                        for schedule in day_info.get("schedule", []):
                            if any(keyword in schedule.get("description", "") for keyword in ["ì ì‹¬", "ì €ë…", "ì‹ì‚¬"]):
                                day_num = day_info.get("day", 1)
                                break
                        if day_num > 0:
                            break

                # ì—¬ì „íˆ ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ê°€ì¥ ì ì€ ì¥ì†Œê°€ ìˆëŠ” ì¼ì°¨ì— ë°°ì¹˜
                if day_num == 0:
                    if places_by_day:
                        min_places_day = min(places_by_day.keys(), key=lambda x: len(places_by_day[x]))
                        day_num = min_places_day
                    else:
                        # ìµœí›„ì˜ ìˆ˜ë‹¨: ìˆœì„œëŒ€ë¡œ ê· ë“± ë¶„ë°°
                        day_num = (idx % max(total_days, 1)) + 1

                print(f"ğŸ“ '{place_name}' -> {day_num}ì¼ì°¨ ë°°ì¹˜")

            day_numbers_list.append(str(day_num))

        print(f"ğŸ—ºï¸ ì§€ë„ í‘œì‹œìš© ì¥ì†Œ êµ¬ì„± ì™„ë£Œ:")
        print(f"   ì¥ì†Œ ëª©ë¡: {places_list[:5]}{'...' if len(places_list) > 5 else ''}")
        print(f"   ì¼ì°¨ ë°°ì •: {day_numbers_list[:5]}{'...' if len(day_numbers_list) > 5 else ''}")
        print(f"   í…Œì´ë¸” ëª©ë¡: {source_tables_list[:5]}{'...' if len(source_tables_list) > 5 else ''}")

    # ë‚ ì§œ ê³„ì‚° (parseddates ìš°ì„  ì‚¬ìš©)
    from datetime import datetime, timedelta
    
    # stateì—ì„œ parseddates ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    parsed_dates = state.get("parsed_dates", {})
    print(f"ğŸ” confirmation_processing_nodeì—ì„œ ë°›ì€ parsed_dates: {parsed_dates}")
    print(f"ğŸ” stateì˜ ëª¨ë“  í‚¤: {list(state.keys())}")

    # travel_planì—ì„œë„ í™•ì¸
    travel_plan_parsed_dates = state.get("travel_plan", {}).get("parsed_dates", {})
    print(f"ğŸ” travel_plan ë‚´ parsed_dates: {travel_plan_parsed_dates}")

    # ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì‚¬ìš©
    if not parsed_dates and travel_plan_parsed_dates:
        parsed_dates = travel_plan_parsed_dates
        print(f"ğŸ”„ travel_planì—ì„œ parsed_dates ê°€ì ¸ì˜´: {parsed_dates}")
    
    if parsed_dates and parsed_dates.get("startDate") and parsed_dates.get("endDate"):
        # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚ ì§œ ì‚¬ìš©
        start_date = parsed_dates["startDate"]
        end_date = parsed_dates["endDate"]
        days = parsed_dates.get("days", 2)
        print(f"âœ… ì‚¬ìš©ì ì§€ì • ë‚ ì§œ ì‚¬ìš©: {start_date} ~ {end_date}")
    else:
        # fallback: durationì—ì„œ ê³„ì‚°
        duration_str = confirmed_plan.get('duration', '2ë°• 3ì¼')
        days_match = re.search(r'(\d+)ì¼', duration_str)
        days = int(days_match.group(1)) if days_match else 2
        
        # ê¸°ì¡´ ë°©ì‹ (ì˜¤ëŠ˜ ê¸°ì¤€)
        start_date = datetime.now().strftime('%Y-%m-%d')
        end_date = (datetime.now() + timedelta(days=days-1)).strftime('%Y-%m-%d')
        print(f"âš ï¸ ê¸°ë³¸ ë‚ ì§œ ì‚¬ìš© (ì˜¤ëŠ˜ ê¸°ì¤€): {start_date} ~ {end_date}")

    # URL íŒŒë¼ë¯¸í„° ìƒì„±
    import urllib.parse
    places_param = ','.join(places_list)
    day_numbers_param = ','.join(day_numbers_list)
    source_tables_param = ','.join(source_tables_list)

    map_url = f"/map?places={urllib.parse.quote(places_param)}&dayNumbers={urllib.parse.quote(day_numbers_param)}&sourceTables={urllib.parse.quote(source_tables_param)}&startDate={start_date}&endDate={end_date}&days={days}&baseAttraction=general"

    print(f"ğŸ”— ìƒì„±ëœ ì§€ë„ URL: {map_url[:100]}{'...' if len(map_url) > 100 else ''}")
    
    # ì§€ë„ í‘œì‹œìš© ì¥ì†Œ ì •ë³´ (DBì—ì„œ ì •í™•í•œ ì •ë³´ ì¡°íšŒ)
    map_places = []
    if "places" in confirmed_plan and confirmed_plan["places"]:
        for place in confirmed_plan["places"]:
            place_id = place.get("place_id", place.get("id", ""))
            table_name = place.get("table_name", "")

            # DBì—ì„œ ì •í™•í•œ ì •ë³´ ì¡°íšŒ
            if place_id and table_name and place_id != "unknown":
                db_place = get_place_from_recommendations(place_id, table_name)
                if db_place:
                    place_info = {
                        "name": db_place.get("name", ""),
                        "category": db_place.get("category", ""),
                        "table_name": db_place.get("table_name", ""),
                        "place_id": db_place.get("place_id", ""),
                        "city": db_place.get("city", ""),
                        "region": db_place.get("region", "")
                    }
                    # ìœ„ì¹˜ ì •ë³´ ì¶”ê°€
                    if db_place.get("latitude") and db_place.get("longitude"):
                        place_info["lat"] = db_place["latitude"]
                        place_info["lng"] = db_place["longitude"]
                    map_places.append(place_info)
                    continue

            # DB ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ì •ë³´ ì‚¬ìš© (fallback)
            place_info = {
                "name": place.get("name", ""),
                "category": place.get("category", ""),
                "table_name": table_name,
                "place_id": place_id,
                "city": place.get("city", ""),
                "region": place.get("region", "")
            }
            # ìœ„ì¹˜ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if place.get("latitude") and place.get("longitude"):
                place_info["lat"] = place["latitude"]
                place_info["lng"] = place["longitude"]
            map_places.append(place_info)
    
    response = f"""
ğŸ‰ <strong>ì—¬í–‰ ì¼ì •ì´ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤!</strong>

ğŸ“‹ <strong>í™•ì •ëœ ì¼ì • ì •ë³´:</strong>
â€¢ <strong>ì§€ì—­</strong>: {confirmed_plan.get('region', 'N/A')}
â€¢ <strong>ê¸°ê°„</strong>: {confirmed_plan.get('duration', 'N/A')}
â€¢ <strong>ì¼ì •</strong>: {itinerary_summary}
â€¢ <strong>ì¥ì†Œ</strong>: {places_summary}

ğŸ—ºï¸ <strong>ì§€ë„ì—ì„œ ì—¬í–‰ì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”!</strong>
í™•ì •ëœ ì—¬í–‰ì§€ë“¤ì´ ì§€ë„ì— í‘œì‹œë©ë‹ˆë‹¤.

ğŸ”„ <strong>ì§€ë„ í˜ì´ì§€ë¡œ ì´ë™ ì¤‘...</strong>
    """
    
    return {
        **state,
        "travel_plan": confirmed_plan,
        "conversation_context": response,
        "tool_results": {
            "action": "redirect_to_map",
            "data": confirmed_plan,
            "redirect_url": map_url,
            "places": map_places
        }
    }

# generate_plan_id moved to utils/travel_planner.py

def create_formatted_ui_response(travel_plan: dict, raw_response: str) -> dict:
    """í”„ë¡ íŠ¸ì—”ë“œ UIìš© êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„±"""
    
    # ì‘ë‹µì—ì„œ ì—¬í–‰ íŒ ì¶”ì¶œ
    travel_tips = ""
    if "ğŸ’¡" in raw_response:
        tips_section = raw_response.split("ğŸ’¡")[1] if "ğŸ’¡" in raw_response else ""
        if tips_section:
            travel_tips = tips_section.split("ì´ ì¼ì •ìœ¼ë¡œ í™•ì •í•˜ì‹œê² ì–´ìš”?")[0].strip()
    
    formatted_response = {
        "type": "travel_plan",
        "title": f"{travel_plan.get('region', 'ì—¬í–‰ì§€')} {travel_plan.get('duration', '')} ì—¬í–‰ ì¼ì •",
        "region": travel_plan.get('region', ''),
        "duration": travel_plan.get('duration', ''),
        "total_days": len(travel_plan.get('itinerary', [])),
        "total_places": len(travel_plan.get('places', [])),
        "itinerary": [],
        "travel_tips": travel_tips,
        "has_confirmation": True,
        "confirmation_message": "ì´ ì¼ì •ìœ¼ë¡œ í™•ì •í•˜ì‹œê² ì–´ìš”?",
        "plan_id": travel_plan.get('plan_id')
    }
    
    # ì¼ì°¨ë³„ ì¼ì • êµ¬ì¡°í™”
    for day_info in travel_plan.get('itinerary', []):
        day_data = {
            "day": day_info.get('day', 1),
            "title": f"{day_info.get('day', 1)}ì¼ì°¨",
            "activities": []
        }
        
        for schedule_item in day_info.get('schedule', []):
            activity = {
                "time": schedule_item.get('time', ''),
                "place_name": schedule_item.get('place_name', ''),
                "description": schedule_item.get('description', ''),
                "category": schedule_item.get('category', ''),
                "is_meal": is_meal_activity(schedule_item.get('description', '')),
                "place_info": schedule_item.get('place_info')
            }
            day_data["activities"].append(activity)
        
        formatted_response["itinerary"].append(day_data)
    
    # ì£¼ìš” ì¥ì†Œ ì •ë³´
    formatted_response["places"] = [
        {
            "name": place.get('name', ''),
            "category": place.get('category', ''),
            "description": place.get('description', ''),
            "similarity_score": place.get('similarity_score', 0)
        }
        for place in travel_plan.get('places', [])[:5]  # ìƒìœ„ 5ê°œ
    ]
    
    return formatted_response

def is_meal_activity(description: str) -> bool:
    """ì‹ì‚¬ ê´€ë ¨ í™œë™ì¸ì§€ íŒë‹¨"""
    meal_keywords = ['ì ì‹¬', 'ì €ë…', 'ì•„ì¹¨', 'ì‹ì‚¬', 'ë§›ì§‘', 'ì¹´í˜', 'ì‹ë‹¹', 'ë ˆìŠ¤í† ë‘']
    return any(keyword in description for keyword in meal_keywords)

def format_travel_response_with_linebreaks(response: str) -> str:
    """ì—¬í–‰ ì‘ë‹µì— ì ì ˆí•œ ê°œí–‰ ë¬¸ìë¥¼ ì¶”ê°€í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ"""
    
    # ê¸°ë³¸ì ì¸ ê°œí–‰ ì²˜ë¦¬
    formatted = response
    
    # ì¼ì°¨ë³„ ì œëª© ì•ì— ê°œí–‰ ì¶”ê°€
    formatted = formatted.replace("<strong>[", "\n\n<strong>[")
    
    # ê° ì¼ì • í•­ëª© ì•ì— ê°œí–‰ ì¶”ê°€ (â€¢ ê¸°í˜¸ ê¸°ì¤€)
    formatted = formatted.replace("â€¢ ", "\nâ€¢ ")
    
    # ì—¬í–‰ íŒ ì„¹ì…˜ ì•ì— ê°œí–‰ ì¶”ê°€
    formatted = formatted.replace("ğŸ’¡ <strong>ì—¬í–‰ íŒ</strong>", "\n\nğŸ’¡ <strong>ì—¬í–‰ íŒ</strong>")
    
    # í™•ì • ì•ˆë‚´ ì•ì— ê°œí–‰ ì¶”ê°€
    formatted = formatted.replace("ì´ ì¼ì •ìœ¼ë¡œ í™•ì •", "\n\nì´ ì¼ì •ìœ¼ë¡œ í™•ì •")
    
    # ì œëª© ì• ë¶ˆí•„ìš”í•œ ê°œí–‰ ì œê±°
    if formatted.startswith("\n\n"):
        formatted = formatted[2:]
    
    # ì—°ì†ëœ ê°œí–‰ ì •ë¦¬ (3ê°œ ì´ìƒ -> 2ê°œ)
    formatted = re.sub(r'\n{3,}', '\n\n', formatted)
    
    return formatted.strip()

def integrate_response_node(state: TravelState) -> TravelState:
    """ì—¬ëŸ¬ ë…¸ë“œì˜ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ìµœì¢… ì‘ë‹µ ìƒì„±"""
    print(f"ğŸ”„ ì‘ë‹µ í†µí•© ì¤‘...")
    
    response_parts = []
    
    # í™•ì • ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²½ìš° í™•ì • ë…¸ë“œë¡œ ì²˜ë¦¬
    if state.get("need_confirmation") and state.get("travel_plan"):
        print("ğŸ¯ í™•ì • ì²˜ë¦¬ í•„ìš” - confirmation_processing_nodeë¡œ ì´ë™")
        return confirmation_processing_node(state)
    
    # RAG ê²°ê³¼ ìš°ì„ 
    if state.get("conversation_context"):
        response_parts.append(state["conversation_context"])
    
    # Search ê²°ê³¼ ì¶”ê°€
    if state.get("search_results"):
        search_summary = f"ê²€ìƒ‰ëœ ì¥ì†Œ: {len(state['search_results'])}ê³³"
        response_parts.append(search_summary)
    
    # Tool ê²°ê³¼ ì¶”ê°€
    if state.get("tool_results") and state["tool_results"].get("message"):
        response_parts.append(f"ğŸ”§ {state['tool_results']['message']}")
    
    # ì‘ë‹µì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µ
    if not response_parts:
        response_parts.append("ì•ˆë…•í•˜ì„¸ìš”! ì—¬í–‰ ê´€ë ¨ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”. ğŸ˜Š")
    
    integrated_response = "\n\n".join(response_parts)
    
    return {
        **state,
        "conversation_context": integrated_response
    }

def get_place_from_recommendations(place_id: str, table_name: str) -> dict:
    """place_recommendations í…Œì´ë¸”ì—ì„œ place_idì™€ table_nameìœ¼ë¡œ ì •í™•í•œ ì •ë³´ ì¡°íšŒ"""
    try:
        from sqlalchemy import text

        # DB ì—°ê²°
        engine = shared_engine

        with engine.connect() as conn:
            # place_idì™€ table_nameìœ¼ë¡œ ì •í™•í•œ ì¡°íšŒ
            search_query = """
            SELECT place_id, table_name, name, region, city, category,
                   latitude, longitude, overview
            FROM place_recommendations
            WHERE place_id = :place_id AND table_name = :table_name
            LIMIT 1
            """

            result = conn.execute(text(search_query), {
                "place_id": place_id,
                "table_name": table_name
            })
            row = result.fetchone()

            if row:
                return {
                    "place_id": str(row.place_id),
                    "table_name": row.table_name,
                    "name": row.name,
                    "region": row.region,
                    "city": row.city,
                    "category": row.category,
                    "latitude": row.latitude if hasattr(row, 'latitude') else None,
                    "longitude": row.longitude if hasattr(row, 'longitude') else None,
                    "overview": row.overview if hasattr(row, 'overview') else "",
                    "description": f"ì¥ì†Œ: {row.name}"
                }
            else:
                print(f"âŒ place_recommendationsì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ: place_id={place_id}, table_name={table_name}")
                return None

    except Exception as e:
        print(f"place_recommendations ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return None

def find_place_in_recommendations(place_name: str) -> dict:
    """place_recommendations í…Œì´ë¸”ì—ì„œ ì¥ì†Œëª…ìœ¼ë¡œ ì‹¤ì œ ë°ì´í„° ê²€ìƒ‰ (ë²¡í„° ì—…ë°ì´íŠ¸ í›„ ë¶ˆí•„ìš”)"""
    # ë²¡í„° ì—…ë°ì´íŠ¸ í›„ì—ëŠ” ë©”íƒ€ë°ì´í„°ì— place_id, table_nameì´ í¬í•¨ë˜ë¯€ë¡œ
    # ì´ í•¨ìˆ˜ëŠ” í˜¸í™˜ì„±ì„ ìœ„í•´ì„œë§Œ ìœ ì§€
    try:
        from sqlalchemy import text

        # DB ì—°ê²°
        engine = shared_engine

        with engine.connect() as conn:
            # ìœ ì‚¬í•œ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´) - psycopg3 ìŠ¤íƒ€ì¼
            search_query = """
            SELECT place_id, table_name, name, region, city, category
            FROM place_recommendations
            WHERE name ILIKE :search_term
            LIMIT 1
            """

            result = conn.execute(text(search_query), {'search_term': f"%{place_name}%"})
            row = result.fetchone()

            if row:
                return {
                    'name': row.name,
                    'place_id': str(row.place_id) if row.place_id else "1",
                    'table_name': row.table_name or 'nature',
                    'region': row.region or 'ê°•ì›íŠ¹ë³„ìì¹˜ë„',
                    'city': row.city or 'ë¯¸ì§€ì •',
                    'category': row.category or 'ê´€ê´‘',
                    'description': f'ì¥ì†Œ: {row.name}',
                    'similarity_score': 0.9  # High score for DB match
                }

        return None

    except Exception as e:
        print(f"place_recommendations ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return None

def find_real_place_id(place_name: str, table_name: str, region: str = "") -> str:
    """ì¥ì†Œëª…ìœ¼ë¡œ ì‹¤ì œ DBì—ì„œ place_id ì¡°íšŒ (ê³µí†µ ì—”ì§„ ì‚¬ìš©)"""
    try:
        from sqlalchemy.orm import sessionmaker
        from models_attractions import Nature, Restaurant, Shopping, Humanities, LeisureSports

        # í…Œì´ë¸” ë§¤í•‘ (ìˆ™ì†Œ ì œì™¸)
        table_models = {
            "nature": Nature,
            "restaurants": Restaurant,
            "shopping": Shopping,
            "humanities": Humanities,
            "leisure_sports": LeisureSports
        }

        if table_name not in table_models:
            print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” table_name: {table_name}")
            return None  # ê¸°ë³¸ê°’ "1" ëŒ€ì‹  None ë°˜í™˜

        # ê³µí†µ ì—”ì§„ ì‚¬ìš© (ì¤‘ë³µ ìƒì„± ë°©ì§€)
        Session = sessionmaker(bind=shared_engine)
        session = Session()

        try:
            table_model = table_models[table_name]

            # ì¥ì†Œëª…ìœ¼ë¡œ ê²€ìƒ‰ (ì •í™•í•œ ë§¤ì¹­ ìš°ì„ )
            query = session.query(table_model).filter(table_model.name.ilike(f"%{place_name}%"))

            # ì§€ì—­ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€ í•„í„°ë§
            if region:
                query = query.filter(table_model.region.ilike(f"%{region}%"))

            place = query.first()

            if place:
                return str(place.id)
            else:
                # ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜ (ë¬´ë“±ì‚° ì£¼ìƒì ˆë¦¬ëŒ€ fallback ë°©ì§€)
                print(f"âŒ ì¥ì†Œëª… '{place_name}'ì´ {table_name} í…Œì´ë¸”ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None

        finally:
            session.close()
            
    except Exception as e:
        print(f"place_id ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ "1" ëŒ€ì‹  None ë°˜í™˜

def extract_structured_places(docs: List[Document]) -> List[dict]:
    """RAG ê²€ìƒ‰ ê²°ê³¼ì—ì„œ êµ¬ì¡°í™”ëœ ì¥ì†Œ ì •ë³´ ì¶”ì¶œ (ì—…ë°ì´íŠ¸ëœ ë©”íƒ€ë°ì´í„° í™œìš©)"""
    structured_places = []

    for doc in docs[:25]:  # ìƒìœ„ 25ê°œ ì²˜ë¦¬
        try:
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì§ì ‘ ì •ë³´ ì¶”ì¶œ (ë²¡í„° ì—…ë°ì´íŠ¸ í›„)
            metadata = doc.metadata or {}

            # ë©”íƒ€ë°ì´í„°ì—ì„œ place_idì™€ table_name ì¶”ì¶œ
            place_id = metadata.get("place_id")
            table_name = metadata.get("table_name")

            # place_idì™€ table_nameì´ ìˆìœ¼ë©´ DBì—ì„œ ì •í™•í•œ ì •ë³´ ì¡°íšŒ
            if place_id and table_name and place_id != "1":
                db_place = get_place_from_recommendations(place_id, table_name)
                if db_place:
                    place_info = {
                        **db_place,  # DBì—ì„œ ê°€ì ¸ì˜¨ ì •í™•í•œ ì •ë³´ ì‚¬ìš©
                        "description": doc.page_content[:200],  # ì²« 200ì
                        "similarity_score": metadata.get('similarity_score', 0)
                    }
                else:
                    # DB ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ë©”íƒ€ë°ì´í„° ì‚¬ìš© (fallback)
                    place_info = {
                        "name": metadata.get("name", "ì¥ì†Œëª… ë¯¸ìƒ"),
                        "category": metadata.get("category", ""),
                        "region": metadata.get("region", ""),
                        "city": metadata.get("city", ""),
                        "table_name": table_name,
                        "place_id": place_id,
                        "description": doc.page_content[:200],
                        "similarity_score": metadata.get('similarity_score', 0)
                    }
            else:
                # ë©”íƒ€ë°ì´í„°ê°€ ë¶ˆì™„ì „í•œ ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                place_info = {
                    "name": metadata.get("name", ""),
                    "category": metadata.get("category", ""),
                    "region": metadata.get("region", ""),
                    "city": metadata.get("city", ""),
                    "table_name": metadata.get("table_name", "nature"),
                    "place_id": place_id or "unknown",  # "1" ëŒ€ì‹  "unknown" ì‚¬ìš©
                    "description": doc.page_content[:200],
                    "similarity_score": metadata.get('similarity_score', 0)
                }

            # ë©”íƒ€ë°ì´í„°ì— nameì´ ì—†ìœ¼ë©´ ë¬¸ì„œ ë‚´ìš©ì—ì„œ ì¶”ì¶œ (í˜¸í™˜ì„± ë³´ì¥)
            if not place_info["name"]:
                content = doc.page_content
                first_line = content.split('\n')[0] if content else ""
                if first_line and len(first_line) < 50:
                    # "ì´ë¦„: " ì ‘ë‘ì–´ ì œê±°
                    name = first_line.strip()
                    if name.startswith("ì´ë¦„: "):
                        name = name[3:].strip()
                    place_info["name"] = name
                else:
                    # íŒ¨í„´ìœ¼ë¡œ ì¥ì†Œëª… ì¶”ì¶œ
                    import re
                    name_patterns = [
                        r'([ê°€-í£]{2,20}(?:ê³µì›|ë°•ë¬¼ê´€|ë§›ì§‘|ì¹´í˜|ì‹œì¥|ê¶|ì ˆ|íƒ€ì›Œ|ì„¼í„°|ëª°|í•´ìˆ˜ìš•ì¥|ì‚°|ì„¬))',
                        r'([ê°€-í£]{2,20}(?:ì‹ë‹¹|ë ˆìŠ¤í† ë‘))',
                    ]

                    for pattern in name_patterns:
                        match = re.search(pattern, content)
                        if match:
                            place_info["name"] = match.group(1)
                            break

                    if not place_info["name"]:
                        words = content.split()[:3]
                        place_info["name"] = " ".join(words) if words else "ì¥ì†Œëª… ë¯¸ìƒ"

            # table_nameì´ ì—†ìœ¼ë©´ ì¹´í…Œê³ ë¦¬ë¡œ ë§¤í•‘ (í˜¸í™˜ì„± ë³´ì¥)
            if not place_info["table_name"] or place_info["table_name"] == "nature":
                category_to_table = {
                    "í•œì‹": "restaurants", "ì¤‘ì‹": "restaurants", "ì–‘ì‹": "restaurants",
                    "ì¼ì‹": "restaurants", "ì¹´í˜": "restaurants", "ì‹ë‹¹": "restaurants",
                    "ë§›ì§‘": "restaurants", "ìì—°": "nature", "ê´€ê´‘": "nature",
                    "ë¬¸í™”": "humanities", "ì‡¼í•‘": "shopping",
                    "ë ˆí¬ì¸ ": "leisure_sports", "ìŠ¤í¬ì¸ ": "leisure_sports",
                    # ìˆ™ì†Œ ê´€ë ¨ ì¹´í…Œê³ ë¦¬ ì œì™¸
                }
                place_info["table_name"] = category_to_table.get(place_info["category"], "nature")

            # ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
            place_info["latitude"] = metadata.get("latitude")
            place_info["longitude"] = metadata.get("longitude")

            structured_places.append(place_info)

        except Exception as e:
            print(f"ì¥ì†Œ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            continue

    return structured_places

def extract_places_from_response(response: str, structured_places: List[dict]) -> List[dict]:
    """LLM ì‘ë‹µì—ì„œ ì‹¤ì œ ì–¸ê¸‰ëœ ì¥ì†Œë“¤ë§Œ ì¶”ì¶œí•˜ì—¬ ë§¤ì¹­"""
    
    # ì‘ë‹µì—ì„œ <strong>ì¥ì†Œëª…</strong> íŒ¨í„´ìœ¼ë¡œ ì¥ì†Œ ì¶”ì¶œ
    place_pattern = r'<strong>([^<]+)</strong>'
    mentioned_places = re.findall(place_pattern, response)
    
    # ë§¤ì¹­ëœ ì¥ì†Œë“¤ ì €ì¥
    matched_places = []
    
    # ì¼ì • ê´€ë ¨ í‚¤ì›Œë“œ í•„í„°ë§ (ë” ì •ë°€í•˜ê²Œ)
    ignore_keywords = ['ì¼ì°¨', 'ì—¬í–‰', 'ì¼ì •', 'íŒ', 'ì •ë³´', 'í™•ì •', '[', ']']
    # ì§€ì—­ëª…ë§Œ í¬í•¨í•˜ëŠ” ê²½ìš°ëŠ” ì œì™¸ (ì˜ˆ: "ë¶€ì‚°", "ì„œìš¸")
    region_only_keywords = ['ë¶€ì‚°', 'ì„œìš¸', 'ì œì£¼', 'ê°•ë¦‰', 'ëŒ€êµ¬', 'ê´‘ì£¼', 'ì „ì£¼', 'ê²½ì£¼']
    
    for mentioned_place in mentioned_places:
        mentioned_place = mentioned_place.strip()
    
        # ì¼ì • ê´€ë ¨ í‚¤ì›Œë“œ ì œì™¸
        if any(keyword in mentioned_place for keyword in ignore_keywords):
            continue
            
        # ì§€ì—­ëª…ë§Œ ë‹¨ë…ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê²½ìš° ì œì™¸ (ì˜ˆ: "ë¶€ì‚°", "ì„œìš¸")
        if mentioned_place.strip() in region_only_keywords:
            continue
        
        # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ì¥ì†Œëª… ì œì™¸
        if len(mentioned_place) < 2 or len(mentioned_place) > 30:
            continue
            
        # structured_placesì—ì„œ ë§¤ì¹­ë˜ëŠ” ì¥ì†Œ ì°¾ê¸° (ë‹¨ìˆœí™”)
        best_match = None

        for place in structured_places:
            place_name = place.get("name", "").strip()

            # ì •í™•íˆ ì¼ì¹˜í•˜ê±°ë‚˜ ë¶€ë¶„ ë§¤ì¹­ë˜ëŠ” ê²½ìš°
            if (mentioned_place == place_name or
                mentioned_place in place_name or
                place_name in mentioned_place):
                best_match = place
                break

        # ë§¤ì¹­ë˜ëŠ” ì¥ì†Œê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if best_match and best_match not in matched_places:
            matched_places.append(best_match)
        elif not best_match and len(mentioned_place) >= 3:
            # ì‹¤ì œ place_recommendations í…Œì´ë¸”ì—ì„œ í•´ë‹¹ ì¥ì†Œ ê²€ìƒ‰
            actual_place = find_place_in_recommendations(mentioned_place)
            if actual_place:
                matched_places.append(actual_place)
            else:
                # ê°€ìƒ ì¥ì†Œ ìƒì„±í•˜ì§€ ì•ŠìŒ - ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì¥ì†Œë§Œ ì‚¬ìš©
                print(f"âš ï¸ ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {mentioned_place}")
    
    return matched_places

def parse_enhanced_travel_plan(response: str, user_query: str, structured_places: List[dict], travel_dates: str = "ë¯¸ì •") -> dict:
    """í–¥ìƒëœ ì—¬í–‰ ì¼ì • íŒŒì‹± (ì‹¤ì œ ì¥ì†Œ ë°ì´í„° í¬í•¨)"""

    # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
    regions, cities, categories = extract_location_and_category(user_query)
    duration = extract_duration(user_query)

    # ì¼ì°¨ë³„ êµ¬ì¡° íŒŒì‹± (ë” ìœ ì—°í•œ íŒ¨í„´)
    day_patterns = [
        r'<strong>\[(\d+)ì¼ì°¨\]</strong>',  # <strong>[1ì¼ì°¨]</strong>
        r'\[(\d+)ì¼ì°¨\]',                    # [1ì¼ì°¨]
        r'(\d+)ì¼ì°¨',                        # 1ì¼ì°¨
        r'<strong>(\d+)ì¼ì°¨</strong>'         # <strong>1ì¼ì°¨</strong>
    ]

    # ê°€ì¥ ë§ì´ ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ ì‚¬ìš©
    best_pattern = None
    best_matches = []

    for pattern in day_patterns:
        matches = re.findall(pattern, response)
        if len(matches) > len(best_matches):
            best_matches = matches
            best_pattern = pattern

    itinerary = []

    if best_pattern and best_matches:
        print(f"ğŸ—“ï¸ ì¼ì°¨ íŒ¨í„´ ì¸ì‹: {len(best_matches)}ê°œ ì¼ì°¨ ë°œê²¬")

        # ì‘ë‹µì„ ì¼ì°¨ë³„ë¡œ ë¶„í• 
        day_sections = re.split(best_pattern, response)

        for i in range(1, len(day_sections), 2):  # í™€ìˆ˜ ì¸ë±ìŠ¤ê°€ ì¼ì°¨ ë²ˆí˜¸, ì§ìˆ˜ê°€ ë‚´ìš©
            if i + 1 < len(day_sections):
                day_num_str = day_sections[i]
                day_content = day_sections[i + 1]

                try:
                    day_num = int(day_num_str)
                except ValueError:
                    continue

                # í•´ë‹¹ ì¼ì°¨ì˜ ì¼ì • íŒŒì‹±
                day_schedule = parse_day_schedule(day_content, structured_places)

                if day_schedule:  # ì¼ì •ì´ ìˆì„ ë•Œë§Œ ì¶”ê°€
                    itinerary.append({
                        "day": day_num,
                        "schedule": day_schedule
                    })
    else:
        print(f"âš ï¸ ì¼ì°¨ íŒ¨í„´ ì¸ì‹ ì‹¤íŒ¨, ë‹¨ì¼ ì¼ì •ìœ¼ë¡œ ì²˜ë¦¬")
        # ì¼ì°¨ êµ¬ë¶„ ì—†ì´ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì¼ì •ìœ¼ë¡œ ì²˜ë¦¬
        single_day_schedule = parse_day_schedule(response, structured_places)
        if single_day_schedule:
            itinerary.append({
                "day": 1,
                "schedule": single_day_schedule
            })

    # ì‹¤ì œ ì‘ë‹µì— í¬í•¨ëœ ì¥ì†Œë“¤ë§Œ ì¶”ì¶œ (LLM íŒë‹¨ ì‹ ë¢°)
    response_places = extract_places_from_response(response, structured_places)

    # íŒŒì‹±ëœ ë‚ ì§œ ì •ë³´ ìƒì„±
    print(f"ğŸ”§ enhanced_plan ìƒì„± ì¤‘ - travel_dates: '{travel_dates}', duration: '{duration}'")
    plan_parsed_dates = parse_travel_dates(travel_dates, duration)
    print(f"ğŸ”§ enhanced_plan ë‚´ë¶€ì—ì„œ ìƒì„±ëœ parsed_dates: {plan_parsed_dates}")

    # ìƒì„¸ ì—¬í–‰ ê³„íš êµ¬ì¡°
    enhanced_plan = {
        "region": regions[0] if regions else "ë¯¸ì§€ì •",
        "cities": cities,
        "duration": duration,
        "travel_dates": travel_dates,  # ì¶”ì¶œëœ ì—¬í–‰ ë‚ ì§œ ì¶”ê°€
        "parsed_dates": plan_parsed_dates,  # íŒŒì‹±ëœ ë‚ ì§œ ì •ë³´ ì¶”ê°€
        "categories": list(set(categories + [place["category"] for place in response_places if place.get("category")])),
        "itinerary": itinerary,
        "places": response_places,  # ì‹¤ì œ ì‘ë‹µì— í¬í•¨ëœ ì¥ì†Œë“¤ë§Œ
        "raw_response": response,
        "status": "draft",
        "created_at": "2025-09-13T00:00:00Z",  # ì‹¤ì œë¡œëŠ” datetime.now()
        "total_places": len(structured_places),
    }

    print(f"ğŸ”§ ìµœì¢… enhanced_planì˜ parsed_dates: {enhanced_plan.get('parsed_dates')}")

    print(f"âœ¨ ì¼ì • íŒŒì‹± ì™„ë£Œ: {len(itinerary)}ì¼ì°¨, ì´ {sum(len(day.get('schedule', [])) for day in itinerary)}ê°œ ì¼ì •")

    return enhanced_plan

def parse_day_schedule(day_content: str, structured_places: List[dict]) -> List[dict]:
    """í•˜ë£¨ ì¼ì • íŒŒì‹± (ê°œì„ ëœ íŒ¨í„´ ì¸ì‹)"""

    schedule = []

    # ë” ìœ ì—°í•œ íŒ¨í„´ë“¤ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
    patterns = [
        # â€¢ 09:00-12:00 <strong>ì¥ì†Œëª…</strong> - ì„¤ëª…
        r'â€¢\s*(\d{1,2}:\d{2}(?:-\d{1,2}:\d{2})?)\s*<strong>([^<\n]+)</strong>\s*-\s*([^\n]+)',
        # â€¢ 09:00 <strong>ì¥ì†Œëª…</strong> - ì„¤ëª… (ë‹¨ì¼ ì‹œê°„)
        r'â€¢\s*(\d{1,2}:\d{2})\s*<strong>([^<\n]+)</strong>\s*-\s*([^\n]+)',
        # â€¢ <strong>ì¥ì†Œëª…</strong> (09:00-12:00) - ì„¤ëª…
        r'â€¢\s*<strong>([^<\n]+)</strong>\s*\((\d{1,2}:\d{2}(?:-\d{1,2}:\d{2})?)\)\s*-\s*([^\n]+)',
        # ì‹œê°„ ì—†ì´: â€¢ <strong>ì¥ì†Œëª…</strong> - ì„¤ëª…
        r'â€¢\s*<strong>([^<\n]+)</strong>\s*-\s*([^\n]+)'
    ]

    for pattern in patterns:
        matches = re.findall(pattern, day_content)

        for match in matches:
            if len(match) == 3:
                if pattern == patterns[2]:  # 3ë²ˆì§¸ íŒ¨í„´ (ì¥ì†Œëª…ì´ ì²« ë²ˆì§¸)
                    place_name, time_range, description = match
                else:
                    time_range, place_name, description = match
            elif len(match) == 2:  # ì‹œê°„ ì—†ëŠ” ê²½ìš°
                place_name, description = match
                time_range = ""
            else:
                continue

            # ì¥ì†Œëª… ì •ë¦¬
            place_name_clean = normalize_place_name(place_name)

            # êµ¬ì¡°í™”ëœ ì¥ì†Œì—ì„œ ë§¤ì¹­ë˜ëŠ” ì •ë³´ ì°¾ê¸° (ë‹¨ìˆœí™”)
            matched_place = None

            for place in structured_places:
                place_name_normalized = normalize_place_name(place.get("name", ""))

                # ì •í™•í•œ ë§¤ì¹­ ë˜ëŠ” ë¶€ë¶„ ë§¤ì¹­
                if (place_name_clean == place_name_normalized or
                    (place_name_clean and place_name_normalized and
                     (place_name_clean in place_name_normalized or
                      place_name_normalized in place_name_clean))):
                    matched_place = place
                    break

            schedule_item = {
                "time": time_range.strip() if time_range else "",
                "place_name": place_name.strip(),
                "description": description.strip(),
                "category": matched_place.get("category", "") if matched_place else "",
                "place_info": matched_place
            }
            schedule.append(schedule_item)

    # ì¤‘ë³µ ì œê±° (ê°™ì€ ì¥ì†Œëª…ê³¼ ì‹œê°„)
    seen = set()
    unique_schedule = []
    for item in schedule:
        key = (item["place_name"], item["time"])
        if key not in seen:
            seen.add(key)
            unique_schedule.append(item)

    return unique_schedule

# calculate_plan_confidence function removed - scoring logic not needed

def parse_travel_plan(response: str, user_query: str) -> dict:
    """ì‘ë‹µì—ì„œ ì—¬í–‰ ì¼ì • êµ¬ì¡° ì¶”ì¶œ"""
    
    # ì§€ì—­ ì¶”ì¶œ
    regions, cities, categories = extract_location_and_category(user_query)
    
    # ì‹œê°„ íŒ¨í„´ ì°¾ê¸° (09:00, 12:00 ë“±)
    time_pattern = r'\d{2}:\d{2}'
    times = re.findall(time_pattern, response)
    
    # ì¥ì†Œëª… ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)
    location_pattern = r'[ê°€-í£]{2,10}(?:ê³µì›|ë°•ë¬¼ê´€|ë§›ì§‘|ì¹´í˜|ì‹œì¥|ê¶|ì ˆ|íƒ€ì›Œ|ì„¼í„°|ëª°)'
    locations = re.findall(location_pattern, response)
    
    return {
        "region": regions[0] if regions else "ë¯¸ì§€ì •",
        "cities": cities,
        "duration": extract_duration(user_query),
        "locations": list(set(locations)),  # ì¤‘ë³µ ì œê±°
        "times": times,
        "categories": categories,
        "raw_response": response,
        "status": "draft"
    }

def extract_duration(query: str) -> str:
    """ì¿¼ë¦¬ì—ì„œ ì—¬í–‰ ê¸°ê°„ ì¶”ì¶œ"""
    duration_patterns = [
        r'(\d+)ë°•\s*(\d+)ì¼',
        r'(\d+)ì¼',
        r'ë‹¹ì¼',
        r'í•˜ë£¨'
    ]
    
    for pattern in duration_patterns:
        match = re.search(pattern, query)
        if match:
            return match.group(0)
    
    return "ë¯¸ì§€ì •"

def route_execution(state: TravelState) -> str:
    """ë‹¨ì¼ ë…¸ë“œ ì‹¤í–‰ì„ ìœ„í•œ ë¼ìš°íŒ… ê²°ì • (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)"""

    # í™•ì • ìš”ì²­ì´ ìµœê³  ìš°ì„ ìˆœìœ„
    if state.get("need_confirmation"):
        return "confirmation_processing"

    # ì˜ë„ë³„ ë¼ìš°íŒ…
    if state.get("need_rag"):
        # ì˜ë„ ë¶„ë¥˜ ê²°ê³¼ í™•ì¸
        user_query = state.get("messages", [""])[-1] if state.get("messages") else ""
        try:
            entities = detect_query_entities_wrapper(user_query)
            intent = entities.get("intent", "general")

            if intent == "place_search":
                return "information_search"
            else:
                return "rag_processing"  # travel_planning ë“±
        except:
            return "rag_processing"  # í´ë°±

    # ì¥ì†Œ ê²€ìƒ‰
    if state.get("need_search"):
        return "search_processing"

    # ê¸°ë³¸: ì¼ë°˜ ì±„íŒ…
    return "general_chat"

def check_completion(state: TravelState) -> Literal["continue", "end"]:
    """ëŒ€í™” ì™„ë£Œ ì—¬ë¶€ í™•ì¸"""
    # í™•ì •ëœ ì¼ì •ì´ ìˆê³  ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¢…ë£Œ
    if (state.get("travel_plan", {}).get("status") == "confirmed" and 
        state.get("tool_results", {}).get("action") == "redirect_to_planning_page"):
        return "end"
    
    # ê¸°ë³¸ì ìœ¼ë¡œ ëŒ€í™” ì§€ì†
    return "continue"

# LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
def create_travel_workflow():
    """ì—¬í–‰ ì¶”ì²œ LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    if not LANGGRAPH_AVAILABLE:
        return None
    
    workflow = StateGraph(TravelState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("classify", classify_query)
    workflow.add_node("rag_processing", rag_processing_node)
    workflow.add_node("information_search", information_search_node)
    workflow.add_node("search_processing", search_processing_node)
    workflow.add_node("general_chat", general_chat_node)
    workflow.add_node("confirmation_processing", confirmation_processing_node)
    workflow.add_node("integrate_response", integrate_response_node)
    
    # ì—£ì§€ êµ¬ì„±
    workflow.add_edge(START, "classify")
    workflow.add_conditional_edges("classify", route_execution)
    
    # ëª¨ë“  ì²˜ë¦¬ ë…¸ë“œë“¤ì´ í†µí•© ë…¸ë“œë¡œ ìˆ˜ë ´
    workflow.add_edge("rag_processing", "integrate_response")
    workflow.add_edge("information_search", "integrate_response")
    workflow.add_edge("search_processing", "integrate_response")
    workflow.add_edge("general_chat", "integrate_response")
    workflow.add_edge("confirmation_processing", "integrate_response")
    
    # ì™„ë£Œ í™•ì¸
    workflow.add_conditional_edges(
        "integrate_response",
        check_completion,
        {
            "continue": END,  # ì¶”ê°€ ëŒ€í™” ì—†ì´ ì¢…ë£Œë¡œ ë³€ê²½
            "end": END
        }
    )
    
    return workflow.compile()

# ì „ì—­ ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤
travel_workflow = create_travel_workflow() if LANGGRAPH_AVAILABLE else None

# ê°œì„ ëœ ìƒíƒœ ê´€ë¦¬: ì„¸ì…˜ ëŒ€ì‹  ì¸ë©”ëª¨ë¦¬ ìƒíƒœ (ìƒˆ ì¶”ì²œì‹œ ë®ì–´ì“°ê¸°)
current_travel_state = {
    "last_query": "",
    "travel_plan": {},
    "places": [],
    "context": "",
    "timestamp": None
}

def get_current_travel_state_ref():
    """í˜„ì¬ ì—¬í–‰ ìƒíƒœ ë°˜í™˜ (ì°¸ì¡° ë™ê¸°í™”ë¥¼ ìœ„í•œ í•¨ìˆ˜)"""
    global current_travel_state
    return current_travel_state


async def get_travel_recommendation_langgraph(query: str, conversation_history: List[str] = None, session_id: str = "default") -> dict:
    """LangGraph ê¸°ë°˜ ì—¬í–‰ ì¶”ì²œ (ê°œì„ ëœ ìƒíƒœ ê´€ë¦¬ - ìƒˆ ì¶”ì²œì‹œ ë®ì–´ì“°ê¸°)"""

    if not travel_workflow:
        # LangGraph ë¯¸ì‚¬ìš© ì‹œ ì—ëŸ¬ ë°˜í™˜
        return {
            "response": "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì—¬í–‰ ì¶”ì²œ ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤.",
            "travel_plan": {},
            "action_required": None,
            "conversation_context": "ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘",
            "success": False,
            "error": "LangGraph workflow not available"
        }
    
    print(f"ğŸš€ LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰: '{query}' (ì„¸ì…˜: {session_id})")
    
    try:
        # ëŒ€í™” ê¸°ë¡ì´ ìˆìœ¼ë©´ í¬í•¨ (í˜„ì¬ëŠ” ë‹¨ì¼ ë©”ì‹œì§€ë§Œ ì²˜ë¦¬)
        messages = [query]
        if conversation_history and isinstance(conversation_history, list):
            messages = conversation_history + [query]
        
        # ì¿¼ë¦¬ íƒ€ì… ë¶„ì„ (ê°œì„ ëœ ê°ì§€ ë¡œì§)
        query_lower = query.lower()
        
        # í™•ì • ì˜ë„ ê°ì§€ (ë” ì •í™•í•˜ê²Œ)
        is_confirmation = any(keyword in query_lower for keyword in ["í™•ì •", "ê²°ì •", "ì¢‹ì•„", "ì´ê±¸ë¡œ", "ok", "ì˜¤ì¼€ì´", "ë§ì•„", "ë„¤", "ì‘", "ê·¸ë˜"])
        
        # ìƒˆë¡œìš´ ì—¬í–‰ ìš”ì²­ ê°ì§€ (ë” í¬ê´„ì ìœ¼ë¡œ)
        travel_keywords = ["ì¶”ì²œ", "ì—¬í–‰", "ì¼ì •", "ê³„íš", "ê°€ê³ ì‹¶ì–´", "ë†€ëŸ¬", "êµ¬ê²½", "ê´€ê´‘"]
        duration_keywords = ["ë°•", "ì¼", "ë‹¹ì¼", "í•˜ë£¨", "ì´í‹€", "ì‚¬í˜"]
        region_keywords = ["ì„œìš¸", "ë¶€ì‚°", "ì œì£¼", "ê°•ë¦‰", "ê²½ì£¼", "ì „ì£¼", "ëŒ€êµ¬", "ê´‘ì£¼", "ì¸ì²œ", "ì¶˜ì²œ", "ì—¬ìˆ˜", "ê²½ê¸°", "ê°•ì›", "ì „ë¼", "ê²½ìƒ", "ì¶©ì²­"]
        
        has_travel_keywords = any(keyword in query_lower for keyword in travel_keywords)
        has_duration_keywords = any(keyword in query_lower for keyword in duration_keywords)
        has_region_keywords = any(keyword in query_lower for keyword in region_keywords)
        
        # ìƒˆë¡œìš´ ì—¬í–‰ ìš”ì²­ìœ¼ë¡œ íŒë‹¨í•˜ëŠ” ì¡°ê±´ë“¤
        is_new_travel_request = (
            has_travel_keywords or  # ì—¬í–‰ ê´€ë ¨ í‚¤ì›Œë“œ
            has_duration_keywords or  # ê¸°ê°„ ê´€ë ¨ í‚¤ì›Œë“œ
            has_region_keywords or  # ì§€ì—­ëª… í¬í•¨
            any(pattern in query_lower for pattern in ["ì–´ë””", "ë­", "ë­˜", "ì–´ë–¤", "ì¶”ì²œí•´", "ì•Œë ¤ì¤˜", "ê°€ë³¼ë§Œí•œ"])  # ì§ˆë¬¸/ìš”ì²­ íŒ¨í„´
        )
        
        # í™•ì •ì´ ì•„ë‹ˆê³  ìƒˆë¡œìš´ ì—¬í–‰ ìš”ì²­ì¸ ê²½ìš°ë§Œ ìƒˆë¡œìš´ ìš”ì²­ìœ¼ë¡œ ì²˜ë¦¬
        is_new_travel_request = is_new_travel_request and not is_confirmation
        
        is_weather_query = any(keyword in query_lower for keyword in ["ë‚ ì”¨", "ê¸°ì˜¨", "ì˜¨ë„"])

        global current_travel_state

        # ë””ë²„ê¹… ì •ë³´
        print(f"ğŸ” ì¿¼ë¦¬ ë¶„ì„: í™•ì •={is_confirmation}, ìƒˆì—¬í–‰={is_new_travel_request}, ë‚ ì”¨={is_weather_query}")
        print(f"ğŸ” ê¸°ì¡´ ìƒíƒœ: {bool(current_travel_state.get('travel_plan'))}")

        # ìƒˆ ì—¬í–‰ ì¶”ì²œì¼ ë•Œë§Œ ìƒíƒœ ì´ˆê¸°í™” (í™•ì •ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
        if is_new_travel_request and not is_confirmation:
            print("ğŸ”„ ìƒˆë¡œìš´ ì—¬í–‰ ì¶”ì²œ - ìƒíƒœ ì´ˆê¸°í™”")
            current_travel_state.clear()
            current_travel_state.update({
                "last_query": query,
                "travel_plan": {},
                "places": [],
                "context": "",
                "timestamp": "auto"
            })
        else:
            print("ğŸ’¾ ê¸°ì¡´ ìƒíƒœ ìœ ì§€")
            current_travel_state["last_query"] = query
            current_travel_state["timestamp"] = "auto"

        # ì „ì—­ ìƒíƒœì—ì„œ ê¸°ì¡´ ì—¬í–‰ ê³„íš ê°€ì ¸ì˜¤ê¸°
        existing_travel_plan = current_travel_state.get("travel_plan", {})
        print(f"ğŸ”„ ì‚¬ìš©í•  ì—¬í–‰ ê³„íš: {bool(existing_travel_plan)}")

        # ì´ˆê¸° ìƒíƒœ ì„¤ì • (ê°„ì†Œí™”)
        initial_state = {
            "messages": messages,
            "query_type": "",
            "need_rag": False,
            "need_search": False,
            "need_confirmation": False,
            "history": " ".join(messages),
            "rag_results": [],
            "search_results": [],
            "tool_results": {},
            "travel_plan": existing_travel_plan,  # ê¸°ì¡´ ì—¬í–‰ ê³„íš í¬í•¨
            "user_preferences": {},
            "conversation_context": "",
            "formatted_ui_response": {}
        }

        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ë¹„ë™ê¸°)
        final_state = await travel_workflow.ainvoke(initial_state)

        # ì „ì—­ ìƒíƒœ ì—…ë°ì´íŠ¸ (ìƒˆ ì¶”ì²œìœ¼ë¡œ ë®ì–´ì“°ê¸°)
        if final_state.get("travel_plan"):
            # placesëŠ” tool_resultsê°€ ì•„ë‹Œ travel_planì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
            places = []
            if final_state.get("tool_results", {}).get("places"):
                # í™•ì • ì‹œ tool_resultsì—ì„œ places ê°€ì ¸ì˜¤ê¸°
                places = final_state.get("tool_results", {}).get("places", [])
            elif final_state.get("travel_plan", {}).get("places"):
                # ì¼ë°˜ ì—¬í–‰ ì¶”ì²œ ì‹œ travel_planì—ì„œ places ê°€ì ¸ì˜¤ê¸°
                places = final_state.get("travel_plan", {}).get("places", [])

            current_travel_state.update({
                "travel_plan": final_state.get("travel_plan", {}),
                "places": places,
                "context": final_state.get("conversation_context", ""),
                "last_query": query,
                "timestamp": "auto"
            })
            print(f"ğŸ’¾ ìƒˆë¡œìš´ ì—¬í–‰ ìƒíƒœ ì €ì¥ ì™„ë£Œ: {len(places)}ê°œ ì¥ì†Œ")
        
        # êµ¬ì¡°í™”ëœ ì‘ë‹µ ë°˜í™˜
        tool_results = final_state.get("tool_results", {})
        return {
            "response": final_state.get("conversation_context", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
            "travel_plan": final_state.get("travel_plan", {}),
            "action_required": tool_results.get("action"),
            "redirect_url": tool_results.get("redirect_url"),
            "places": tool_results.get("places"),
            "travel_dates": final_state.get("travel_dates"),  # ìµœìƒìœ„ ë ˆë²¨ì— ì¶”ê°€
            "parsed_dates": final_state.get("parsed_dates"),  # ìµœìƒìœ„ ë ˆë²¨ì— ì¶”ê°€
            "raw_state": final_state,
            "success": True
        }
        
    except Exception as e:
        print(f"âŒ LangGraph ì›Œí¬í”Œë¡œìš° ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ì—ëŸ¬ ì‘ë‹µ ë°˜í™˜
        return {
            "response": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "travel_plan": {},
            "action_required": None,
            "conversation_context": f"Error: {str(e)}",
            "success": False,
            "error": str(e)
        }

# ì‹œìŠ¤í…œ ì´ˆê¸°í™”: DB ì¹´íƒˆë¡œê·¸ ë¡œë“œ
try:
    print("ğŸš€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”: DB ì¹´íƒˆë¡œê·¸ ë¡œë“œ ì¤‘...")
    load_db_catalogs()
except Exception as e:
    print(f"âš ï¸ DB ì¹´íƒˆë¡œê·¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
