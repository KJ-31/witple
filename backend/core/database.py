"""
ë°ì´í„°ë² ì´ìŠ¤ ë° ê²€ìƒ‰ ê´€ë ¨ ê¸°ëŠ¥ë“¤
"""
import re
from typing import List, Any, Dict
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document
from sqlalchemy import text
from database import engine as shared_engine
from core.travel_context import TravelContext, get_travel_context


# ìˆ™ì†Œ ì¹´í…Œê³ ë¦¬ ìƒìˆ˜í™” (ë³´ì•ˆ ê°œì„ )
ACCOMMODATION_CATEGORIES = ['ìˆ™ì†Œ', 'í˜¸í…”', 'íœì…˜', 'ëª¨í…”', 'ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤', 'ë¦¬ì¡°íŠ¸', 'í•œì˜¥', 'ê´€ê´‘í˜¸í…”', 'ìœ ìŠ¤í˜¸ìŠ¤í…”']


def is_accommodation(category: str) -> bool:
    """ìˆ™ì†Œ ì¹´í…Œê³ ë¦¬ ì—¬ë¶€ íŒë‹¨"""
    return any(keyword in category for keyword in ACCOMMODATION_CATEGORIES)


def load_db_catalogs() -> Dict[str, List[str]]:
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì§€ì—­, ë„ì‹œ, ì¹´í…Œê³ ë¦¬ ì¹´íƒˆë¡œê·¸ ë¡œë“œ"""
    try:
        engine = shared_engine
        catalogs = {
            "regions": [],
            "cities": [],
            "categories": []
        }

        with engine.connect() as conn:
            # ì§€ì—­ ëª©ë¡ ë¡œë“œ
            regions_query = text("""
                SELECT DISTINCT cmetadata->>'region' as region
                FROM langchain_pg_embedding
                WHERE cmetadata->>'region' IS NOT NULL
                AND cmetadata->>'region' != ''
                ORDER BY region
            """)
            regions_result = conn.execute(regions_query).fetchall()
            catalogs["regions"] = [row.region for row in regions_result if row.region]

            # ë„ì‹œ ëª©ë¡ ë¡œë“œ
            cities_query = text("""
                SELECT DISTINCT cmetadata->>'city' as city
                FROM langchain_pg_embedding
                WHERE cmetadata->>'city' IS NOT NULL
                AND cmetadata->>'city' != ''
                ORDER BY city
            """)
            cities_result = conn.execute(cities_query).fetchall()
            catalogs["cities"] = [row.city for row in cities_result if row.city]

            # ì¹´í…Œê³ ë¦¬ ëª©ë¡ ë¡œë“œ
            categories_query = text("""
                SELECT DISTINCT cmetadata->>'category' as category
                FROM langchain_pg_embedding
                WHERE cmetadata->>'category' IS NOT NULL
                AND cmetadata->>'category' != ''
                ORDER BY category
            """)
            categories_result = conn.execute(categories_query).fetchall()
            catalogs["categories"] = [row.category for row in categories_result if row.category]

        print(f"âœ… DB ì¹´íƒˆë¡œê·¸ ë¡œë“œ ì™„ë£Œ:")
        print(f"   - ì§€ì—­: {len(catalogs['regions'])}ê°œ")
        print(f"   - ë„ì‹œ: {len(catalogs['cities'])}ê°œ")
        print(f"   - ì¹´í…Œê³ ë¦¬: {len(catalogs['categories'])}ê°œ")

        return catalogs

    except Exception as e:
        print(f"âŒ DB ì¹´íƒˆë¡œê·¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {"regions": [], "cities": [], "categories": []}


def normalize_entities(entities: dict, use_fuzzy: bool = True) -> dict:
    """DB ì¹´íƒˆë¡œê·¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—”í‹°í‹° ì •ê·œí™”"""
    context = get_travel_context()
    db_catalogs = context.db_catalogs

    if not db_catalogs:
        print("âš ï¸ DB ì¹´íƒˆë¡œê·¸ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
        return entities

    normalized = {
        "regions": [],
        "cities": [],
        "categories": []
    }

    # ì§€ì—­ëª… ì •ê·œí™”
    for region in entities.get("regions", []):
        for db_region in db_catalogs["regions"]:
            if (region.lower() in db_region.lower() or
                db_region.lower() in region.lower()):
                if db_region not in normalized["regions"]:
                    normalized["regions"].append(db_region)
                break

    # ë„ì‹œëª… ì •ê·œí™”
    for city in entities.get("cities", []):
        for db_city in db_catalogs["cities"]:
            if (city.lower() in db_city.lower() or
                db_city.lower() in city.lower()):
                if db_city not in normalized["cities"]:
                    normalized["cities"].append(db_city)
                break

    # ì¹´í…Œê³ ë¦¬ ì •ê·œí™”
    for category in entities.get("categories", []):
        for db_category in db_catalogs["categories"]:
            if (category.lower() in db_category.lower() or
                db_category.lower() in category.lower()):
                if db_category not in normalized["categories"]:
                    normalized["categories"].append(db_category)
                break

    print(f"ğŸ”§ ì—”í‹°í‹° ì •ê·œí™” ì™„ë£Œ:")
    print(f"   ì›ë³¸ â†’ ì •ê·œí™”")
    print(f"   ì§€ì—­: {entities.get('regions', [])} â†’ {normalized['regions']}")
    print(f"   ë„ì‹œ: {entities.get('cities', [])} â†’ {normalized['cities']}")
    print(f"   ì¹´í…Œê³ ë¦¬: {entities.get('categories', [])} â†’ {normalized['categories']}")

    return normalized


class HybridOptimizedRetriever(BaseRetriever):
    """SQL í•„í„°ë§ + ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°"""

    vectorstore: Any = None
    k: int = 10000  # SQL í•„í„°ë§ìœ¼ë¡œ ì¶•ì†Œëœ í›„ë³´êµ°ì—ì„œ ë²¡í„° ê²€ìƒ‰
    score_threshold: float = 0.5
    max_sql_results: int = 5000  # SQL í•„í„°ë§ ìµœëŒ€ ê²°ê³¼ ìˆ˜

    def __init__(self, vectorstore, k: int = 10000, score_threshold: float = 0.5, max_sql_results: int = 5000):
        super().__init__()
        self.vectorstore = vectorstore
        self.k = k
        self.score_threshold = score_threshold
        self.max_sql_results = max_sql_results

    def _get_relevant_documents(self, query: str) -> List[Document]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: SQL 1ì°¨ í•„í„°ë§ + ë²¡í„° 2ì°¨ ê²€ìƒ‰"""
        try:
            print(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")

            # 1ë‹¨ê³„: ì§€ì—­/ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
            from utils.entity_extractor import detect_query_entities
            context = get_travel_context()
            entities = detect_query_entities(query, context.llm, context.db_catalogs)
            regions = entities.get('regions', [])
            cities = entities.get('cities', [])
            categories = entities.get('categories', [])

            print(f"   ì¶”ì¶œëœ ì •ë³´ - ì§€ì—­: {regions}, ë„ì‹œ: {cities}, ì¹´í…Œê³ ë¦¬: {categories}")

            # 2ë‹¨ê³„: ë„ì‹œ ìš°ì„  ê²€ìƒ‰ ë¡œì§
            candidate_docs = self._city_first_search(query, regions, cities, categories)

            if not candidate_docs:
                print("âš ï¸ SQL í•„í„°ë§ ê²°ê³¼ ì—†ìŒ, ì „ì²´ ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰")
                docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=min(500, self.k))
                filtered_docs = []
                for doc, score in docs_with_scores:
                    if score >= self.score_threshold:
                        doc.metadata['similarity_score'] = round(score, 3)
                        doc.metadata['search_method'] = 'pgvector_full'
                        filtered_docs.append(doc)
                print(f"âœ… ì „ì²´ ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(filtered_docs)}ê°œ ë¬¸ì„œ")
                return filtered_docs

            print(f"ğŸ“Š SQL í•„í„°ë§: {len(candidate_docs)}ê°œ í›„ë³´ ë¬¸ì„œ ì„ ë³„")

            # 3ë‹¨ê³„: ì„ ë³„ëœ í›„ë³´êµ°ì— ëŒ€í•´ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°
            final_docs = self._vector_search_on_candidates(query, candidate_docs)

            print(f"âœ… ìµœì¢… ê²°ê³¼: {len(final_docs)}ê°œ ë¬¸ì„œ (ì„ê³„ê°’ â‰¥{self.score_threshold})")
            return final_docs

        except Exception as e:
            print(f"âŒ HybridOptimizedRetriever ì˜¤ë¥˜: {e}")
            return []

    def _city_first_search(self, query: str, regions: List[str], cities: List[str], categories: List[str]) -> List[Document]:
        """ë„ì‹œ ìš°ì„  ê²€ìƒ‰ - ë„ì‹œë§Œìœ¼ë¡œ ë¨¼ì € ê²€ìƒ‰í•˜ê³ , ê²°ê³¼ ë¶€ì¡±ì‹œ ì§€ì—­ìœ¼ë¡œ í™•ëŒ€"""
        try:
            MIN_CITY_RESULTS = 10  # ë„ì‹œ ê²€ìƒ‰ ìµœì†Œ ê²°ê³¼ ìˆ˜

            # 1ë‹¨ê³„: ë„ì‹œë§Œìœ¼ë¡œ ê²€ìƒ‰
            if cities:
                print(f"ğŸ¯ 1ë‹¨ê³„: ë„ì‹œ ìš°ì„  ê²€ìƒ‰ - {cities}")
                city_docs = self._sql_filter_candidates(query, [], cities, categories)
                print(f"   ë„ì‹œ ê²€ìƒ‰ ê²°ê³¼: {len(city_docs)}ê°œ")

                if len(city_docs) >= MIN_CITY_RESULTS:
                    print(f"âœ… ë„ì‹œ ê²€ìƒ‰ìœ¼ë¡œ ì¶©ë¶„í•œ ê²°ê³¼({len(city_docs)}ê°œ) í™•ë³´, ì§€ì—­ í™•ì¥ ì—†ì´ ì§„í–‰")
                    return city_docs
                else:
                    print(f"âš ï¸ ë„ì‹œ ê²€ìƒ‰ ê²°ê³¼ ë¶€ì¡±({len(city_docs)}ê°œ < {MIN_CITY_RESULTS}ê°œ), ì§€ì—­ìœ¼ë¡œ í™•ëŒ€ ê²€ìƒ‰")

            # 2ë‹¨ê³„: ì§€ì—­ìœ¼ë¡œ í™•ëŒ€ ê²€ìƒ‰ (ê¸°ì¡´ ë¡œì§)
            if regions or cities:
                print(f"ğŸŒ 2ë‹¨ê³„: ì§€ì—­ í™•ëŒ€ ê²€ìƒ‰ - ì§€ì—­: {regions}, ë„ì‹œ: {cities}")
                expanded_docs = self._sql_filter_candidates(query, regions, cities, categories)
                print(f"   í™•ëŒ€ ê²€ìƒ‰ ê²°ê³¼: {len(expanded_docs)}ê°œ")
                return expanded_docs

            # 3ë‹¨ê³„: ëª¨ë“  ì¡°ê±´ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œì§
            return self._sql_filter_candidates(query, regions, cities, categories)

        except Exception as e:
            print(f"âŒ ë„ì‹œ ìš°ì„  ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def _sql_filter_candidates(self, query: str, regions: List[str], cities: List[str], categories: List[str]) -> List[Document]:
        """SQL ì¿¼ë¦¬ë¡œ í›„ë³´ ë¬¸ì„œë“¤ì„ ë¨¼ì € í•„í„°ë§"""
        try:
            engine = shared_engine

            # ì¡°ê±´ì´ ì—†ìœ¼ë©´ ì „ì²´ ê²€ìƒ‰ ì‹¤í–‰
            if not regions and not cities and not categories:
                print("ğŸ” ì§€ì—­/ì¹´í…Œê³ ë¦¬ ì •ë³´ ì—†ìŒ, ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤í–‰")
                sql_query = text("""
                    SELECT document, cmetadata
                    FROM langchain_pg_embedding
                    WHERE collection_id = (SELECT uuid FROM langchain_pg_collection WHERE name = 'place_recommendations')
                    ORDER BY RANDOM()
                    LIMIT :limit
                """)

                with engine.connect() as conn:
                    results = conn.execute(sql_query, {"limit": min(self.max_sql_results, 1000)}).fetchall()

                docs = []
                for row in results:
                    metadata = row.cmetadata or {}
                    metadata['search_method'] = 'sql_random'
                    docs.append(Document(page_content=row.document, metadata=metadata))

                print(f"ğŸ“Š ì „ì²´ í…ìŠ¤íŠ¸ ê²€ìƒ‰: {len(docs)}ê°œ ë¬¸ì„œ ë°˜í™˜")
                return docs

            # SQL ì¡°ê±´ êµ¬ì„±
            conditions = []

            # SQL ì¡°ê±´ê³¼ íŒŒë¼ë¯¸í„° êµ¬ì„±
            params = {}
            param_counter = 0

            if regions:
                region_conditions = []
                for region in regions:
                    # ì„œìš¸íŠ¹ë³„ì‹œ -> ì„œìš¸ë¡œ ë³€í™˜í•˜ì—¬ ê²€ìƒ‰
                    region_simple = region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '')
                    param_name = f"region_{param_counter}"
                    region_conditions.append(f"cmetadata->>'region' ILIKE :{param_name}")
                    params[param_name] = f'%{region_simple}%'
                    param_counter += 1
                conditions.append(f"({' OR '.join(region_conditions)})")

            if cities:
                city_conditions = []
                for city in cities:
                    # city í•„ë“œì™€ region í•„ë“œ ëª¨ë‘ì—ì„œ ê²€ìƒ‰ (ì„œìš¸ì˜ ê²½ìš°)
                    city_simple = city.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '')

                    # city í•„ë“œ ê²€ìƒ‰
                    city_param = f"city_{param_counter}"
                    city_conditions.append(f"cmetadata->>'city' ILIKE :{city_param}")
                    params[city_param] = f'%{city_simple}%'
                    param_counter += 1

                    # region í•„ë“œ ê²€ìƒ‰
                    region_param = f"city_region_{param_counter}"
                    city_conditions.append(f"cmetadata->>'region' ILIKE :{region_param}")
                    params[region_param] = f'%{city_simple}%'
                    param_counter += 1

                conditions.append(f"({' OR '.join(city_conditions)})")

            if categories:
                category_conditions = []
                for category in categories:
                    param_name = f"category_{param_counter}"
                    category_conditions.append(f"cmetadata->>'category' ILIKE :{param_name}")
                    params[param_name] = f'%{category}%'
                    param_counter += 1
                conditions.append(f"({' OR '.join(category_conditions)})")

            where_clause = " OR ".join(conditions)

            # ìˆ™ì†Œ í•„í„°ë§ì„ ìœ„í•œ íŒŒë¼ë¯¸í„° ì¶”ê°€
            for i, accommodation in enumerate(ACCOMMODATION_CATEGORIES):
                param_name = f"exclude_accommodation_{i}"
                params[param_name] = f'%{accommodation}%'

            # ìˆ™ì†Œ ì œì™¸ ì¡°ê±´ êµ¬ì„±
            accommodation_excludes = " AND ".join([
                f"cmetadata->>'category' NOT ILIKE :exclude_accommodation_{i}"
                for i in range(len(ACCOMMODATION_CATEGORIES))
            ])

            params['max_results'] = self.max_sql_results

            sql_query = f"""
                SELECT document, cmetadata, embedding
                FROM langchain_pg_embedding
                WHERE ({where_clause})
                AND {accommodation_excludes}
                LIMIT :max_results
            """

            print(f"ğŸ—„ï¸ SQL í•„í„°ë§ ì‹¤í–‰ (íŒŒë¼ë¯¸í„° ë°”ì¸ë”©)...")

            with engine.connect() as conn:
                result = conn.execute(text(sql_query), params)
                rows = result.fetchall()

                docs = []
                for row in rows:
                    doc = Document(
                        page_content=row.document,
                        metadata=row.cmetadata or {}
                    )
                    # ì„ë² ë”© ì •ë³´ë„ ì €ì¥ (ë²¡í„° ê²€ìƒ‰ìš©)
                    if row.embedding:
                        doc.metadata['_embedding'] = row.embedding
                    docs.append(doc)

                return docs

        except Exception as e:
            print(f"âŒ SQL í•„í„°ë§ ì˜¤ë¥˜: {e}")
            return []

    def _vector_search_on_candidates(self, query: str, candidate_docs: List[Document]) -> List[Document]:
        """PGVectorë¥¼ ì‚¬ìš©í•œ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            # PGVector ë²¡í„° ê²€ìƒ‰
            print("ğŸ”„ PGVector ë²¡í„° ê²€ìƒ‰")
            all_docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=self.k)

            # í›„ë³´ ë¬¸ì„œì˜ ë‚´ìš©ìœ¼ë¡œ ë§¤ì¹­
            candidate_contents = {doc.page_content for doc in candidate_docs}

            filtered_docs = []
            for doc, score in all_docs_with_scores:
                # ìˆ™ì†Œ ì¹´í…Œê³ ë¦¬ í•„í„°ë§
                category = doc.metadata.get('category', '')
                accommodation_keywords = ['ìˆ™ì†Œ', 'í˜¸í…”', 'íœì…˜', 'ëª¨í…”', 'ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤', 'ë¦¬ì¡°íŠ¸', 'í•œì˜¥', 'ê´€ê´‘í˜¸í…”', 'ìœ ìŠ¤í˜¸ìŠ¤í…”', 'í…”', 'ë ˆì§€ë˜ìŠ¤']
                is_accommodation = any(keyword in category for keyword in accommodation_keywords)

                if is_accommodation:
                    print(f"ğŸš« PGVector ìˆ™ì†Œ í•„í„°ë§: {category} - {doc.page_content[:30]}...")
                    continue

                if doc.page_content in candidate_contents and score >= self.score_threshold:
                    # ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ metadataì— ì¶”ê°€
                    doc.metadata['similarity_score'] = round(score, 3)
                    doc.metadata['search_method'] = 'pgvector_hybrid'
                    filtered_docs.append(doc)

                    # ì¶©ë¶„í•œ ê²°ê³¼ë¥¼ ì–»ìœ¼ë©´ ì¤‘ë‹¨ (ì„±ëŠ¥ ìµœì í™”)
                    if len(filtered_docs) >= 50:
                        break

            print(f"âœ… PGVector ê²€ìƒ‰ ì™„ë£Œ: {len(filtered_docs)}ê°œ ë¬¸ì„œ")
            return filtered_docs

        except Exception as e:
            print(f"âŒ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return []


def search_places(query, target_categories=None):
    """ê¸°ë³¸ ì¥ì†Œ ê²€ìƒ‰ í•¨ìˆ˜"""
    context = get_travel_context()
    if not context.retriever:
        return []

    try:
        if target_categories:
            # ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ ë¡œì§
            docs = context.retriever._city_first_search_with_categories(
                query, [], [], target_categories
            )
        else:
            # ì¼ë°˜ ê²€ìƒ‰
            docs = context.retriever._get_relevant_documents(query)

        return docs

    except Exception as e:
        print(f"âŒ ì¥ì†Œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []


def search_places_by_type(query, regions, cities):
    """íƒ€ì…ë³„ ì¥ì†Œ ê²€ìƒ‰"""
    context = get_travel_context()
    if not context.retriever:
        return []

    try:
        # ì—¬í–‰ì§€ì™€ ìŒì‹ì  ë¶„ë¦¬ ê²€ìƒ‰
        travel_docs = search_places_with_filter(query, regions, cities, ["ê´€ê´‘ì§€", "ìì—°", "ì—­ì‚¬"])
        food_docs = search_places_with_filter(query, regions, cities, ["ë§›ì§‘", "ì¹´í˜", "ìŒì‹"])

        # ê²°í•© ë° ì¤‘ë³µ ì œê±°
        all_docs = travel_docs + food_docs
        unique_docs = []
        seen_contents = set()

        for doc in all_docs:
            if doc.page_content not in seen_contents:
                seen_contents.add(doc.page_content)
                unique_docs.append(doc)

        return unique_docs[:50]  # ìƒìœ„ 50ê°œ ì œí•œ

    except Exception as e:
        print(f"âŒ íƒ€ì…ë³„ ì¥ì†Œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []


def search_places_with_filter(query, regions, cities, target_categories):
    """í•„í„°ë¥¼ ì ìš©í•œ ì¥ì†Œ ê²€ìƒ‰"""
    context = get_travel_context()
    if not context.retriever:
        return []

    try:
        docs = context.retriever._sql_filter_candidates(query, regions, cities, target_categories)
        return docs[:30]  # ìƒìœ„ 30ê°œ ì œí•œ

    except Exception as e:
        print(f"âŒ í•„í„° ì¥ì†Œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []


def initialize_retriever(vectorstore):
    """Retriever ì´ˆê¸°í™” ë° ì»¨í…ìŠ¤íŠ¸ì— ì„¤ì •"""
    retriever = HybridOptimizedRetriever(
        vectorstore=vectorstore,
        k=10000,
        score_threshold=0.5,
        max_sql_results=5000
    )

    # ì»¨í…ìŠ¤íŠ¸ì— retriever ì„¤ì •
    context = get_travel_context()
    context.retriever = retriever
    context.vectorstore = vectorstore

    # DB ì¹´íƒˆë¡œê·¸ ë¡œë“œ
    db_catalogs = load_db_catalogs()
    context.db_catalogs = db_catalogs

    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ë° ê²€ìƒ‰ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    return retriever