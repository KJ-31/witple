"""
ìµœì í™”ëœ ì¥ì†Œ ë§¤ì¹­ ì‹œìŠ¤í…œ
"""
from functools import lru_cache
from cachetools import TTLCache
import hashlib
import re
from typing import List, Dict, Any, Set, Optional, Tuple
import time
from dataclasses import dataclass
from collections import defaultdict


@dataclass
class MatchResult:
    """ë§¤ì¹­ ê²°ê³¼"""
    day_number: int
    confidence: float
    matched_schedule_item: Optional[Dict] = None
    match_type: str = "none"  # exact, partial, category, default


class OptimizedPlaceMatcher:
    """ìºì‹±ê³¼ ì¸ë±ì‹±ì„ í™œìš©í•œ ê³ ì„±ëŠ¥ ì¥ì†Œ ë§¤ì¹­"""

    def __init__(self, cache_ttl: int = 3600, cache_maxsize: int = 1000):
        # ìºì‹œ ì„¤ì •
        self.cache = TTLCache(maxsize=cache_maxsize, ttl=cache_ttl)

        # ì¸ë±ìŠ¤
        self.normalized_places_index: Dict[str, Dict] = {}  # ì •ê·œí™”ëœ ì¥ì†Œëª… -> ì¥ì†Œ ì •ë³´
        self.itinerary_index: Dict[str, Dict] = {}         # ì¼ì •ë³„ ì¸ë±ìŠ¤
        self.category_index: Dict[str, List[int]] = defaultdict(list)  # ì¹´í…Œê³ ë¦¬ë³„ ì¼ì°¨

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.metrics = {
            "cache_hits": 0,
            "cache_misses": 0,
            "index_builds": 0,
            "match_attempts": 0
        }

    @lru_cache(maxsize=2000)
    def normalize_place_name(self, place_name: str) -> str:
        """ì¥ì†Œëª… ì •ê·œí™” (LRU ìºì‹œ ì ìš©)"""
        if not place_name:
            return ""

        # íš¨ìœ¨ì ì¸ ì •ê·œí™” ë¡œì§
        cleaned = place_name.strip().lower()

        # í•œê¸€, ì˜ìˆ«ì, ê³µë°±ë§Œ ìœ ì§€
        cleaned = ''.join(char for char in cleaned
                         if char.isalnum() or char.isspace() or ord(char) >= 0xAC00)

        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€ê²½
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()

        # ì¼ë°˜ì ì¸ ì ‘ë¯¸ì‚¬ ì œê±° (ì„±ëŠ¥ ìµœì í™”)
        suffixes = ['ì¹´í˜', 'ë ˆìŠ¤í† ë‘', 'ì‹ë‹¹', 'ë°•ë¬¼ê´€', 'ë¯¸ìˆ ê´€', 'ê³µì›', 'í•´ë³€', 'ì‹œì¥', 'í˜¸í…”', 'íœì…˜']
        for suffix in suffixes:
            if cleaned.endswith(suffix) and len(cleaned) > len(suffix):
                base_name = cleaned[:-len(suffix)].strip()
                if len(base_name) >= 2:  # ìµœì†Œ ê¸¸ì´ í™•ì¸
                    cleaned = base_name
                    break

        return cleaned

    def build_itinerary_index(self, itinerary: List[Dict]) -> str:
        """ì¼ì • ì¸ë±ìŠ¤ êµ¬ì¶•"""
        # ì¼ì • í•´ì‹œ ìƒì„± (ìºì‹œ í‚¤ìš©)
        itinerary_hash = hashlib.md5(str(itinerary).encode()).hexdigest()[:8]

        if itinerary_hash in self.itinerary_index:
            return itinerary_hash

        print(f"ğŸ—ï¸ ì¼ì • ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘: {len(itinerary)}ì¼ì°¨")
        self.metrics["index_builds"] += 1

        # ì¼ì°¨ë³„ ì •ê·œí™”ëœ ì¥ì†Œ ë§¤í•‘
        day_places_index = {}
        category_day_mapping = defaultdict(set)

        for day_info in itinerary:
            day_num = day_info.get("day", 1)
            day_places = []

            for schedule in day_info.get("schedule", []):
                # ë‹¤ì–‘í•œ í•„ë“œì—ì„œ ì¥ì†Œëª… ì¶”ì¶œ
                place_names = self._extract_place_names_from_schedule(schedule)

                for place_name_raw in place_names:
                    if place_name_raw:
                        normalized = self.normalize_place_name(place_name_raw)
                        if normalized:
                            day_places.append({
                                'original': place_name_raw,
                                'normalized': normalized,
                                'schedule_item': schedule
                            })

                            # ì¹´í…Œê³ ë¦¬ë³„ ì¸ë±ì‹±
                            category = self._extract_category_from_schedule(schedule)
                            if category:
                                category_day_mapping[category].add(day_num)

            day_places_index[day_num] = day_places

        # ì¸ë±ìŠ¤ ì €ì¥
        self.itinerary_index[itinerary_hash] = {
            'day_places': day_places_index,
            'category_mapping': dict(category_day_mapping),
            'total_days': len(itinerary),
            'build_time': time.time()
        }

        print(f"âœ… ì¼ì • ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ: {len(day_places_index)}ì¼ì°¨, "
              f"{sum(len(places) for places in day_places_index.values())}ê°œ ì¥ì†Œ")

        return itinerary_hash

    def _extract_place_names_from_schedule(self, schedule: Dict) -> List[str]:
        """ìŠ¤ì¼€ì¤„ í•­ëª©ì—ì„œ ì¥ì†Œëª… ì¶”ì¶œ"""
        possible_fields = [
            "place_name", "place", "name", "location",
            "venue", "attraction", "restaurant"
        ]

        place_names = []

        # ì§ì ‘ í•„ë“œì—ì„œ ì¶”ì¶œ
        for field in possible_fields:
            if schedule.get(field):
                place_names.append(str(schedule[field]))

        # place_info ë‚´ë¶€ì—ì„œ ì¶”ì¶œ
        if schedule.get("place_info"):
            place_info = schedule["place_info"]
            for field in possible_fields:
                if place_info.get(field):
                    place_names.append(str(place_info[field]))

        return place_names

    def _extract_category_from_schedule(self, schedule: Dict) -> Optional[str]:
        """ìŠ¤ì¼€ì¤„ í•­ëª©ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
        category_fields = ["category", "type", "classification"]

        for field in category_fields:
            if schedule.get(field):
                return str(schedule[field]).lower()

            if schedule.get("place_info", {}).get(field):
                return str(schedule["place_info"][field]).lower()

        # ì„¤ëª…ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ë¡ 
        description = schedule.get("description", "").lower()
        if any(keyword in description for keyword in ["ì‹ë‹¹", "ë§›ì§‘", "ìŒì‹"]):
            return "ì‹ë‹¹"
        elif any(keyword in description for keyword in ["ê´€ê´‘", "ëª…ì†Œ", "ë°•ë¬¼ê´€"]):
            return "ê´€ê´‘ì§€"

        return None

    def find_day_for_place(self, place_name: str, itinerary: List[Dict]) -> MatchResult:
        """ìºì‹œë¥¼ í™œìš©í•œ ê³ ì„±ëŠ¥ ì¥ì†Œ-ì¼ì°¨ ë§¤ì¹­"""
        self.metrics["match_attempts"] += 1

        # ì¼ì • ì¸ë±ìŠ¤ êµ¬ì¶•
        itinerary_hash = self.build_itinerary_index(itinerary)

        # ìºì‹œ í‚¤ ìƒì„±
        place_normalized = self.normalize_place_name(place_name)
        cache_key = f"{place_normalized}:{itinerary_hash}"

        # ìºì‹œì—ì„œ ì¡°íšŒ
        if cache_key in self.cache:
            self.metrics["cache_hits"] += 1
            cached_result = self.cache[cache_key]
            print(f"ğŸ¯ ìºì‹œ íˆíŠ¸: '{place_name}' -> {cached_result.day_number}ì¼ì°¨")
            return cached_result

        self.metrics["cache_misses"] += 1

        # ì‹¤ì œ ë§¤ì¹­ ìˆ˜í–‰
        result = self._perform_matching(place_name, place_normalized, itinerary_hash)

        # ê²°ê³¼ ìºì‹±
        self.cache[cache_key] = result

        print(f"ğŸ” ë§¤ì¹­ ê²°ê³¼: '{place_name}' -> {result.day_number}ì¼ì°¨ "
              f"(ì‹ ë¢°ë„: {result.confidence:.2f}, íƒ€ì…: {result.match_type})")

        return result

    def _perform_matching(self, original_place: str, normalized_place: str, itinerary_hash: str) -> MatchResult:
        """ì‹¤ì œ ë§¤ì¹­ ë¡œì§"""
        index_data = self.itinerary_index[itinerary_hash]
        day_places = index_data['day_places']

        # 1ë‹¨ê³„: ì •í™• ë§¤ì¹­
        for day_num, places_list in day_places.items():
            for place_data in places_list:
                if normalized_place == place_data['normalized']:
                    return MatchResult(
                        day_number=day_num,
                        confidence=1.0,
                        matched_schedule_item=place_data['schedule_item'],
                        match_type="exact"
                    )

        # 2ë‹¨ê³„: ë¶€ë¶„ ë§¤ì¹­ (í¬í•¨ ê´€ê³„)
        best_match = None
        best_confidence = 0.0

        for day_num, places_list in day_places.items():
            for place_data in places_list:
                schedule_normalized = place_data['normalized']

                # ì–‘ë°©í–¥ í¬í•¨ ê´€ê³„ í™•ì¸
                confidence = self._calculate_similarity_confidence(normalized_place, schedule_normalized)

                if confidence > 0.5 and confidence > best_confidence:
                    best_match = MatchResult(
                        day_number=day_num,
                        confidence=confidence,
                        matched_schedule_item=place_data['schedule_item'],
                        match_type="partial"
                    )
                    best_confidence = confidence

        if best_match:
            return best_match

        # 3ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ë§¤ì¹­
        category_result = self._match_by_category(original_place, index_data)
        if category_result:
            return category_result

        # 4ë‹¨ê³„: ê¸°ë³¸ê°’ (ìµœì†Œ ì¥ì†Œê°€ ìˆëŠ” ì¼ì°¨)
        if day_places:
            min_places_day = min(day_places.keys(),
                                key=lambda x: len(day_places[x]))
            return MatchResult(
                day_number=min_places_day,
                confidence=0.1,
                match_type="default"
            )

        # ìµœì¢… í´ë°±
        return MatchResult(day_number=1, confidence=0.0, match_type="none")

    def _calculate_similarity_confidence(self, place1: str, place2: str) -> float:
        """ìœ ì‚¬ë„ ì‹ ë¢°ë„ ê³„ì‚°"""
        if not place1 or not place2:
            return 0.0

        # ê¸¸ì´ í™•ì¸
        min_len = min(len(place1), len(place2))
        if min_len < 2:
            return 0.0

        # í¬í•¨ ê´€ê³„ í™•ì¸
        if place1 in place2:
            return len(place1) / len(place2)
        elif place2 in place1:
            return len(place2) / len(place1)

        # Jaccard ìœ ì‚¬ë„ ê³„ì‚° (ë‹¨ì–´ ê¸°ë°˜)
        words1 = set(place1.split())
        words2 = set(place2.split())

        if not words1 or not words2:
            return 0.0

        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))

        return intersection / union if union > 0 else 0.0

    def _match_by_category(self, place_name: str, index_data: Dict) -> Optional[MatchResult]:
        """ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ ë§¤ì¹­"""
        # ì¥ì†Œëª…ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ë¡ 
        inferred_category = None
        place_lower = place_name.lower()

        if any(keyword in place_lower for keyword in ["ì‹ë‹¹", "ë§›ì§‘", "ì¹´í˜", "ë ˆìŠ¤í† ë‘"]):
            inferred_category = "ì‹ë‹¹"
        elif any(keyword in place_lower for keyword in ["ë°•ë¬¼ê´€", "ë¯¸ìˆ ê´€", "ê´€ê´‘", "ëª…ì†Œ"]):
            inferred_category = "ê´€ê´‘ì§€"

        if not inferred_category:
            return None

        category_mapping = index_data.get('category_mapping', {})
        if inferred_category in category_mapping:
            possible_days = list(category_mapping[inferred_category])
            if possible_days:
                # ê°€ì¥ ì ê²Œ ì‚¬ìš©ëœ ì¼ì°¨ ì„ íƒ
                day_places = index_data['day_places']
                best_day = min(possible_days,
                             key=lambda x: len(day_places.get(x, [])))
                return MatchResult(
                    day_number=best_day,
                    confidence=0.3,
                    match_type="category"
                )

        return None

    def batch_match_places(self, places: List[Dict], itinerary: List[Dict]) -> Dict[str, MatchResult]:
        """ë°°ì¹˜ ì¥ì†Œ ë§¤ì¹­ (ì„±ëŠ¥ ìµœì í™”)"""
        print(f"ğŸ”„ ë°°ì¹˜ ë§¤ì¹­ ì‹œì‘: {len(places)}ê°œ ì¥ì†Œ")

        # ì¼ì • ì¸ë±ìŠ¤ ë¯¸ë¦¬ êµ¬ì¶•
        itinerary_hash = self.build_itinerary_index(itinerary)

        results = {}
        for place in places:
            place_name = place.get('name', '')
            if place_name:
                result = self.find_day_for_place(place_name, itinerary)
                results[place_name] = result

        print(f"âœ… ë°°ì¹˜ ë§¤ì¹­ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
        return results

    def get_performance_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        cache_hit_rate = (self.metrics["cache_hits"] /
                         max(self.metrics["cache_hits"] + self.metrics["cache_misses"], 1))

        return {
            "cache_size": len(self.cache),
            "cache_hit_rate": cache_hit_rate,
            "total_matches": self.metrics["match_attempts"],
            "index_builds": self.metrics["index_builds"],
            "metrics": self.metrics.copy()
        }

    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        self.cache.clear()
        self.itinerary_index.clear()
        self.normalized_places_index.clear()
        self.category_index.clear()
        print("ğŸ§¹ ì¥ì†Œ ë§¤ì¹­ ìºì‹œ ì´ˆê¸°í™” ì™„ë£Œ")

    def warm_up_cache(self, common_places: List[str], sample_itineraries: List[List[Dict]]):
        """ìºì‹œ ì˜ˆì—´ (ìì£¼ ì‚¬ìš©ë˜ëŠ” ì¥ì†Œë“¤)"""
        print(f"ğŸ”¥ ìºì‹œ ì˜ˆì—´ ì‹œì‘: {len(common_places)}ê°œ ì¥ì†Œ, {len(sample_itineraries)}ê°œ ì¼ì •")

        for itinerary in sample_itineraries:
            for place_name in common_places:
                self.find_day_for_place(place_name, itinerary)

        print(f"âœ… ìºì‹œ ì˜ˆì—´ ì™„ë£Œ: {len(self.cache)}ê°œ í•­ëª©")


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_global_place_matcher: Optional[OptimizedPlaceMatcher] = None


def get_place_matcher() -> OptimizedPlaceMatcher:
    """ì „ì—­ ì¥ì†Œ ë§¤ì¹­ê¸° ì¡°íšŒ"""
    global _global_place_matcher
    if _global_place_matcher is None:
        _global_place_matcher = OptimizedPlaceMatcher()
    return _global_place_matcher


def reset_place_matcher():
    """ì „ì—­ ì¥ì†Œ ë§¤ì¹­ê¸° ë¦¬ì…‹"""
    global _global_place_matcher
    _global_place_matcher = None


# í¸ì˜ í•¨ìˆ˜ë“¤
def match_place_to_day(place_name: str, itinerary: List[Dict]) -> int:
    """ì¥ì†Œë¥¼ ì¼ì°¨ì— ë§¤ì¹­ (ê°„ë‹¨í•œ ì¸í„°í˜ì´ìŠ¤)"""
    matcher = get_place_matcher()
    result = matcher.find_day_for_place(place_name, itinerary)
    return result.day_number


def match_places_batch(places: List[Dict], itinerary: List[Dict]) -> Dict[str, int]:
    """ì¥ì†Œë“¤ì„ ì¼ì°¨ì— ë°°ì¹˜ ë§¤ì¹­"""
    matcher = get_place_matcher()
    results = matcher.batch_match_places(places, itinerary)
    return {name: result.day_number for name, result in results.items()}