"""
í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìµœì í™” RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œ
PostgreSQL + PGVector + LangChain + Amazon Bedrock ê¸°ë°˜

ì‘ì„±ì¼: 2025ë…„
ëª©ì : SQL í•„í„°ë§ + ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ ê³ ì„±ëŠ¥ ì—¬í–‰ì§€ ì¶”ì²œ ì‹œìŠ¤í…œ (Amazon Bedrock ë²„ì „)
"""

import boto3
from langchain_aws import ChatBedrock
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_postgres import PGVector
from langchain_core.runnables import RunnablePassthrough
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document
from typing import List, Any
from sqlalchemy import create_engine, text
import sys
import os

# =============================================================================
# AWS ì„¤ì • ë° ì´ˆê¸°í™”
# =============================================================================

# AWS ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” AWS CLI ì„¤ì • ì‚¬ìš©)
AWS_REGION = os.getenv('AWS_REGION')  # Bedrockì´ ì§€ì›ë˜ëŠ” ë¦¬ì „ (ì„œìš¸)
AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')
AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')

# AWS ì„¸ì…˜ ìƒì„±
try:
    boto3_session = boto3.Session(
        aws_access_key_id=AWS_ACCESS_KEY_ID,
        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
        region_name=AWS_REGION
    )
except Exception as e:
    print(f"âš ï¸ AWS ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
    boto3_session = None

# =============================================================================
# ì„¤ì • ë° ì´ˆê¸°í™”
# =============================================================================

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
CONNECTION_STRING = "postgresql+psycopg://postgres:witple123!@witple-pub-database.cfme8csmytkv.ap-northeast-2.rds.amazonaws.com:5432/witple_db"

# LLM ëª¨ë¸ ì„¤ì • (Amazon Bedrock - Claude)
print("ğŸ¤– Amazon Bedrock Claude ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
try:
    llm = ChatBedrock(
        model_id="anthropic.claude-3-haiku-20240307-v1:0",  # Claude 3 Haiku
        # model_id="anthropic.claude-3-sonnet-20240229-v1:0",  # Claude 3 Sonnet (ë” ê°•ë ¥)
        region_name=AWS_REGION,
        credentials_profile_name=None,  # ê¸°ë³¸ ìê²©ì¦ëª… ì‚¬ìš©
        model_kwargs={
            "temperature": 0.2,  # ë‚®ì„ìˆ˜ë¡ ì¼ê´€ëœ ë‹µë³€ ì œê³µ
            "max_tokens": 2000,  # ìµœëŒ€ í† í° ìˆ˜
            "top_p": 0.9,
        }
    )
except Exception as e:
    print(f"âŒ Bedrock LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    print("í™˜ê²½ë³€ìˆ˜ë‚˜ AWS CLI ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

# ì„ë² ë”© ëª¨ë¸ ì„¤ì • (384ì°¨ì›) - ë¡œì»¬ HuggingFace ëª¨ë¸ ì‚¬ìš©
print("ğŸ§  ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
embeddings = HuggingFaceEmbeddings(
    model_name='sentence-transformers/all-MiniLM-L12-v2'
)

# Amazon Bedrock Embeddings ì‚¬ìš©í•˜ë ¤ë©´ ì•„ë˜ ì½”ë“œë¡œ êµì²´:
# from langchain_aws import BedrockEmbeddings
# embeddings = BedrockEmbeddings(
#     model_id="amazon.titan-embed-text-v1",
#     boto3_session=boto3_session
# )

# =============================================================================
# ë²¡í„°ìŠ¤í† ì–´ ì—°ê²°
# =============================================================================

print("ğŸ”— ë²¡í„°ìŠ¤í† ì–´ ì—°ê²° ì¤‘...")
vectorstore = PGVector(
    embeddings=embeddings,
    collection_name="place_recommendations",  # ì´ê´€ëœ ë°ì´í„°ê°€ ìˆëŠ” collection
    connection=CONNECTION_STRING,
    pre_delete_collection=False,  # ê¸°ì¡´ ë°ì´í„° ë³´ì¡´
)

# =============================================================================
# ì§€ì—­ ë° í‚¤ì›Œë“œ ì¸ì‹ ì‹œìŠ¤í…œ
# =============================================================================

# ì§€ì—­ ë° í‚¤ì›Œë“œ ë°ì´í„° (ì‹¤ì œ DB ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
REGIONS = [
    'ê²½ê¸°ë„', 'ì„œìš¸íŠ¹ë³„ì‹œ', 'ê°•ì›íŠ¹ë³„ìì¹˜ë„', 'ê²½ìƒë‚¨ë„', 'ê²½ìƒë¶ë„', 'ì „ë¼ë‚¨ë„', 
    'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ì¶©ì²­ë‚¨ë„', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„', 'ì¸ì²œê´‘ì—­ì‹œ', 'ì „ë¶íŠ¹ë³„ìì¹˜ë„', 
    'ì¶©ì²­ë¶ë„', 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ê´‘ì£¼ê´‘ì—­ì‹œ', 'ëŒ€ì „ê´‘ì—­ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ'
]

CITIES = [
    'ì¤‘êµ¬', 'í‰ì°½êµ°', 'ê°•ë‚¨êµ¬', 'ì„œê·€í¬ì‹œ', 'ê°•ë¦‰ì‹œ', 'ì œì£¼ì‹œ', 'ê³ ì–‘ì‹œ', 'ìš©ì¸ì‹œ', 
    'ì„œêµ¬', 'íŒŒì£¼ì‹œ', 'ì•ˆì–‘ì‹œ', 'êµ¬ë¡œêµ¬', 'ê²½ì£¼ì‹œ', 'ê¸°ì¥êµ°', 'ê°€í‰êµ°', 'ì¢…ë¡œêµ¬', 
    'ì•ˆë™ì‹œ', 'ì˜ë“±í¬êµ¬', 'ìˆ˜ì›ì‹œ', 'ë¶€ì‚°', 'ê°•ë¦‰', 'ì œì£¼', 'ì„œìš¸', 'ê²½ì£¼', 'ê°€í‰'
]

CATEGORIES = [
    'í•œì‹', 'ì‡¼í•‘', 'ë ˆí¬ì¸ ', 'ìì—°', 'ê´€ê´‘í˜¸í…”', 'íœì…˜', 'í•œì˜¥', 'ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤', 
    'ì¼ì‹', 'ì½˜ë„ë¯¸ë””ì—„', 'ì¹´í˜', 'ëª¨í…”', 'ì¤‘ì‹', 'ìœ ìŠ¤í˜¸ìŠ¤í…”', 'ì–‘ì‹', 'ë§›ì§‘'
]

# ìŒì‹ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¥
FOOD_KEYWORDS = ['ë§›ì§‘', 'ìŒì‹', 'ë ˆìŠ¤í† ë‘', 'ì‹ë‹¹', 'ë¨¹ê±°ë¦¬', 'ìš”ë¦¬', 'ì¹´í˜', 'ë””ì €íŠ¸']

def extract_location_and_category(query: str):
    """ì¿¼ë¦¬ì—ì„œ ì§€ì—­ëª…ê³¼ ì¹´í…Œê³ ë¦¬ë¥¼ ì •í™•íˆ ì¶”ì¶œ"""
    query_lower = query.lower()
    
    found_regions = []
    found_cities = []
    found_categories = []
    
    # ì§€ì—­ ë§¤ì¹­ (ë¶€ë¶„ ë¬¸ìì—´ í¬í•¨)
    for region in REGIONS:
        if region in query or region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '') in query:
            found_regions.append(region)
    
    # ë„ì‹œ ë§¤ì¹­
    for city in CITIES:
        if city in query:
            found_cities.append(city)
    
    # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­
    for category in CATEGORIES:
        if category in query:
            found_categories.append(category)
    
    # ìŒì‹ í‚¤ì›Œë“œ íŠ¹ë³„ ì²˜ë¦¬ - ë” í¬ê´„ì ìœ¼ë¡œ
    if any(word in query for word in FOOD_KEYWORDS):
        found_categories.extend(['í•œì‹', 'ì¼ì‹', 'ì¤‘ì‹', 'ì–‘ì‹'])  # ëª¨ë“  ìŒì‹ ì¹´í…Œê³ ë¦¬ í¬í•¨
    
    return found_regions, found_cities, found_categories

class HybridOptimizedRetriever(BaseRetriever):
    """SQL í•„í„°ë§ + ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°"""
    
    vectorstore: Any = None
    k: int = 10000  # SQL í•„í„°ë§ìœ¼ë¡œ ì¶•ì†Œëœ í›„ë³´êµ°ì—ì„œ ë²¡í„° ê²€ìƒ‰
    score_threshold: float = 0.5
    max_sql_results: int = 5000  # SQL í•„í„°ë§ ìµœëŒ€ ê²°ê³¼ ìˆ˜
    
    def __init__(self, vectorstore, k: int = 10000, score_threshold: float = 0.5, max_sql_results: int = 5000):
        super().__init__(vectorstore=vectorstore, k=k, score_threshold=score_threshold, max_sql_results=max_sql_results)
    
    def _get_relevant_documents(self, query: str) -> List[Document]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: SQL 1ì°¨ í•„í„°ë§ + ë²¡í„° 2ì°¨ ê²€ìƒ‰"""
        try:
            print(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
            
            # 1ë‹¨ê³„: ì§€ì—­/ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
            regions, cities, categories = extract_location_and_category(query)
            print(f"   ì¶”ì¶œëœ ì •ë³´ - ì§€ì—­: {regions}, ë„ì‹œ: {cities}, ì¹´í…Œê³ ë¦¬: {categories}")
            
            # 2ë‹¨ê³„: SQL ê¸°ë°˜ 1ì°¨ í•„í„°ë§
            candidate_docs = self._sql_filter_candidates(query, regions, cities, categories)
            
            if not candidate_docs:
                print("âš ï¸ SQL í•„í„°ë§ ê²°ê³¼ ì—†ìŒ, ìˆœìˆ˜ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ í´ë°±")
                return self._fallback_vector_search(query)
            
            print(f"ğŸ“Š SQL í•„í„°ë§: {len(candidate_docs)}ê°œ í›„ë³´ ë¬¸ì„œ ì„ ë³„")
            
            # 3ë‹¨ê³„: ì„ ë³„ëœ í›„ë³´êµ°ì— ëŒ€í•´ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°
            final_docs = self._vector_search_on_candidates(query, candidate_docs)
            
            print(f"âœ… ìµœì¢… ê²°ê³¼: {len(final_docs)}ê°œ ë¬¸ì„œ (ì„ê³„ê°’ â‰¥{self.score_threshold})")
            return final_docs
            
        except Exception as e:
            print(f"âŒ HybridOptimizedRetriever ì˜¤ë¥˜: {e}")
            return []
    
    def _sql_filter_candidates(self, query: str, regions: List[str], cities: List[str], categories: List[str]) -> List[Document]:
        """SQL ì¿¼ë¦¬ë¡œ í›„ë³´ ë¬¸ì„œë“¤ì„ ë¨¼ì € í•„í„°ë§"""
        try:
            engine = create_engine(CONNECTION_STRING)
            
            # ì¡°ê±´ì´ ì—†ìœ¼ë©´ ìµœê·¼ ë¬¸ì„œë‚˜ ì¸ê¸° ë¬¸ì„œë¡œ ì œí•œ
            if not regions and not cities and not categories:
                # í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
                return self._text_search_fallback(query, engine)
            
            # SQL ì¡°ê±´ êµ¬ì„±
            conditions = []
            
            if regions:
                region_conditions = " OR ".join([f"cmetadata->>'region' ILIKE '%{region}%'" for region in regions])
                conditions.append(f"({region_conditions})")
            
            if cities:
                city_conditions = " OR ".join([f"cmetadata->>'city' ILIKE '%{city}%'" for city in cities])
                conditions.append(f"({city_conditions})")
            
            if categories:
                category_conditions = " OR ".join([f"cmetadata->>'category' ILIKE '%{category}%'" for category in categories])
                conditions.append(f"({category_conditions})")
            
            where_clause = " OR ".join(conditions)
            
            sql_query = f"""
                SELECT document, cmetadata, embedding
                FROM langchain_pg_embedding 
                WHERE {where_clause}
                LIMIT {self.max_sql_results}
            """
            
            print(f"ğŸ—„ï¸ SQL í•„í„°ë§ ì‹¤í–‰...")
            
            with engine.connect() as conn:
                result = conn.execute(text(sql_query))
                rows = result.fetchall()
                
                docs = []
                for row in rows:
                    doc = Document(
                        page_content=row.document,
                        metadata=row.cmetadata or {}
                    )
                    # ì„ë² ë”© ì •ë³´ë„ ì €ì¥ (ë²¡í„° ê²€ìƒ‰ìš©)
                    if row.embedding:
                        doc.metadata['_embedding'] = row.embedding
                    docs.append(doc)
                
                return docs
                
        except Exception as e:
            print(f"âŒ SQL í•„í„°ë§ ì˜¤ë¥˜: {e}")
            return []
    
    def _text_search_fallback(self, query: str, engine) -> List[Document]:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ í´ë°± ê²€ìƒ‰"""
        try:
            # ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ ê²€ìƒ‰
            keywords = query.split()
            text_conditions = []
            
            for keyword in keywords[:3]:  # ìµœëŒ€ 3ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
                if len(keyword) > 1:
                    text_conditions.append(f"document ILIKE '%{keyword}%'")
            
            if not text_conditions:
                return []
            
            text_where = " OR ".join(text_conditions)
            
            sql_query = f"""
                SELECT document, cmetadata, embedding
                FROM langchain_pg_embedding 
                WHERE {text_where}
                LIMIT {self.max_sql_results // 2}
            """
            
            with engine.connect() as conn:
                result = conn.execute(text(sql_query))
                rows = result.fetchall()
                
                docs = []
                for row in rows:
                    doc = Document(
                        page_content=row.document,
                        metadata=row.cmetadata or {}
                    )
                    if row.embedding:
                        doc.metadata['_embedding'] = row.embedding
                    docs.append(doc)
                
                return docs
                
        except Exception as e:
            print(f"âŒ í…ìŠ¤íŠ¸ ê²€ìƒ‰ í´ë°± ì˜¤ë¥˜: {e}")
            return []
    
    def _vector_search_on_candidates(self, query: str, candidate_docs: List[Document]) -> List[Document]:
        """ì„ ë³„ëœ í›„ë³´ ë¬¸ì„œë“¤ì— ëŒ€í•´ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            # í›„ë³´ ë¬¸ì„œë“¤ì„ ì„ì‹œ ë²¡í„°ìŠ¤í† ì–´ë‚˜ ì§ì ‘ ìœ ì‚¬ë„ ê³„ì‚°
            # ì‹¤ì œë¡œëŠ” í›„ë³´ ë¬¸ì„œ IDë“¤ë¡œ ì œí•œëœ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰
            
            # ê°„ë‹¨í•œ êµ¬í˜„: ì „ì²´ ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰í•˜ë˜ ê²°ê³¼ë¥¼ í›„ë³´ì™€ ë§¤ì¹˜
            all_docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=self.k)
            
            # í›„ë³´ ë¬¸ì„œì˜ ë‚´ìš©ìœ¼ë¡œ ë§¤ì¹­ (ì‹¤ì œë¡œëŠ” ID ê¸°ë°˜ ë§¤ì¹­ì´ ë” íš¨ìœ¨ì )
            candidate_contents = {doc.page_content for doc in candidate_docs}
            
            filtered_docs = []
            for doc, score in all_docs_with_scores:
                if doc.page_content in candidate_contents and score >= self.score_threshold:
                    # ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ metadataì— ì¶”ê°€
                    doc.metadata['similarity_score'] = round(score, 3)
                    filtered_docs.append(doc)
                    
                    # ì¶©ë¶„í•œ ê²°ê³¼ë¥¼ ì–»ìœ¼ë©´ ì¤‘ë‹¨ (ì„±ëŠ¥ ìµœì í™”)
                    if len(filtered_docs) >= 50:
                        break
            
            return filtered_docs
            
        except Exception as e:
            print(f"âŒ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return []
    
    def _fallback_vector_search(self, query: str) -> List[Document]:
        """SQL í•„í„°ë§ ì‹¤íŒ¨ì‹œ ìˆœìˆ˜ ë²¡í„° ê²€ìƒ‰"""
        try:
            print("ğŸ§  ìˆœìˆ˜ ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰...")
            docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=min(100, self.k))
            
            filtered_docs = []
            for doc, score in docs_with_scores:
                if score >= self.score_threshold:
                    doc.metadata['similarity_score'] = round(score, 3)
                    filtered_docs.append(doc)
            
            return filtered_docs
            
        except Exception as e:
            print(f"âŒ í´ë°± ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

# í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™” Retriever ìƒì„±
retriever = HybridOptimizedRetriever(vectorstore, k=10000, score_threshold=0.5, max_sql_results=5000)

# =============================================================================
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
# =============================================================================

rag_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì—¬í–‰ ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ì—¬í–‰ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë§ëŠ” ì—¬í–‰ ì¼ì •ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì—¬í–‰ì§€ ì •ë³´:
{context}

ì‚¬ìš©ì ì§ˆë¬¸: {question}

ë‹µë³€ ì§€ì¹¨:
1. ë§Œì•½ ì—¬í–‰ì§€ ì •ë³´ê°€ "NO_RELEVANT_DATA"ë¼ë©´, ë‹¤ìŒê³¼ ê°™ì´ ë‹µë³€í•˜ì„¸ìš”:
   "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  '{question}'ì™€ ê´€ë ¨ëœ ì—¬í–‰ì§€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 
   ë” êµ¬ì²´ì ì¸ ì§€ì—­ëª…ì´ë‚˜ ë‹¤ë¥¸ ì—¬í–‰ì§€ë¡œ ë‹¤ì‹œ ë¬¸ì˜í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."

2. ê´€ë ¨ ì—¬í–‰ì§€ ì •ë³´ê°€ ìˆë‹¤ë©´:
    - ì‹¤ì œ ì œê³µëœ ì—¬í–‰ì§€ ì •ë³´ë§Œì„ í™œìš©í•˜ì„¸ìš”
    - êµ¬ì²´ì ì¸ ì¥ì†Œëª…, ì§€ì—­, ì¹´í…Œê³ ë¦¬ë¥¼ í¬í•¨í•˜ì„¸ìš”
    - ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì¼ì •ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”
    - ì ì‹¬, ì €ë… ì‹œê°„ì„ ìƒê°í•˜ê³  ì‹ì‚¬ë¥¼ í•  ê³³ë„ ë„£ì–´ì£¼ì„¸ìš”
    - ì¹´í…Œê³ ë¦¬ê°€ ë‹¤ë¥´ë”ë¼ë„ ëª…ì†Œë¼ ìƒê°ë˜ë©´ ë‹µë³€í•´ì£¼ì„¸ìš”
    - ì¤‘ë³µëœ ì¶”ì²œì€ ë°˜ë“œì‹œ ì œê±°í•´ì£¼ì„¸ìš”
    - í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš”

ë‹µë³€:
""")

# =============================================================================
# RAG ì²´ì¸ êµ¬ì„±
# =============================================================================

def format_docs(docs):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ… (ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨)"""
    if not docs:
        return "NO_RELEVANT_DATA"  # ê´€ë ¨ ë°ì´í„° ì—†ìŒì„ ë‚˜íƒ€ë‚´ëŠ” íŠ¹ë³„í•œ ë§ˆì»¤
    
    formatted_docs = []
    for i, doc in enumerate(docs, 1):
        # ìœ ì‚¬ë„ ì ìˆ˜ ì¶”ì¶œ
        similarity_score = doc.metadata.get('similarity_score', 'N/A')
        content = f"[ì—¬í–‰ì§€ {i}] (ìœ ì‚¬ë„: {similarity_score})\n{doc.page_content}"
        
        if doc.metadata:
            meta_info = []
            for key, value in doc.metadata.items():
                if value and key not in ['original_id', 'similarity_score', '_embedding']:  # ë‚´ë¶€ í‚¤ ì œì™¸
                    meta_info.append(f"{key}: {value}")
            if meta_info:
                content += f"\n({', '.join(meta_info)})"
        formatted_docs.append(content)
    
    return "\n\n".join(formatted_docs)

# RAG íŒŒì´í”„ë¼ì¸ êµ¬ì„±
rag_chain = (
    {
        "context": retriever | format_docs, 
        "question": RunnablePassthrough()
    }
    | rag_prompt
    | llm
    | StrOutputParser()
)

# =============================================================================
# ì£¼ìš” ê¸°ëŠ¥ í•¨ìˆ˜ë“¤
# =============================================================================

def search_places(query):
    """ì—¬í–‰ì§€ ê²€ìƒ‰ í•¨ìˆ˜ (í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™”)"""
    try:
        print(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: '{query}'")
        
        # HybridOptimizedRetriever ì§ì ‘ ì‚¬ìš©
        docs = retriever._get_relevant_documents(query)
        
        return docs
        
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

def get_travel_recommendation(query, stream=True):
    """ì—¬í–‰ ì¶”ì²œ ìƒì„± í•¨ìˆ˜ (ìŠ¤íŠ¸ë¦¼ ì§€ì›)"""
    try:
        print(f"ğŸ“ ì—¬í–‰ ì¶”ì²œ ìš”ì²­: '{query}'")
        print("ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘...")
        
        if stream:
            return get_travel_recommendation_stream(query)
        else:
            # ê¸°ì¡´ ë°©ì‹
            response = rag_chain.invoke(query)
            print("âœ… ì—¬í–‰ ì¶”ì²œ ì™„ë£Œ!")
            return response
        
    except Exception as e:
        print(f"âŒ ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì—¬í–‰ ì¶”ì²œì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def get_travel_recommendation_stream(query):
    """ìŠ¤íŠ¸ë¦¼ ë°©ì‹ ì—¬í–‰ ì¶”ì²œ ìƒì„± (Amazon Bedrock ì§€ì›)"""
    try:
        # ê²€ìƒ‰ ì‹¤í–‰
        docs = retriever._get_relevant_documents(query)
        context = format_docs(docs)
        
        # í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        prompt_value = rag_prompt.invoke({"context": context, "question": query})
        
        print("ğŸ¤– Amazon Bedrock Claude ë‹µë³€ ìƒì„± ì¤‘...")
        print("â”€" * 40)
        
        # ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë‹µë³€ ìƒì„±
        full_response = ""
        for chunk in llm.stream(prompt_value):
            if hasattr(chunk, 'content'):
                content = chunk.content
            else:
                content = str(chunk)
            
            if content:
                print(content, end='', flush=True)
                full_response += content
        
        print("\n" + "â”€" * 40)
        print("âœ… ì—¬í–‰ ì¶”ì²œ ì™„ë£Œ!")
        
        return full_response
        
    except Exception as e:
        print(f"âŒ ìŠ¤íŠ¸ë¦¼ ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì—¬í–‰ ì¶”ì²œì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def interactive_mode():
    """ëŒ€í™”í˜• ëª¨ë“œ"""
    print("\n" + "="*60)
    print("ğŸŒŸ í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™” ì—¬í–‰ ì¶”ì²œ RAG ì‹œìŠ¤í…œ (Amazon Bedrock)")
    print("="*60)
    print("ì‚¬ìš©ë²•: ì—¬í–‰ ì§€ì—­ê³¼ ê¸°ê°„ì„ ì…ë ¥í•˜ì„¸ìš”")
    print("ì˜ˆì‹œ: 'ë¶€ì‚° 2ë°• 3ì¼ ì—¬í–‰ ì¶”ì²œ', 'ì œì£¼ë„ ë§›ì§‘ ì¶”ì²œ'")
    print("íŠ¹ì§•: SQL í•„í„°ë§ + ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ ê³ ì† ê²€ìƒ‰")
    print("AI ëª¨ë¸: Amazon Bedrock Claude")
    print("ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit' ì…ë ¥")
    print("-"*60)
    
    while True:
        try:
            user_input = input("\nğŸ’¬ ì—¬í–‰ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                print("ğŸ‘‹ ì—¬í–‰ ì¶”ì²œ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤!")
                break
                
            if not user_input:
                print("âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            
            print("\n" + "-"*40)
            get_travel_recommendation(user_input, stream=True)
            print("-"*40)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì—¬í–‰ ì¶”ì²œ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤!")
            break
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

# =============================================================================
# ë©”ì¸ ì‹¤í–‰ë¶€
# =============================================================================

if __name__ == "__main__":
    # AWS ìê²© ì¦ëª… í™•ì¸
    if not AWS_ACCESS_KEY_ID or not AWS_SECRET_ACCESS_KEY:
        print("âš ï¸ ê²½ê³ : AWS ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("í™˜ê²½ë³€ìˆ˜ AWS_ACCESS_KEY_IDì™€ AWS_SECRET_ACCESS_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜")
        print("AWS CLIë¡œ ìê²© ì¦ëª…ì„ êµ¬ì„±í•´ì£¼ì„¸ìš”.")
        print("ìì„¸í•œ ë‚´ìš©: https://docs.aws.amazon.com/cli/latest/userguide/getting-started-quickstart.html")
        sys.exit(1)
    
    print("\nğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™” RAG ì‹œìŠ¤í…œ (Amazon Bedrock) ì´ˆê¸°í™” ì™„ë£Œ!")
    print("ğŸ“Š íŠ¹ì§•: SQL 1ì°¨ í•„í„°ë§ + ë²¡í„° 2ì°¨ ê²€ìƒ‰ìœ¼ë¡œ ê³ ì† ì •í™• ê²€ìƒ‰")
    print("ğŸ¤– AI ëª¨ë¸: Amazon Bedrock Claude")
    
    try:
        interactive_mode()
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

# =============================================================================
# ì„¤ì¹˜ ë° ì„¤ì • ê°€ì´ë“œ
# =============================================================================

"""
Amazon Bedrock ì‚¬ìš©ì„ ìœ„í•œ ì„¤ì • ê°€ì´ë“œ:

1. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜:
   pip install boto3 langchain-aws

2. AWS ìê²© ì¦ëª… ì„¤ì •:
   ë°©ë²• 1: í™˜ê²½ë³€ìˆ˜ ì„¤ì •
   export AWS_ACCESS_KEY_ID="your-access-key"
   export AWS_SECRET_ACCESS_KEY="your-secret-key"
   
   ë°©ë²• 2: AWS CLI ì„¤ì •
   aws configure
   
   ë°©ë²• 3: IAM Role (EC2ì—ì„œ ì‹¤í–‰ ì‹œ)

3. Amazon Bedrock ëª¨ë¸ ì•¡ì„¸ìŠ¤ ê¶Œí•œ:
   - AWS ì½˜ì†”ì—ì„œ Bedrock ì„œë¹„ìŠ¤ë¡œ ì´ë™
   - Model access ë©”ë‰´ì—ì„œ ì›í•˜ëŠ” ëª¨ë¸ ì•¡ì„¸ìŠ¤ ìš”ì²­
   - Claude ëª¨ë¸: Anthropic Claude v2, Claude 3 Haiku, Claude 3 Sonnet ë“±

4. ì§€ì›ë˜ëŠ” ë¦¬ì „:
   - us-east-1 (ë²„ì§€ë‹ˆì•„ ë¶ë¶€)
   - us-west-2 (ì˜¤ë ˆê³¤)
   - ap-southeast-1 (ì‹±ê°€í¬ë¥´)
   ë“± (ìµœì‹  ì •ë³´ëŠ” AWS ë¬¸ì„œ í™•ì¸)

5. ë¹„ìš© ì£¼ì˜ì‚¬í•­:
   - Bedrockì€ ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ê³¼ê¸ˆ
   - ì…ë ¥/ì¶œë ¥ í† í° ìˆ˜ì— ë”°ë¼ ë¹„ìš© ë°œìƒ
   - ëª¨ë¸ë³„ë¡œ ê°€ê²©ì´ ë‹¤ë¦„ (Claude 3 Haiku < Sonnet < Opus)

ì‚¬ìš© ì˜ˆì‹œ:
python sample.py
"""