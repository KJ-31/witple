"""
í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìµœì í™” RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œ
PostgreSQL + PGVector + LangChain + Amazon Bedrock ê¸°ë°˜

ì‘ì„±ì¼: 2025ë…„
ëª©ì : SQL í•„í„°ë§ + ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ ê³ ì„±ëŠ¥ ì—¬í–‰ì§€ ì¶”ì²œ ì‹œìŠ¤í…œ (Amazon Bedrock ë²„ì „)
"""

import boto3
from langchain_aws import ChatBedrock
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_postgres import PGVector
from langchain_core.runnables import RunnablePassthrough
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.retrievers import BaseRetriever
from langchain_core.documents import Document
from typing import List, Any, Literal, TypedDict, Sequence, Optional
from sqlalchemy import create_engine, text
from database import engine as shared_engine
from cache_utils import RedisCache
import sys
import os
import json
import re
import requests
import datetime
import hashlib
import redis
from functools import wraps

# AWS ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” AWS CLI ì„¤ì • ì‚¬ìš©)
AWS_REGION = os.getenv('AWS_REGION')  # Bedrockì´ ì§€ì›ë˜ëŠ” ë¦¬ì „ (ì„œìš¸)
AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')
AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')

# AWS ì„¸ì…˜ ìƒì„±
try:
    boto3_session = boto3.Session(
        aws_access_key_id=AWS_ACCESS_KEY_ID,
        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
        region_name=AWS_REGION
    )
except Exception as e:
    print(f"âš ï¸ AWS ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
    boto3_session = None

# # ì„¤ì • ë° ì´ˆê¸°í™”
# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì • (Redis ìš°ì„ , PGVector í´ë°±)
DB_ENABLED = True  # Redis ìºì‹œ ìš°ì„  + PGVector í´ë°±

# Redis ìºì‹± ì„¤ì •
print("ğŸ”— Redis ìºì‹± ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
redis_available = False
try:
    # í™˜ê²½ë³€ìˆ˜ ì§ì ‘ ì‚¬ìš© + ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”
    redis_url = os.getenv('REDIS_URL')
    redis_client = redis.Redis.from_url(
        redis_url,
        decode_responses=True,
        socket_timeout=5,
        socket_connect_timeout=5,
        retry_on_timeout=True
    )
    # ì—°ê²° í…ŒìŠ¤íŠ¸
    redis_client.ping()
    redis_available = True
    print("âœ… Redis ì—°ê²° ì„±ê³µ!")
except Exception as e:
    print(f"âš ï¸ Redis ì—°ê²° ì‹¤íŒ¨: {e}")
    redis_client = None
    redis_available = False

class LLMCache:
    """LLM ì‘ë‹µ ì „ìš© ìºì‹± ì‹œìŠ¤í…œ"""

    def __init__(self, redis_client=None):
        self.redis = redis_client
        self.enabled = redis_client is not None
        print(f"ğŸ§  LLM ìºì‹œ {'í™œì„±í™”' if self.enabled else 'ë¹„í™œì„±í™”'}")

    def _generate_cache_key(self, query: str, cache_type: str = "response") -> str:
        """ì¿¼ë¦¬ ê¸°ë°˜ ìºì‹œ í‚¤ ìƒì„±"""
        # ì¿¼ë¦¬ ì •ê·œí™” (ê³µë°±, ëŒ€ì†Œë¬¸ì, íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬)
        normalized_query = re.sub(r'\s+', ' ', query.strip().lower())
        normalized_query = re.sub(r'[^\w\sê°€-í£]', '', normalized_query)

        # í•´ì‹œ ìƒì„±
        query_hash = hashlib.md5(normalized_query.encode('utf-8')).hexdigest()[:12]
        return f"llm:{cache_type}:{query_hash}"

    def get_cached_response(self, query: str) -> Optional[str]:
        """ìºì‹œëœ LLM ì‘ë‹µ ì¡°íšŒ"""
        if not self.enabled:
            return None

        try:
            cache_key = self._generate_cache_key(query)
            cached_data = self.redis.get(cache_key)

            if cached_data:
                print(f"ğŸ¯ ìºì‹œ íˆíŠ¸: {cache_key}")
                return cached_data
            else:
                print(f"âŒ ìºì‹œ ë¯¸ìŠ¤: {cache_key}")
                return None

        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None

    def cache_response(self, query: str, response: str, expire: int = 3600) -> bool:
        """LLM ì‘ë‹µ ìºì‹± (1ì‹œê°„ ê¸°ë³¸)"""
        if not self.enabled or not response:
            return False

        try:
            cache_key = self._generate_cache_key(query)
            success = self.redis.set(cache_key, response, ex=expire)

            if success:
                print(f"ğŸ’¾ ì‘ë‹µ ìºì‹œ ì €ì¥: {cache_key}")

            return success

        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False

    def cache_search_results(self, query: str, docs: List[Document], expire: int = 1800) -> bool:
        """ê²€ìƒ‰ ê²°ê³¼ ìºì‹± (30ë¶„)"""
        if not self.enabled:
            return False

        try:
            cache_key = self._generate_cache_key(query, "search")

            # Document ê°ì²´ë¥¼ ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
            serializable_docs = []
            for doc in docs:
                serializable_docs.append({
                    'page_content': doc.page_content,
                    'metadata': doc.metadata
                })

            docs_json = json.dumps(serializable_docs, ensure_ascii=False)
            success = self.redis.set(cache_key, docs_json, ex=expire)

            if success:
                print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼ ìºì‹œ ì €ì¥: {cache_key}")

            return success

        except Exception as e:
            print(f"âš ï¸ ê²€ìƒ‰ ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {e}")
            return False

    def get_cached_search_results(self, query: str) -> Optional[List[Document]]:
        """ìºì‹œëœ ê²€ìƒ‰ ê²°ê³¼ ì¡°íšŒ"""
        if not self.enabled:
            return None

        try:
            cache_key = self._generate_cache_key(query, "search")
            cached_data = self.redis.get(cache_key)

            if cached_data:
                print(f"ğŸ” ê²€ìƒ‰ ìºì‹œ íˆíŠ¸: {cache_key}")

                # JSONì„ Document ê°ì²´ë¡œ ë³µì›
                docs_data = json.loads(cached_data)
                docs = []
                for doc_data in docs_data:
                    doc = Document(
                        page_content=doc_data['page_content'],
                        metadata=doc_data['metadata']
                    )
                    docs.append(doc)

                return docs

            return None

        except Exception as e:
            print(f"âš ï¸ ê²€ìƒ‰ ìºì‹œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None

    def get_cache_stats(self) -> dict:
        """ìºì‹œ í†µê³„ ì¡°íšŒ"""
        if not self.enabled:
            return {"enabled": False}

        try:
            # Redis INFO ëª…ë ¹ìœ¼ë¡œ í†µê³„ ì¡°íšŒ
            info = self.redis.info()

            # LLM ê´€ë ¨ í‚¤ ê°œìˆ˜ ì¡°íšŒ
            llm_keys = self.redis.keys("llm:*")

            return {
                "enabled": True,
                "total_keys": len(llm_keys),
                "memory_usage": info.get('used_memory_human', 'N/A'),
                "connected_clients": info.get('connected_clients', 0),
                "cache_hit_ratio": "ì¶”í›„ êµ¬í˜„"  # ë³„ë„ ëª¨ë‹ˆí„°ë§ í•„ìš”
            }

        except Exception as e:
            return {"enabled": True, "error": str(e)}

    def preload_region_documents(self, region: str, expire: int = 7200) -> bool:
        """ì§€ì—­ë³„ ë¬¸ì„œ ì‚¬ì „ ë¡œë”© (2ì‹œê°„ ìºì‹œ)"""
        if not self.enabled:
            return False

        try:
            cache_key = f"llm:region:{region}"

            # ì´ë¯¸ ìºì‹œë˜ì–´ ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
            if self.redis.exists(cache_key):
                print(f"ğŸ“¦ ì§€ì—­ ìºì‹œ ì¡´ì¬: {region}")
                return True

            # DBì—ì„œ í•´ë‹¹ ì§€ì—­ì˜ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ
            engine = shared_engine
            with engine.connect() as conn:
                query = text("""
                    SELECT document, cmetadata
                    FROM langchain_pg_embedding
                    WHERE cmetadata->>'region' = :region
                    LIMIT 500
                """)
                result = conn.execute(query, {"region": region})

                documents = []
                for row in result:
                    documents.append({
                        'page_content': row.document,
                        'metadata': json.loads(row.cmetadata) if row.cmetadata else {}
                    })

                if documents:
                    docs_json = json.dumps(documents, ensure_ascii=False)
                    success = self.redis.set(cache_key, docs_json, ex=expire)
                    print(f"ğŸ—ï¸ ì§€ì—­ ìºì‹œ ìƒì„±: {region} ({len(documents)}ê°œ ë¬¸ì„œ)")
                    return success

        except Exception as e:
            print(f"âš ï¸ ì§€ì—­ ìºì‹œ ì˜¤ë¥˜: {e}")
            return False

    def get_region_documents(self, region: str) -> List[Document]:
        """ì§€ì—­ë³„ ìºì‹œëœ ë¬¸ì„œ ì¡°íšŒ"""
        if not self.enabled:
            return []

        try:
            cache_key = f"llm:region:{region}"
            cached_data = self.redis.get(cache_key)

            if cached_data:
                print(f"ğŸ¯ ì§€ì—­ ìºì‹œ íˆíŠ¸: {region}")
                docs_data = json.loads(cached_data)
                return [Document(page_content=doc['page_content'], metadata=doc['metadata'])
                       for doc in docs_data]

        except Exception as e:
            print(f"âš ï¸ ì§€ì—­ ìºì‹œ ì¡°íšŒ ì˜¤ë¥˜: {e}")

        return []

    def preload_popular_documents(self, expire: int = 3600) -> bool:
        """ì¸ê¸° ë¬¸ì„œ ì‚¬ì „ ë¡œë”© (1ì‹œê°„ ìºì‹œ)"""
        if not self.enabled:
            return False

        try:
            cache_key = "llm:hot:popular"

            if self.redis.exists(cache_key):
                print("ğŸ“¦ ì¸ê¸° ë¬¸ì„œ ìºì‹œ ì¡´ì¬")
                return True

            # ì¸ê¸° ë¬¸ì„œ ì¡°íšŒ (ì¡°íšŒìˆ˜, ì¶”ì²œìˆ˜ ê¸°ë°˜)
            engine = shared_engine
            with engine.connect() as conn:
                query = text("""
                    SELECT document, cmetadata
                    FROM langchain_pg_embedding
                    ORDER BY (cmetadata->>'view_count')::int DESC NULLS LAST
                    LIMIT 100
                """)
                result = conn.execute(query)

                documents = []
                for row in result:
                    documents.append({
                        'page_content': row.document,
                        'metadata': json.loads(row.cmetadata) if row.cmetadata else {}
                    })

                if documents:
                    docs_json = json.dumps(documents, ensure_ascii=False)
                    success = self.redis.set(cache_key, docs_json, ex=expire)
                    print(f"ğŸ”¥ ì¸ê¸° ë¬¸ì„œ ìºì‹œ ìƒì„±: {len(documents)}ê°œ")
                    return success

        except Exception as e:
            print(f"âš ï¸ ì¸ê¸° ë¬¸ì„œ ìºì‹œ ì˜¤ë¥˜: {e}")
            return False

# ì „ì—­ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
llm_cache = LLMCache(redis_client if redis_available else None)

# LLM ëª¨ë¸ ì„¤ì • (Amazon Bedrock - Claude)
print("ğŸ¤– Amazon Bedrock Claude ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
try:
    llm = ChatBedrock(
        model_id="anthropic.claude-3-haiku-20240307-v1:0",      # Claude 3 Haiku
        # model_id="anthropic.claude-3-sonnet-20240229-v1:0",   # Claude 3 Sonnet
        # model_id="anthropic.claude-sonnet-4-20250514-v1:0",   # Claude 4 Sonnet
        region_name=AWS_REGION,
        credentials_profile_name=None,  # ê¸°ë³¸ ìê²©ì¦ëª… ì‚¬ìš©
        model_kwargs={
            "temperature": 0.3,         # ì•½ê°„ ë†’ì—¬ì„œ ë¹ ë¥¸ ì‘ë‹µ (0.2 â†’ 0.3)
            "max_tokens": 3000,         # í† í° ìˆ˜ ì¤„ì—¬ì„œ ì†ë„ í–¥ìƒ (4000 â†’ 2000)
            "top_p": 0.8,               # ë” ì œí•œì ìœ¼ë¡œ ì„ íƒí•´ì„œ ì†ë„ í–¥ìƒ
        }
    )
except Exception as e:
    print(f"âŒ Bedrock LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    print("í™˜ê²½ë³€ìˆ˜ë‚˜ AWS CLI ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

# ì„ë² ë”© ëª¨ë¸ ì„¤ì • - ì•ˆì •ì ì¸ sentence-transformers ëª¨ë¸ ì‚¬ìš©
print("ğŸ§  Sentence Transformers ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
embeddings = HuggingFaceEmbeddings(
    model_name='sentence-transformers/all-MiniLM-L12-v2',
)



# # ë²¡í„°ìŠ¤í† ì–´ ì—°ê²° (Redis ìºì‹œ ìš°ì„  ì‚¬ìš©ìœ¼ë¡œ ë¹„í™œì„±í™”)

print("ğŸ¯ Redis ìºì‹œ ìš°ì„  + PGVector í´ë°± ëª¨ë“œ")
vectorstore = None
if DB_ENABLED:
    try:
        print("ğŸ”— ë²¡í„°ìŠ¤í† ì–´ ì—°ê²° ì¤‘...")
        vectorstore = PGVector(
            embeddings=embeddings,
            collection_name="place_recommendations",
            connection=os.getenv('DATABASE_URL'),
            pre_delete_collection=False,
        )
        print("âœ… ë²¡í„°ìŠ¤í† ì–´ ì—°ê²° ì™„ë£Œ (Redis ìš°ì„ , PGVector í´ë°±)")
    except Exception as e:
        print(f"âš ï¸ ë²¡í„°ìŠ¤í† ì–´ ì—°ê²° ì‹¤íŒ¨: {e}")
        print("ğŸ“¢ Redis ìºì‹œ ì „ìš© ëª¨ë“œë¡œ ë™ì‘")
        vectorstore = None

# # ì§€ì—­ ë° í‚¤ì›Œë“œ ì¸ì‹ ì‹œìŠ¤í…œ

# ì§€ì—­ ë° í‚¤ì›Œë“œ ë°ì´í„° (ì‹¤ì œ DB ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
REGIONS = [
    'ê²½ê¸°ë„', 'ì„œìš¸íŠ¹ë³„ì‹œ', 'ê°•ì›íŠ¹ë³„ìì¹˜ë„', 'ê²½ìƒë‚¨ë„', 'ê²½ìƒë¶ë„', 'ì „ë¼ë‚¨ë„', 
    'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ì¶©ì²­ë‚¨ë„', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„', 'ì¸ì²œê´‘ì—­ì‹œ', 'ì „ë¶íŠ¹ë³„ìì¹˜ë„', 
    'ì¶©ì²­ë¶ë„', 'ëŒ€êµ¬ê´‘ì—­ì‹œ', 'ê´‘ì£¼ê´‘ì—­ì‹œ', 'ëŒ€ì „ê´‘ì—­ì‹œ', 'ìš¸ì‚°ê´‘ì—­ì‹œ', 'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ'
]

CITIES = [
    'ì¤‘êµ¬', 'í‰ì°½êµ°', 'ê°•ë‚¨êµ¬', 'ì„œê·€í¬ì‹œ', 'ê°•ë¦‰ì‹œ', 'ì œì£¼ì‹œ', 'ê³ ì–‘ì‹œ', 'ìš©ì¸ì‹œ', 
    'ì„œêµ¬', 'íŒŒì£¼ì‹œ', 'ì•ˆì–‘ì‹œ', 'êµ¬ë¡œêµ¬', 'ê²½ì£¼ì‹œ', 'ê¸°ì¥êµ°', 'ê°€í‰êµ°', 'ì¢…ë¡œêµ¬', 
    'ì•ˆë™ì‹œ', 'ì˜ë“±í¬êµ¬', 'ìˆ˜ì›ì‹œ', 'ë¶€ì‚°', 'ê°•ë¦‰', 'ì œì£¼', 'ì„œìš¸', 'ê²½ì£¼', 'ê°€í‰'
]

CATEGORIES = [
    'í•œì‹', 'ì‡¼í•‘', 'ë ˆí¬ì¸ ', 'ìì—°', 'ê´€ê´‘í˜¸í…”', 'íœì…˜', 'í•œì˜¥', 'ê²ŒìŠ¤íŠ¸í•˜ìš°ìŠ¤', 
    'ì¼ì‹', 'ì½˜ë„ë¯¸ë””ì—„', 'ì¹´í˜', 'ëª¨í…”', 'ì¤‘ì‹', 'ìœ ìŠ¤í˜¸ìŠ¤í…”', 'ì–‘ì‹', 'ë§›ì§‘'
]

# ìŒì‹ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¥
FOOD_KEYWORDS = ['ë§›ì§‘', 'ìŒì‹', 'ë ˆìŠ¤í† ë‘', 'ì‹ë‹¹', 'ë¨¹ê±°ë¦¬', 'ìš”ë¦¬', 'ì¹´í˜', 'ë””ì €íŠ¸']

def extract_location_and_category(query: str):
    """ì¿¼ë¦¬ì—ì„œ ì§€ì—­ëª…ê³¼ ì¹´í…Œê³ ë¦¬ë¥¼ ì •í™•íˆ ì¶”ì¶œ"""
    query_lower = query.lower()
    
    found_regions = []
    found_cities = []
    found_categories = []
    
    # ë„ì‹œ-ì§€ì—­ ë§¤í•‘
    CITY_TO_REGION = {
        'ê°•ë¦‰': 'ê°•ì›íŠ¹ë³„ìì¹˜ë„', 'ê°•ë¦‰ì‹œ': 'ê°•ì›íŠ¹ë³„ìì¹˜ë„', 
        'í‰ì°½êµ°': 'ê°•ì›íŠ¹ë³„ìì¹˜ë„',
        'ë¶€ì‚°': 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ê¸°ì¥êµ°': 'ë¶€ì‚°ê´‘ì—­ì‹œ',
        'ì„œìš¸': 'ì„œìš¸íŠ¹ë³„ì‹œ', 'ê°•ë‚¨êµ¬': 'ì„œìš¸íŠ¹ë³„ì‹œ', 'ì¢…ë¡œêµ¬': 'ì„œìš¸íŠ¹ë³„ì‹œ', 'ì˜ë“±í¬êµ¬': 'ì„œìš¸íŠ¹ë³„ì‹œ',
        'ì œì£¼': 'ì œì£¼íŠ¹ë³„ìì¹˜ë„', 'ì œì£¼ì‹œ': 'ì œì£¼íŠ¹ë³„ìì¹˜ë„', 'ì„œê·€í¬ì‹œ': 'ì œì£¼íŠ¹ë³„ìì¹˜ë„',
        'ìˆ˜ì›ì‹œ': 'ê²½ê¸°ë„', 'ê³ ì–‘ì‹œ': 'ê²½ê¸°ë„', 'ìš©ì¸ì‹œ': 'ê²½ê¸°ë„', 'íŒŒì£¼ì‹œ': 'ê²½ê¸°ë„', 'ì•ˆì–‘ì‹œ': 'ê²½ê¸°ë„', 'ê°€í‰êµ°': 'ê²½ê¸°ë„', 'ê°€í‰': 'ê²½ê¸°ë„',
        'ê²½ì£¼': 'ê²½ìƒë¶ë„', 'ê²½ì£¼ì‹œ': 'ê²½ìƒë¶ë„', 'ì•ˆë™ì‹œ': 'ê²½ìƒë¶ë„',
    }
    
    # ì§€ì—­ ë§¤ì¹­ (ë¶€ë¶„ ë¬¸ìì—´ í¬í•¨)
    for region in REGIONS:
        if region in query or region.replace('íŠ¹ë³„ì‹œ', '').replace('ê´‘ì—­ì‹œ', '').replace('íŠ¹ë³„ìì¹˜ë„', '').replace('ë„', '') in query:
            found_regions.append(region)
    
    # ë„ì‹œ ë§¤ì¹­
    for city in CITIES:
        if city in query:
            found_cities.append(city)
            # ë„ì‹œì— í•´ë‹¹í•˜ëŠ” ì§€ì—­ë„ ìë™ ì¶”ê°€
            if city in CITY_TO_REGION and CITY_TO_REGION[city] not in found_regions:
                found_regions.append(CITY_TO_REGION[city])
    
    # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­
    for category in CATEGORIES:
        if category in query:
            found_categories.append(category)
    
    # ìŒì‹ í‚¤ì›Œë“œ íŠ¹ë³„ ì²˜ë¦¬ - ë” í¬ê´„ì ìœ¼ë¡œ
    if any(word in query for word in FOOD_KEYWORDS):
        found_categories.extend(['í•œì‹', 'ì¼ì‹', 'ì¤‘ì‹', 'ì–‘ì‹'])  # ëª¨ë“  ìŒì‹ ì¹´í…Œê³ ë¦¬ í¬í•¨
    
    return found_regions, found_cities, found_categories

class HybridOptimizedRetriever(BaseRetriever):
    """SQL í•„í„°ë§ + ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ê¸°"""
    
    vectorstore: Any = None
    k: int = 10000  # SQL í•„í„°ë§ìœ¼ë¡œ ì¶•ì†Œëœ í›„ë³´êµ°ì—ì„œ ë²¡í„° ê²€ìƒ‰
    score_threshold: float = 0.5
    max_sql_results: int = 5000  # SQL í•„í„°ë§ ìµœëŒ€ ê²°ê³¼ ìˆ˜
    
    def __init__(self, vectorstore, k: int = 10000, score_threshold: float = 0.5, max_sql_results: int = 5000):
        super().__init__(vectorstore=vectorstore, k=k, score_threshold=score_threshold, max_sql_results=max_sql_results)
    
    def _get_relevant_documents(self, query: str) -> List[Document]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: SQL 1ì°¨ í•„í„°ë§ + ë²¡í„° 2ì°¨ ê²€ìƒ‰"""
        try:
            print(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'")
            
            # 1ë‹¨ê³„: ì§€ì—­/ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
            regions, cities, categories = extract_location_and_category(query)
            print(f"   ì¶”ì¶œëœ ì •ë³´ - ì§€ì—­: {regions}, ë„ì‹œ: {cities}, ì¹´í…Œê³ ë¦¬: {categories}")
            
            # 2ë‹¨ê³„: SQL ê¸°ë°˜ 1ì°¨ í•„í„°ë§
            candidate_docs = self._sql_filter_candidates(query, regions, cities, categories)
            
            if not candidate_docs:
                print("âš ï¸ SQL í•„í„°ë§ ê²°ê³¼ ì—†ìŒ, ìˆœìˆ˜ ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ í´ë°±")
                return self._fallback_vector_search(query)
            
            print(f"ğŸ“Š SQL í•„í„°ë§: {len(candidate_docs)}ê°œ í›„ë³´ ë¬¸ì„œ ì„ ë³„")
            
            # 3ë‹¨ê³„: ì„ ë³„ëœ í›„ë³´êµ°ì— ëŒ€í•´ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°
            final_docs = self._vector_search_on_candidates(query, candidate_docs)
            
            print(f"âœ… ìµœì¢… ê²°ê³¼: {len(final_docs)}ê°œ ë¬¸ì„œ (ì„ê³„ê°’ â‰¥{self.score_threshold})")
            return final_docs
            
        except Exception as e:
            print(f"âŒ HybridOptimizedRetriever ì˜¤ë¥˜: {e}")
            return []
    
    def _sql_filter_candidates(self, query: str, regions: List[str], cities: List[str], categories: List[str]) -> List[Document]:
        """SQL ì¿¼ë¦¬ë¡œ í›„ë³´ ë¬¸ì„œë“¤ì„ ë¨¼ì € í•„í„°ë§"""
        try:
            engine = shared_engine
            
            # ì¡°ê±´ì´ ì—†ìœ¼ë©´ ìµœê·¼ ë¬¸ì„œë‚˜ ì¸ê¸° ë¬¸ì„œë¡œ ì œí•œ
            if not regions and not cities and not categories:
                # í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
                return self._text_search_fallback(query, engine)
            
            # SQL ì¡°ê±´ êµ¬ì„±
            conditions = []
            
            if regions:
                region_conditions = " OR ".join([f"cmetadata->>'region' ILIKE '%{region}%'" for region in regions])
                conditions.append(f"({region_conditions})")
            
            if cities:
                city_conditions = " OR ".join([f"cmetadata->>'city' ILIKE '%{city}%'" for city in cities])
                conditions.append(f"({city_conditions})")
            
            if categories:
                category_conditions = " OR ".join([f"cmetadata->>'category' ILIKE '%{category}%'" for category in categories])
                conditions.append(f"({category_conditions})")
            
            where_clause = " OR ".join(conditions)
            
            sql_query = f"""
                SELECT document, cmetadata, embedding
                FROM langchain_pg_embedding 
                WHERE {where_clause}
                LIMIT {self.max_sql_results}
            """
            
            print(f"ğŸ—„ï¸ SQL í•„í„°ë§ ì‹¤í–‰...")
            
            with engine.connect() as conn:
                result = conn.execute(text(sql_query))
                rows = result.fetchall()
                
                docs = []
                for row in rows:
                    doc = Document(
                        page_content=row.document,
                        metadata=row.cmetadata or {}
                    )
                    # ì„ë² ë”© ì •ë³´ë„ ì €ì¥ (ë²¡í„° ê²€ìƒ‰ìš©)
                    if row.embedding:
                        doc.metadata['_embedding'] = row.embedding
                    docs.append(doc)
                
                return docs
                
        except Exception as e:
            print(f"âŒ SQL í•„í„°ë§ ì˜¤ë¥˜: {e}")
            return []
    
    def _text_search_fallback(self, query: str, engine) -> List[Document]:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ í´ë°± ê²€ìƒ‰"""
        try:
            # ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ ê²€ìƒ‰
            keywords = query.split()
            text_conditions = []
            
            for keyword in keywords[:3]:  # ìµœëŒ€ 3ê°œ í‚¤ì›Œë“œë§Œ ì‚¬ìš©
                if len(keyword) > 1:
                    text_conditions.append(f"document ILIKE '%{keyword}%'")
            
            if not text_conditions:
                return []
            
            text_where = " OR ".join(text_conditions)
            
            sql_query = f"""
                SELECT document, cmetadata, embedding
                FROM langchain_pg_embedding 
                WHERE {text_where}
                LIMIT {self.max_sql_results // 2}
            """
            
            with engine.connect() as conn:
                result = conn.execute(text(sql_query))
                rows = result.fetchall()
                
                docs = []
                for row in rows:
                    doc = Document(
                        page_content=row.document,
                        metadata=row.cmetadata or {}
                    )
                    if row.embedding:
                        doc.metadata['_embedding'] = row.embedding
                    docs.append(doc)
                
                return docs
                
        except Exception as e:
            print(f"âŒ í…ìŠ¤íŠ¸ ê²€ìƒ‰ í´ë°± ì˜¤ë¥˜: {e}")
            return []
    
    def _vector_search_on_candidates(self, query: str, candidate_docs: List[Document]) -> List[Document]:
        """ì„ ë³„ëœ í›„ë³´ ë¬¸ì„œë“¤ì— ëŒ€í•´ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚°"""
        try:
            # í›„ë³´ ë¬¸ì„œë“¤ì„ ì„ì‹œ ë²¡í„°ìŠ¤í† ì–´ë‚˜ ì§ì ‘ ìœ ì‚¬ë„ ê³„ì‚°
            # ì‹¤ì œë¡œëŠ” í›„ë³´ ë¬¸ì„œ IDë“¤ë¡œ ì œí•œëœ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰
            
            # ê°„ë‹¨í•œ êµ¬í˜„: ì „ì²´ ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰í•˜ë˜ ê²°ê³¼ë¥¼ í›„ë³´ì™€ ë§¤ì¹˜
            all_docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=self.k)
            
            # í›„ë³´ ë¬¸ì„œì˜ ë‚´ìš©ìœ¼ë¡œ ë§¤ì¹­ (ì‹¤ì œë¡œëŠ” ID ê¸°ë°˜ ë§¤ì¹­ì´ ë” íš¨ìœ¨ì )
            candidate_contents = {doc.page_content for doc in candidate_docs}
            
            filtered_docs = []
            for doc, score in all_docs_with_scores:
                if doc.page_content in candidate_contents and score >= self.score_threshold:
                    # ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ metadataì— ì¶”ê°€
                    doc.metadata['similarity_score'] = round(score, 3)
                    filtered_docs.append(doc)
                    
                    # ì¶©ë¶„í•œ ê²°ê³¼ë¥¼ ì–»ìœ¼ë©´ ì¤‘ë‹¨ (ì„±ëŠ¥ ìµœì í™”)
                    if len(filtered_docs) >= 50:
                        break
            
            return filtered_docs
            
        except Exception as e:
            print(f"âŒ ë²¡í„° ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return []
    
    def _fallback_vector_search(self, query: str) -> List[Document]:
        """SQL í•„í„°ë§ ì‹¤íŒ¨ì‹œ ìˆœìˆ˜ ë²¡í„° ê²€ìƒ‰"""
        try:
            print("ğŸ§  ìˆœìˆ˜ ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰...")
            docs_with_scores = self.vectorstore.similarity_search_with_score(query, k=min(100, self.k))
            
            filtered_docs = []
            for doc, score in docs_with_scores:
                if score >= self.score_threshold:
                    doc.metadata['similarity_score'] = round(score, 3)
                    filtered_docs.append(doc)
            
            return filtered_docs
            
        except Exception as e:
            print(f"âŒ í´ë°± ë²¡í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

# í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™” Retriever ìƒì„± (sentence-transformers ëª¨ë¸ì— ìµœì í™”ëœ ì„ê³„ê°’)
retriever = HybridOptimizedRetriever(vectorstore, k=32000, score_threshold=0.5, max_sql_results=5000)

# =============================================================================
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
# =============================================================================

rag_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì—¬í–‰ ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ì—¬í–‰ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë§ëŠ” ì—¬í–‰ ì¼ì •ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì—¬í–‰ì§€ ì •ë³´:
{context}

ì‚¬ìš©ì ì§ˆë¬¸: {question}

ë‹µë³€ ì§€ì¹¨:
1. ë§Œì•½ ì—¬í–‰ì§€ ì •ë³´ê°€ "NO_RELEVANT_DATA"ë¼ë©´, ë‹¤ìŒê³¼ ê°™ì´ ë‹µë³€í•˜ì„¸ìš”:
   "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­í•˜ì‹  '{question}'ì™€ ê´€ë ¨ëœ ì—¬í–‰ì§€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 
   ë” êµ¬ì²´ì ì¸ ì§€ì—­ëª…ì´ë‚˜ ë‹¤ë¥¸ ì—¬í–‰ì§€ë¡œ ë‹¤ì‹œ ë¬¸ì˜í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."

2. ê´€ë ¨ ì—¬í–‰ì§€ ì •ë³´ê°€ ìˆë‹¤ë©´:
    - ì‹¤ì œ ì œê³µëœ ì—¬í–‰ì§€ ì •ë³´ë§Œì„ í™œìš©í•˜ì„¸ìš”
    - êµ¬ì²´ì ì¸ ì¥ì†Œëª…, ì§€ì—­, ì¹´í…Œê³ ë¦¬ë¥¼ í¬í•¨í•˜ì„¸ìš”
    - ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì¼ì •ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”
    - ì ì‹¬, ì €ë… ì‹œê°„ì„ ìƒê°í•˜ê³  ì‹ì‚¬ë¥¼ í•  ê³³ë„ ë„£ì–´ì£¼ì„¸ìš”
    - ì‹œê°„ë‹¨ìœ„ë¡œ ì¼ì •ì„ ì œê³µí•´ì£¼ì„¸ìš”
    - ì¹´í…Œê³ ë¦¬ê°€ ë‹¤ë¥´ë”ë¼ë„ ëª…ì†Œë¼ ìƒê°ë˜ë©´ ë‹µë³€í•´ì£¼ì„¸ìš”
    - ì¤‘ë³µëœ ì¶”ì²œì€ ë°˜ë“œì‹œ ì œê±°í•´ì£¼ì„¸ìš”
    - í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ì„¸ìš”

ë‹µë³€:
""")

# # RAG ì²´ì¸ êµ¬ì„±

def format_docs(docs):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ… (ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨)"""
    if not docs:
        return "NO_RELEVANT_DATA"  # ê´€ë ¨ ë°ì´í„° ì—†ìŒì„ ë‚˜íƒ€ë‚´ëŠ” íŠ¹ë³„í•œ ë§ˆì»¤
    
    formatted_docs = []
    for i, doc in enumerate(docs, 1):
        # ìœ ì‚¬ë„ ì ìˆ˜ ì¶”ì¶œ
        similarity_score = doc.metadata.get('similarity_score', 'N/A')
        content = f"[ì—¬í–‰ì§€ {i}] (ìœ ì‚¬ë„: {similarity_score})\n{doc.page_content}"
        
        if doc.metadata:
            meta_info = []
            for key, value in doc.metadata.items():
                if value and key not in ['original_id', 'similarity_score', '_embedding']:  # ë‚´ë¶€ í‚¤ ì œì™¸
                    meta_info.append(f"{key}: {value}")
            if meta_info:
                content += f"\n({', '.join(meta_info)})"
        formatted_docs.append(content)
    
    return "\n\n".join(formatted_docs)

# RAG íŒŒì´í”„ë¼ì¸ êµ¬ì„±
rag_chain = (
    {
        "context": retriever | format_docs, 
        "question": RunnablePassthrough()
    }
    | rag_prompt
    | llm
    | StrOutputParser()
)

# # ì£¼ìš” ê¸°ëŠ¥ í•¨ìˆ˜ë“¤

def search_places(query):
    """ì—¬í–‰ì§€ ê²€ìƒ‰ í•¨ìˆ˜ (í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™” + Redis ìºì‹±)"""
    try:
        print(f"ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: '{query}'")

        # ìºì‹œëœ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
        cached_docs = llm_cache.get_cached_search_results(query)
        if cached_docs:
            print("âš¡ ìºì‹œëœ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜!")
            return cached_docs

        print("ğŸ” ìƒˆë¡œìš´ ê²€ìƒ‰ ì‹¤í–‰...")

        # HybridOptimizedRetriever ì§ì ‘ ì‚¬ìš©
        docs = retriever._get_relevant_documents(query)

        # ê²€ìƒ‰ ê²°ê³¼ ìºì‹± (30ë¶„)
        llm_cache.cache_search_results(query, docs, expire=1800)

        return docs

    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []

def get_travel_recommendation_optimized(query, stream=True):
    """ìµœì í™”ëœ Redis ìºì‹± + ìŠ¤íŠ¸ë¦¼"""
    def _generate_stream():
        try:
            # ê²€ìƒ‰ ë‹¨ê³„ëŠ” í•­ìƒ ìºì‹± í™œìš©
            cached_docs = llm_cache.get_cached_search_results(query)
            if cached_docs:
                docs = cached_docs
            else:
                docs = retriever._get_relevant_documents(query)
                llm_cache.cache_search_results(query, docs, expire=1800)

            context = format_docs(docs)
            prompt_value = rag_prompt.invoke({"context": context, "question": query})

            # ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ: yieldë¡œ ì‹¤ì‹œê°„ ì‘ë‹µ
            full_response = ""
            buffer = ""
            for chunk in llm.stream(prompt_value):
                if hasattr(chunk, 'content'):
                    content = chunk.content
                    if content:
                        buffer += content
                        full_response += content

                        # ì ì ˆí•œ ì²­í¬ë¡œ yield
                        if len(buffer) > 15 or any(c in buffer for c in ['\n', '.']):
                            yield buffer
                            buffer = ""

            if buffer:
                yield buffer

            # ğŸ¯ ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ í›„ ì „ì²´ ì‘ë‹µ ìºì‹±
            if len(full_response) > 50:
                llm_cache.cache_response(query, full_response, expire=3600)

        except Exception as e:
            yield f"âŒ ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {e}"

    try:
        if stream:
            return _generate_stream()
        else:
            # ë¹„ìŠ¤íŠ¸ë¦¼: ìºì‹œ í™•ì¸ í›„ ì¼ë°˜ ì²˜ë¦¬
            cached_response = llm_cache.get_cached_response(query)
            if cached_response:
                return cached_response

            # ê²€ìƒ‰ ë‹¨ê³„ëŠ” í•­ìƒ ìºì‹± í™œìš©
            cached_docs = llm_cache.get_cached_search_results(query)
            if cached_docs:
                docs = cached_docs
            else:
                docs = retriever._get_relevant_documents(query)
                llm_cache.cache_search_results(query, docs, expire=1800)

            context = format_docs(docs)
            prompt_value = rag_prompt.invoke({"context": context, "question": query})

            response = llm.invoke(prompt_value)
            if hasattr(response, 'content'):
                response_text = response.content
            else:
                response_text = str(response)
            llm_cache.cache_response(query, response_text, expire=3600)
            return response_text

    except Exception as e:
        return f"âŒ ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {e}"

def get_travel_recommendation(query, stream=True):
    """ì—¬í–‰ ì¶”ì²œ ìƒì„± í•¨ìˆ˜ (ìŠ¤íŠ¸ë¦¼ ì§€ì› + Redis ìºì‹±)"""
    if stream:
        return get_travel_recommendation_optimized(query, stream=True)
    else:
        return get_travel_recommendation_optimized(query, stream=False)

def get_travel_recommendation_stream(query):
    """ì§„ì§œ ìŠ¤íŠ¸ë¦¼ ë°©ì‹ ì—¬í–‰ ì¶”ì²œ ìƒì„± (í„°ë¯¸ë„/ì›¹ ìš©)"""
    try:
        docs = retriever._get_relevant_documents(query)
        context = format_docs(docs)

        prompt_value = rag_prompt.invoke({"context": context, "question": query})

        # â–¶ï¸ ì§„ì§œ yieldë¡œ ìŠ¤íŠ¸ë¦¬ë°
        buffer = ""
        full_response = ""
        for chunk in llm.stream(prompt_value):
            if hasattr(chunk, 'content'):
                content = chunk.content
            else:
                content = str(chunk)
            if content:
                buffer += content
                full_response += content
                # ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤íŠ¸ë¦¬ë°: ë¬¸ì¥/ì¤„/ì²­í¬ ë‹¨ìœ„ë¡œ
                if len(buffer) > 15 or '\n' in buffer or '.' in buffer:
                    to_send, buffer = buffer, ""
                    yield to_send
        if buffer:
            yield buffer
    except Exception as e:
        yield f"âŒ ìŠ¤íŠ¸ë¦¼ ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {e}"


async def get_travel_recommendation_stream_async(query):
    """ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼ ë°©ì‹ ì—¬í–‰ ì¶”ì²œ ìƒì„± (FastAPI í˜¸í™˜)"""
    import asyncio
    try:
        docs = retriever._get_relevant_documents(query)
        if len(docs) > 5:
            docs = docs[:5]
        context = format_docs(docs)
        prompt_value = rag_prompt.invoke({"context": context, "question": query})

        buffer = ""
        full_response = ""
        for chunk in llm.stream(prompt_value):
            if hasattr(chunk, 'content'):
                content = chunk.content
            else:
                content = str(chunk)
            if content:
                buffer += content
                full_response += content
                # ë¹ ë¥¸ ìŠ¤íŠ¸ë¦¼ + ìì—°ìŠ¤ëŸ¬ìš´ ë‹¨ìœ„
                if len(buffer) > 15 or '\n' in buffer or '.' in buffer:
                    to_send, buffer = buffer, ""
                    yield to_send
                    await asyncio.sleep(0.02)
        if buffer:
            yield buffer
    except Exception as e:
        error_msg = f"âŒ ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¼ ì¶”ì²œ ìƒì„± ì˜¤ë¥˜: {e}"
        yield error_msg
        await asyncio.sleep(0.01)

# =============================================================================
# ê¸°ìƒì²­ API ê´€ë ¨ í•¨ìˆ˜ë“¤
# =============================================================================

# ê¸°ìƒì²­ API í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
WEATHER_API_KEY = os.getenv('WEATHER_API_KEY')

def get_coordinates_for_region(region_name):
    """ì§€ì—­ëª…ì„ ê¸°ìƒì²­ APIìš© ê²©ì ì¢Œí‘œë¡œ ë³€í™˜ (DB ê¸°ë°˜ + ë§¤í•‘)"""

    # ì§€ì—­ë³„ ëŒ€í‘œ ì¢Œí‘œ ë§¤í•‘ (ê¸°ìƒì²­ ê²©ì ì¢Œí‘œ)
    region_coordinates = {
        # === íŠ¹ë³„ì‹œ/ê´‘ì—­ì‹œ/ë„ ëŒ€í‘œ ì¢Œí‘œ ===
        'ì„œìš¸íŠ¹ë³„ì‹œ': {'nx': 60, 'ny': 127},
        'ì„œìš¸': {'nx': 60, 'ny': 127},

        'ë¶€ì‚°ê´‘ì—­ì‹œ': {'nx': 98, 'ny': 76},
        'ë¶€ì‚°': {'nx': 98, 'ny': 76},

        'ëŒ€êµ¬ê´‘ì—­ì‹œ': {'nx': 89, 'ny': 90},
        'ëŒ€êµ¬': {'nx': 89, 'ny': 90},

        'ì¸ì²œê´‘ì—­ì‹œ': {'nx': 55, 'ny': 124},
        'ì¸ì²œ': {'nx': 55, 'ny': 124},

        'ê´‘ì£¼ê´‘ì—­ì‹œ': {'nx': 58, 'ny': 74},
        'ê´‘ì£¼': {'nx': 58, 'ny': 74},

        'ëŒ€ì „ê´‘ì—­ì‹œ': {'nx': 67, 'ny': 100},
        'ëŒ€ì „': {'nx': 67, 'ny': 100},

        'ìš¸ì‚°ê´‘ì—­ì‹œ': {'nx': 102, 'ny': 84},
        'ìš¸ì‚°': {'nx': 102, 'ny': 84},

        'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ': {'nx': 66, 'ny': 103},
        'ì„¸ì¢…ì‹œ': {'nx': 66, 'ny': 103},
        'ì„¸ì¢…': {'nx': 66, 'ny': 103},

        'ê²½ê¸°ë„': {'nx': 60, 'ny': 121},  # ìˆ˜ì› ê¸°ì¤€
        'ê°•ì›íŠ¹ë³„ìì¹˜ë„': {'nx': 73, 'ny': 134},  # ì¶˜ì²œ ê¸°ì¤€
        'ê°•ì›ë„': {'nx': 73, 'ny': 134},
        'ì¶©ì²­ë¶ë„': {'nx': 69, 'ny': 106},  # ì²­ì£¼ ê¸°ì¤€
        'ì¶©ì²­ë‚¨ë„': {'nx': 63, 'ny': 110},  # ì²œì•ˆ ê¸°ì¤€
        'ì „ë¶íŠ¹ë³„ìì¹˜ë„': {'nx': 63, 'ny': 89},  # ì „ì£¼ ê¸°ì¤€
        'ì „ë¼ë¶ë„': {'nx': 63, 'ny': 89},
        'ì „ë¼ë‚¨ë„': {'nx': 58, 'ny': 74},  # ê´‘ì£¼ ê¸°ì¤€
        'ê²½ìƒë¶ë„': {'nx': 89, 'ny': 90},  # ëŒ€êµ¬ ê¸°ì¤€
        'ê²½ìƒë‚¨ë„': {'nx': 90, 'ny': 77},  # ì°½ì› ê¸°ì¤€
        'ì œì£¼íŠ¹ë³„ìì¹˜ë„': {'nx': 52, 'ny': 38},
        'ì œì£¼ë„': {'nx': 52, 'ny': 38},
        'ì œì£¼': {'nx': 52, 'ny': 38},

        # === ì£¼ìš” ë„ì‹œ ì„¸ë¶€ ì¢Œí‘œ ===
        # ì„œìš¸ ì£¼ìš” êµ¬
        'ê°•ë‚¨êµ¬': {'nx': 61, 'ny': 126},
        'ê°•ë‚¨': {'nx': 61, 'ny': 126},
        'ì¢…ë¡œêµ¬': {'nx': 60, 'ny': 127},
        'ì¢…ë¡œ': {'nx': 60, 'ny': 127},
        'ë§ˆí¬êµ¬': {'nx': 59, 'ny': 126},
        'ê°•ë¶êµ¬': {'nx': 60, 'ny': 128},
        'ê°•ë¶': {'nx': 60, 'ny': 128},
        'ì†¡íŒŒêµ¬': {'nx': 62, 'ny': 126},
        'êµ¬ë¡œêµ¬': {'nx': 58, 'ny': 125},

        # ë¶€ì‚° ì£¼ìš” êµ¬
        'í•´ìš´ëŒ€êµ¬': {'nx': 99, 'ny': 75},
        'í•´ìš´ëŒ€': {'nx': 99, 'ny': 75},
        'ì‚¬í•˜êµ¬': {'nx': 96, 'ny': 76},
        'ì‚¬í•˜': {'nx': 96, 'ny': 76},
        'ê¸°ì¥êµ°': {'nx': 100, 'ny': 77},

        # ê²½ê¸°ë„ ì£¼ìš” ë„ì‹œ
        'ìˆ˜ì›ì‹œ': {'nx': 60, 'ny': 121},
        'ìˆ˜ì›': {'nx': 60, 'ny': 121},
        'ì„±ë‚¨ì‹œ': {'nx': 63, 'ny': 124},
        'ì„±ë‚¨': {'nx': 63, 'ny': 124},
        'ê³ ì–‘ì‹œ': {'nx': 57, 'ny': 128},
        'ê³ ì–‘': {'nx': 57, 'ny': 128},
        'ìš©ì¸ì‹œ': {'nx': 64, 'ny': 119},
        'ìš©ì¸': {'nx': 64, 'ny': 119},
        'ì•ˆì–‘ì‹œ': {'nx': 59, 'ny': 123},
        'ì•ˆì–‘': {'nx': 59, 'ny': 123},
        'íŒŒì£¼ì‹œ': {'nx': 56, 'ny': 131},
        'íŒŒì£¼': {'nx': 56, 'ny': 131},
        'ê°€í‰êµ°': {'nx': 61, 'ny': 133},
        'ê°€í‰': {'nx': 61, 'ny': 133},

        # ê°•ì›ë„ ì£¼ìš” ë„ì‹œ
        'ì¶˜ì²œì‹œ': {'nx': 73, 'ny': 134},
        'ì¶˜ì²œ': {'nx': 73, 'ny': 134},
        'ê°•ë¦‰ì‹œ': {'nx': 92, 'ny': 131},
        'ê°•ë¦‰': {'nx': 92, 'ny': 131},
        'í‰ì°½êµ°': {'nx': 84, 'ny': 123},
        'í‰ì°½': {'nx': 84, 'ny': 123},

        # ê¸°íƒ€ ì£¼ìš” ë„ì‹œ
        'ê²½ì£¼ì‹œ': {'nx': 100, 'ny': 91},
        'ê²½ì£¼': {'nx': 100, 'ny': 91},
        'ì „ì£¼ì‹œ': {'nx': 63, 'ny': 89},
        'ì „ì£¼': {'nx': 63, 'ny': 89},
        'ì—¬ìˆ˜ì‹œ': {'nx': 73, 'ny': 66},
        'ì—¬ìˆ˜': {'nx': 73, 'ny': 66},
        'ì°½ì›ì‹œ': {'nx': 90, 'ny': 77},
        'ì°½ì›': {'nx': 90, 'ny': 77},
        'ì œì£¼ì‹œ': {'nx': 53, 'ny': 38},
        'ì„œê·€í¬ì‹œ': {'nx': 52, 'ny': 33},
        'ì„œê·€í¬': {'nx': 52, 'ny': 33},

        # êµ¬ ì´ë¦„ë“¤ (ì¤‘ë³µ ì²˜ë¦¬)
        'ì¤‘êµ¬': {'nx': 60, 'ny': 127},  # ì„œìš¸ ê¸°ì¤€
        'ë™êµ¬': {'nx': 68, 'ny': 100},  # ëŒ€ì „ ê¸°ì¤€
        'ì„œêµ¬': {'nx': 67, 'ny': 100},  # ëŒ€ì „ ê¸°ì¤€
        'ë‚¨êµ¬': {'nx': 58, 'ny': 74},   # ê´‘ì£¼ ê¸°ì¤€
        'ë¶êµ¬': {'nx': 59, 'ny': 75},   # ê´‘ì£¼ ê¸°ì¤€
    }

    # ì •í™•í•œ ë§¤ì¹˜ ì‹œë„
    if region_name in region_coordinates:
        return region_coordinates[region_name]

    # ë¶€ë¶„ ë§¤ì¹˜ ì‹œë„ (ì§€ì—­ëª…ì´ í¬í•¨ëœ ê²½ìš°)
    for key, coords in region_coordinates.items():
        if region_name in key or key in region_name:
            return coords

    # ê¸°ë³¸ê°’ (ì„œìš¸)
    return {'nx': 60, 'ny': 127}

def get_db_regions_and_cities():
    """DBì—ì„œ ì‹¤ì œ regionê³¼ city ë°ì´í„° ì¶”ì¶œ"""
    try:
        from sqlalchemy import text

        engine = shared_engine
        with engine.connect() as conn:
            # Region ë°ì´í„° ì¶”ì¶œ
            regions = []
            result = conn.execute(text("SELECT DISTINCT cmetadata->>'region' as region FROM langchain_pg_embedding WHERE cmetadata->>'region' IS NOT NULL AND cmetadata->>'region' != ''"))
            for row in result:
                if row[0]:  # ë¹ˆ ë¬¸ìì—´ ì œì™¸
                    regions.append(row[0])

            # City ë°ì´í„° ì¶”ì¶œ (ìƒìœ„ 100ê°œ)
            cities = []
            result = conn.execute(text("SELECT DISTINCT cmetadata->>'city' as city FROM langchain_pg_embedding WHERE cmetadata->>'city' IS NOT NULL AND cmetadata->>'city' != '' ORDER BY city LIMIT 100"))
            for row in result:
                if row[0]:  # ë¹ˆ ë¬¸ìì—´ ì œì™¸
                    cities.append(row[0])

            return regions, cities
    except Exception as e:
        print(f"DB ì—°ê²° ì˜¤ë¥˜: {e}")
        # ê¸°ë³¸ê°’ ë°˜í™˜
        return ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ëŒ€êµ¬ê´‘ì—­ì‹œ'], ['ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬']

def extract_region_from_context(state):
    """í˜„ì¬ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§€ì—­ëª… ì¶”ì¶œ"""
    try:
        # 1. í˜„ì¬ ì—¬í–‰ ê³„íšì—ì„œ ì§€ì—­ ì¶”ì¶œ
        travel_plan = state.get("travel_plan", {})
        if travel_plan:
            # ì—¬í–‰ ê³„íšì˜ region í•„ë“œì—ì„œ ì§ì ‘ ì¶”ì¶œ
            if "region" in travel_plan and travel_plan["region"]:
                return travel_plan["region"]

            # ì¥ì†Œë“¤ì—ì„œ ì§€ì—­ ì¶”ì¶œ
            places = travel_plan.get("places", [])
            for place in places:
                if isinstance(place, dict):
                    region = place.get("region") or place.get("city")
                    if region:
                        return region
                elif isinstance(place, str):
                    extracted_region = extract_region_from_query(place)
                    if extracted_region:
                        return extracted_region

        # 2. ê¸€ë¡œë²Œ current_travel_stateì—ì„œ ì§€ì—­ ì¶”ì¶œ
        global current_travel_state
        if current_travel_state and current_travel_state.get("travel_plan"):
            plan = current_travel_state["travel_plan"]
            if isinstance(plan, dict):
                if "region" in plan and plan["region"]:
                    return plan["region"]

                places = plan.get("places", [])
                for place in places:
                    if isinstance(place, dict):
                        region = place.get("region") or place.get("city")
                        if region:
                            return region

        # 3. ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì—ì„œ ì§€ì—­ ì¶”ì¶œ
        messages = state.get("messages", [])
        if messages:
            # ìµœê·¼ ë©”ì‹œì§€ë¶€í„° ì—­ìˆœìœ¼ë¡œ ê²€ìƒ‰
            for message in reversed(messages):
                if isinstance(message, str):
                    extracted_region = extract_region_from_query(message)
                    if extracted_region:
                        return extracted_region

        # 4. ë§ˆì§€ë§‰ ì¿¼ë¦¬ì—ì„œ ì§€ì—­ ì¶”ì¶œ
        last_query = current_travel_state.get("last_query", "") if current_travel_state else ""
        if last_query:
            extracted_region = extract_region_from_query(last_query)
            if extracted_region:
                return extracted_region

        return None

    except Exception as e:
        print(f"âŒ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§€ì—­ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None

def extract_region_from_query(query):
    """ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ì§€ì—­ëª… ì¶”ì¶œ (DB ê¸°ë°˜)"""
    # DBì—ì„œ ì‹¤ì œ regionê³¼ city ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    db_regions, db_cities = get_db_regions_and_cities()

    # ì „ì²´ ì§€ì—­ í‚¤ì›Œë“œ = DB regions + DB cities + ì¶”ê°€ ë³„ì¹­
    region_keywords = []

    # DBì—ì„œ ê°€ì ¸ì˜¨ regionë“¤
    region_keywords.extend(db_regions)

    # DBì—ì„œ ê°€ì ¸ì˜¨ cityë“¤
    region_keywords.extend(db_cities)

    # ì¶”ê°€ ë³„ì¹­ë“¤ (ì¤„ì„ë§, ë‹¤ë¥¸ í‘œê¸°)
    aliases = [
        'ì„œìš¸', 'ë¶€ì‚°', 'ëŒ€êµ¬', 'ì¸ì²œ', 'ê´‘ì£¼', 'ëŒ€ì „', 'ìš¸ì‚°', 'ì„¸ì¢…',
        'ê²½ê¸°', 'ê°•ì›', 'ì¶©ë¶', 'ì¶©ë‚¨', 'ì „ë¶', 'ì „ë‚¨', 'ê²½ë¶', 'ê²½ë‚¨', 'ì œì£¼',
        'í•´ìš´ëŒ€', 'ê°•ë‚¨', 'ê°•ë¶', 'ì¢…ë¡œ', 'ëª…ë™', 'í™ëŒ€', 'ì´íƒœì›', 'ì¸ì‚¬ë™',
        'ê´‘ì•ˆë¦¬', 'ë‚¨í¬ë™', 'ì„œë©´', 'ê°•ë¦‰', 'ì¶˜ì²œ', 'ì›ì£¼', 'ì†ì´ˆ', 'ë™í•´',
        'ì‚¼ì²™', 'íƒœë°±', 'ì •ì„ ', 'í‰ì°½', 'ì˜ì›”', 'íš¡ì„±', 'í™ì²œ', 'í™”ì²œ',
        'ì–‘êµ¬', 'ì¸ì œ', 'ê³ ì„±', 'ì–‘ì–‘'
    ]
    region_keywords.extend(aliases)

    # ì¤‘ë³µ ì œê±°
    region_keywords = list(set(region_keywords))

    # ê¸´ í‚¤ì›Œë“œë¶€í„° ë§¤ì¹­ (ë” êµ¬ì²´ì ì¸ ì§€ì—­ëª… ìš°ì„ )
    region_keywords.sort(key=len, reverse=True)

    # ì¿¼ë¦¬ì—ì„œ ì§€ì—­ëª… ì°¾ê¸°
    for region in region_keywords:
        if region in query:
            return region

    return None

def get_weather_info(region_name):
    """ê¸°ìƒì²­ APIë¡œ ë‚ ì”¨ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    if not WEATHER_API_KEY:
        return "âŒ ê¸°ìƒì²­ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— WEATHER_API_KEYë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”."

    try:
        # ì§€ì—­ ì¢Œí‘œ ê°€ì ¸ì˜¤ê¸°
        coords = get_coordinates_for_region(region_name)

        # í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„
        now = datetime.datetime.now()
        base_date = now.strftime('%Y%m%d')

        # ê¸°ìƒì²­ ë°œí‘œì‹œê°„ì— ë§ì¶° base_time ì„¤ì • (02, 05, 08, 11, 14, 17, 20, 23ì‹œ)
        hour = now.hour
        if hour < 2:
            base_time = '2300'
            base_date = (now - datetime.timedelta(days=1)).strftime('%Y%m%d')
        elif hour < 5:
            base_time = '0200'
        elif hour < 8:
            base_time = '0500'
        elif hour < 11:
            base_time = '0800'
        elif hour < 14:
            base_time = '1100'
        elif hour < 17:
            base_time = '1400'
        elif hour < 20:
            base_time = '1700'
        elif hour < 23:
            base_time = '2000'
        else:
            base_time = '2300'

        # ê¸°ìƒì²­ API ìš”ì²­ URL (HTTPë¡œ ì‹œë„)
        url = 'http://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getVilageFcst'

        params = {
            'serviceKey': WEATHER_API_KEY,
            'pageNo': '1',
            'numOfRows': '1000',
            'dataType': 'JSON',
            'base_date': base_date,
            'base_time': base_time,
            'nx': coords['nx'],
            'ny': coords['ny']
        }

        # ì¬ì‹œë„ ë¡œì§ê³¼ í•¨ê»˜ HTTP ìš”ì²­
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json',
            'Connection': 'keep-alive'
        }

        # ì¬ì‹œë„ ë¡œì§
        max_retries = 3
        for attempt in range(max_retries):
            try:
                print(f"ğŸŒ¤ï¸ ê¸°ìƒì²­ API í˜¸ì¶œ ì‹œë„ {attempt + 1}/{max_retries}")
                response = requests.get(url, params=params, headers=headers, timeout=30)
                break
            except requests.exceptions.Timeout:
                if attempt == max_retries - 1:
                    return f"âŒ ê¸°ìƒì²­ ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼ ({region_name})"
                print(f"   â° íƒ€ì„ì•„ì›ƒ ë°œìƒ, {attempt + 2}ë²ˆì§¸ ì‹œë„...")
                continue
            except Exception as e:
                if attempt == max_retries - 1:
                    return f"âŒ ê¸°ìƒì²­ API ì—°ê²° ì˜¤ë¥˜: {e}"
                print(f"   ğŸ”„ ì—°ê²° ì˜¤ë¥˜, {attempt + 2}ë²ˆì§¸ ì‹œë„...")
                continue

        if response.status_code == 200:
            data = response.json()

            if data['response']['header']['resultCode'] == '00':
                items = data['response']['body']['items']['item']

                # ì˜¤ëŠ˜ê³¼ ë‚´ì¼ ë‚ ì”¨ ì •ë³´ ì¶”ì¶œ
                weather_info = parse_weather_data(items, region_name)
                return weather_info
            else:
                return f"âŒ ê¸°ìƒì²­ API ì˜¤ë¥˜: {data['response']['header']['resultMsg']}"
        else:
            return f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}"

    except Exception as e:
        return f"âŒ ë‚ ì”¨ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}"

def parse_weather_data(items, region_name):
    """ê¸°ìƒì²­ API ì‘ë‹µ ë°ì´í„° íŒŒì‹±"""
    try:
        # ì˜¤ëŠ˜ê³¼ ë‚´ì¼ ë‚ ì”¨ ë°ì´í„° ë¶„ë¥˜
        today = datetime.datetime.now().strftime('%Y%m%d')
        tomorrow = (datetime.datetime.now() + datetime.timedelta(days=1)).strftime('%Y%m%d')

        today_data = {}
        tomorrow_data = {}

        for item in items:
            fcst_date = item['fcstDate']
            fcst_time = item['fcstTime']
            category = item['category']
            fcst_value = item['fcstValue']

            # ì˜¤ëŠ˜ ë°ì´í„°
            if fcst_date == today:
                if fcst_time not in today_data:
                    today_data[fcst_time] = {}
                today_data[fcst_time][category] = fcst_value

            # ë‚´ì¼ ë°ì´í„°
            elif fcst_date == tomorrow:
                if fcst_time not in tomorrow_data:
                    tomorrow_data[fcst_time] = {}
                tomorrow_data[fcst_time][category] = fcst_value

        # ë‚ ì”¨ ì •ë³´ í¬ë§·íŒ…
        weather_text = f"ğŸŒ¤ï¸ <strong>{region_name} ë‚ ì”¨ ì •ë³´</strong>\n\n"

        # ì˜¤ëŠ˜ ë‚ ì”¨ (ëŒ€í‘œ ì‹œê°„: 12ì‹œ)
        if '1200' in today_data:
            data = today_data['1200']
            weather_text += "ğŸ“… <strong>ì˜¤ëŠ˜</strong>\n"
            weather_text += format_weather_detail(data)
            weather_text += "\n"

        # ë‚´ì¼ ë‚ ì”¨ (ëŒ€í‘œ ì‹œê°„: 12ì‹œ)
        if '1200' in tomorrow_data:
            data = tomorrow_data['1200']
            weather_text += "ğŸ“… <strong>ë‚´ì¼</strong>\n"
            weather_text += format_weather_detail(data)

        return weather_text

    except Exception as e:
        return f"âŒ ë‚ ì”¨ ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {e}"

def format_weather_detail(data):
    """ë‚ ì”¨ ìƒì„¸ ì •ë³´ í¬ë§·íŒ…"""
    try:
        # ê¸°ìƒì²­ ì½”ë“œ ë§¤í•‘
        sky_codes = {
            '1': 'ë§‘ìŒ â˜€ï¸',
            '3': 'êµ¬ë¦„ë§ìŒ â›…',
            '4': 'íë¦¼ â˜ï¸'
        }

        pty_codes = {
            '0': 'ì—†ìŒ',
            '1': 'ë¹„ ğŸŒ§ï¸',
            '2': 'ë¹„/ëˆˆ ğŸŒ¨ï¸',
            '3': 'ëˆˆ â„ï¸',
            '4': 'ì†Œë‚˜ê¸° ğŸŒ¦ï¸'
        }

        detail = ""

        # í•˜ëŠ˜ìƒíƒœ
        if 'SKY' in data:
            sky = sky_codes.get(data['SKY'], 'ì •ë³´ì—†ìŒ')
            detail += f"â€¢ í•˜ëŠ˜ìƒíƒœ: {sky}\n"

        # ê°•ìˆ˜í˜•íƒœ
        if 'PTY' in data:
            pty = pty_codes.get(data['PTY'], 'ì •ë³´ì—†ìŒ')
            if data['PTY'] != '0':
                detail += f"â€¢ ê°•ìˆ˜í˜•íƒœ: {pty}\n"

        # ê¸°ì˜¨
        if 'TMP' in data:
            detail += f"â€¢ ê¸°ì˜¨: {data['TMP']}Â°C ğŸŒ¡ï¸\n"

        # ê°•ìˆ˜í™•ë¥ 
        if 'POP' in data:
            detail += f"â€¢ ê°•ìˆ˜í™•ë¥ : {data['POP']}% ğŸ’§\n"

        # ìŠµë„
        if 'REH' in data:
            detail += f"â€¢ ìŠµë„: {data['REH']}% ğŸ’¨\n"

        # í’ì†
        if 'WSD' in data:
            detail += f"â€¢ í’ì†: {data['WSD']}m/s ğŸ’¨\n"

        return detail

    except Exception as e:
        return f"ìƒì„¸ ì •ë³´ ì²˜ë¦¬ ì˜¤ë¥˜: {e}\n"

def get_smart_weather_info(region_name, travel_date=None):
    """ìŠ¤ë§ˆíŠ¸ ë‚ ì”¨ ì¡°íšŒ: ë‹¨ê¸°ì˜ˆë³´ ìš°ì„ , ì‹¤íŒ¨ ì‹œ ê³¼ê±° ë°ì´í„° í´ë°±"""
    import datetime

    try:
        # 1. ë¨¼ì € ë‹¨ê¸°ì˜ˆë³´(ë¯¸ë˜ ë‚ ì”¨) ì‹œë„ - í˜„ì¬ ì‹œê°„ ê¸°ì¤€ 3ì¼ ì´ë‚´
        now = datetime.datetime.now()

        # ì—¬í–‰ ë‚ ì§œê°€ ì—†ìœ¼ë©´ í˜„ì¬ ë‚ ì§œë¡œ ê°€ì •
        if not travel_date:
            travel_dt = now
        else:
            try:
                if isinstance(travel_date, str):
                    if len(travel_date) == 8:  # YYYYMMDD
                        travel_dt = datetime.datetime.strptime(travel_date, '%Y%m%d')
                    else:
                        travel_dt = datetime.datetime.strptime(travel_date, '%Y-%m-%d')
                else:
                    travel_dt = travel_date
            except Exception as e:
                print(f"ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: {e}")
                travel_dt = now

        days_diff = (travel_dt - now).days
        print(f"ğŸ“… ì—¬í–‰ì¼: {travel_dt.strftime('%Y-%m-%d')}, í˜„ì¬ë¡œë¶€í„° {days_diff}ì¼ í›„")

        # ë‹¨ê¸°ì˜ˆë³´ ê°€ëŠ¥ ê¸°ê°„: ì˜¤ëŠ˜~3ì¼ í›„ (ê¸°ìƒì²­ API ì œê³µ ë²”ìœ„)
        if 0 <= days_diff <= 3:
            print(f"ğŸŒ¤ï¸ {region_name} ë‹¨ê¸°ì˜ˆë³´ ì¡°íšŒ ì¤‘... ({days_diff}ì¼ í›„)")
            future_weather = get_weather_info(region_name)
            if not future_weather.startswith("âŒ"):
                return f"ğŸ“ <strong>{region_name} ì˜ˆìƒ ë‚ ì”¨</strong> (ì—¬í–‰ì¼ ê¸°ì¤€)\n\n{future_weather}"

        # 2. ë‹¨ê¸°ì˜ˆë³´ ì‹¤íŒ¨ ì‹œ ê³¼ê±° ë™ì¼ ê¸°ê°„ ë‚ ì”¨ë¡œ í´ë°±
        print(f"ğŸ“… {region_name} ê³¼ê±° ë™ì¼ ê¸°ê°„ ë‚ ì”¨ ì¡°íšŒ ì¤‘...")

        # ì‘ë…„ ë™ì¼ ê¸°ê°„ ë‚ ì§œ ê³„ì‚°
        now = datetime.datetime.now()
        if travel_date:
            try:
                if isinstance(travel_date, str) and len(travel_date) == 8:
                    travel_dt = datetime.datetime.strptime(travel_date, '%Y%m%d')
                else:
                    travel_dt = now
                # ì‘ë…„ ë™ì¼ ë‚ ì§œ
                last_year_date = travel_dt.replace(year=travel_dt.year - 1)
            except:
                last_year_date = now.replace(year=now.year - 1)
        else:
            # ì—¬í–‰ ë‚ ì§œ ì—†ìœ¼ë©´ ì‘ë…„ ì´ë§˜ë•Œ
            last_year_date = now.replace(year=now.year - 1)

        historical_date = last_year_date.strftime('%Y%m%d')
        historical_weather = get_historical_weather_info(region_name, historical_date)

        if not historical_weather.startswith("âŒ"):
            # ê³¼ê±° ë‚ ì”¨ì—ì„œ í‰ê·  ê¸°ì˜¨ë§Œ ì¶”ì¶œ
            simplified_weather = simplify_historical_weather(historical_weather, region_name, last_year_date.strftime('%Y-%m-%d'))
            return f"ğŸ“Š <strong>{region_name} ì°¸ê³  ë‚ ì”¨</strong> (ì‘ë…„ ë™ì¼ ê¸°ê°„)\n\n{simplified_weather}\n\nğŸ’¡ <em>ì‹¤ì œ ì—¬í–‰ ì‹œ ìµœì‹  ì˜ˆë³´ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!</em>"

        # 3. ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ ì¼ë°˜ì ì¸ ê³„ì ˆ ì •ë³´
        month = now.month if not travel_date else travel_dt.month
        seasonal_info = get_seasonal_weather_info(region_name, month)
        return seasonal_info

    except Exception as e:
        return f"ğŸ“ <strong>{region_name}</strong>\në‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì–´ ì¼ë°˜ì ì¸ ê³„ì ˆ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\n{get_seasonal_weather_info(region_name, datetime.datetime.now().month)}"

def get_seasonal_weather_info(region_name, month):
    """ê³„ì ˆë³„ ì¼ë°˜ì ì¸ ë‚ ì”¨ ì •ë³´ ì œê³µ"""
    seasonal_data = {
        1: {"temp": "ì˜í•˜~5Â°C", "desc": "ì¶¥ê³  ê±´ì¡°", "clothes": "ë‘êº¼ìš´ ì™¸íˆ¬, ëª©ë„ë¦¬ í•„ìˆ˜"},
        2: {"temp": "0~8Â°C", "desc": "ì¶”ìœ„ê°€ ì ˆì •", "clothes": "íŒ¨ë”©, ì¥ê°‘ ê¶Œì¥"},
        3: {"temp": "5~15Â°C", "desc": "ë´„ì˜ ì‹œì‘, ì¼êµì°¨ í¼", "clothes": "ì–‡ì€ ì™¸íˆ¬, ë ˆì´ì–´ë“œ"},
        4: {"temp": "10~20Â°C", "desc": "ë”°ëœ»í•œ ë´„ë‚ ì”¨", "clothes": "ê°€ë””ê±´, ì–‡ì€ ì¬í‚·"},
        5: {"temp": "15~25Â°C", "desc": "í™”ì°½í•˜ê³  ì¾Œì ", "clothes": "ë°˜íŒ”, ê¸´íŒ” ì…”ì¸ "},
        6: {"temp": "20~28Â°C", "desc": "ë”ì›Œì§€ê¸° ì‹œì‘", "clothes": "ë°˜íŒ”, ì„ í¬ë¦¼ í•„ìˆ˜"},
        7: {"temp": "23~32Â°C", "desc": "ë¬´ë¥ê³  ìŠµí•¨, ì¥ë§ˆ", "clothes": "ì‹œì›í•œ ì˜·, ìš°ì‚° ì¤€ë¹„"},
        8: {"temp": "25~33Â°C", "desc": "ê°€ì¥ ë”ìš´ ì‹œê¸°", "clothes": "í†µí’ ì˜ë˜ëŠ” ì˜·"},
        9: {"temp": "20~28Â°C", "desc": "ì„ ì„ í•´ì§€ê¸° ì‹œì‘", "clothes": "ë°˜íŒ”~ì–‡ì€ ê¸´íŒ”"},
        10: {"temp": "15~23Â°C", "desc": "ê°€ì„ ë‹¨í’, ì¾Œì ", "clothes": "ê°€ë””ê±´, ì–‡ì€ ì™¸íˆ¬"},
        11: {"temp": "8~18Â°C", "desc": "ìŒ€ìŒ€í•œ ê°€ì„", "clothes": "ë‘êº¼ìš´ ì™¸íˆ¬ ì¤€ë¹„"},
        12: {"temp": "0~8Â°C", "desc": "ì¶”ìœ„ ì‹œì‘", "clothes": "ì½”íŠ¸, ëª©ë„ë¦¬"}
    }

    info = seasonal_data.get(month, seasonal_data[datetime.datetime.now().month])

    return f"""ğŸŒ¡ï¸ <strong>í‰ê·  ê¸°ì˜¨</strong>: {info['temp']}
â˜ï¸ <strong>ë‚ ì”¨ íŠ¹ì§•</strong>: {info['desc']}
ğŸ‘• <strong>ë³µì¥ ì¶”ì²œ</strong>: {info['clothes']}

ğŸ’¡ <em>ì¼ë°˜ì ì¸ {month}ì›” ë‚ ì”¨ ì •ë³´ì…ë‹ˆë‹¤. ì—¬í–‰ ì „ ìµœì‹  ì˜ˆë³´ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”!</em>"""

def is_weather_query(query):
    """ì¿¼ë¦¬ê°€ ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ íŒë‹¨"""
    weather_keywords = [
        'ë‚ ì”¨', 'ê¸°ì˜¨', 'ì˜¨ë„', 'ë¹„', 'ëˆˆ', 'ë°”ëŒ', 'ìŠµë„', 'ë§‘ìŒ', 'íë¦¼',
        'ê°•ìˆ˜', 'ê¸°ìƒ', 'ì¼ê¸°ì˜ˆë³´', 'ì˜ˆë³´', 'ìš°ì²œ', 'ê°•ìš°', 'í­ìš°', 'íƒœí’',
        'weather', 'ì˜¨ë„ê°€', 'ë¥', 'ì¶¥', 'ì‹œì›', 'ë”°ëœ»'
    ]

    query_lower = query.lower()
    return any(keyword in query_lower for keyword in weather_keywords)

def is_historical_weather_query(query):
    """ì¿¼ë¦¬ê°€ ê³¼ê±° ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ íŒë‹¨"""
    import re

    historical_keywords = [
        'ì§€ë‚œ', 'ì‘ë…„', 'ì „ë…„', 'ê³¼ê±°', 'ì˜ˆì „', 'ì´ì „', 'ì§€ë‚œì£¼', 'ì§€ë‚œë‹¬', 'ì§€ë‚œí•´',
        'ì–´ì œ', 'ê·¸ë•Œ', 'ë‹¹ì‹œ', 'ë…„ì „', 'ë‹¬ì „', 'ì£¼ì „', 'ì¼ì „',
        'ì‘ë…„ ì´ë§˜ë•Œ', 'ì§€ë‚œë²ˆ', 'ê·¸ ë‹¹ì‹œ', 'ëª‡ë…„ì „', 'ëª‡ë‹¬ì „'
    ]

    weather_keywords = [
        'ë‚ ì”¨', 'ê¸°ì˜¨', 'ì˜¨ë„', 'ë¹„', 'ëˆˆ', 'ë°”ëŒ', 'ìŠµë„', 'ê°•ìˆ˜', 'ê¸°ìƒ'
    ]

    query_lower = query.lower()

    # ì¼ë°˜ì ì¸ ê³¼ê±° í‚¤ì›Œë“œ ì²´í¬
    has_historical = any(keyword in query_lower for keyword in historical_keywords)
    has_weather = any(keyword in query_lower for keyword in weather_keywords)

    # êµ¬ì²´ì ì¸ ë‚ ì§œ íŒ¨í„´ ì²´í¬ (ê³¼ê±°ë¡œ ê°„ì£¼)
    date_patterns = [
        r'\d{1,2}ì›”\s*\d{1,2}ì¼',  # 10ì›” 4ì¼
        r'\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼',  # 2023ë…„ 10ì›” 4ì¼
        r'\d{1,2}/\d{1,2}',  # 10/4
        r'\d{4}/\d{1,2}/\d{1,2}',  # 2023/10/4
        r'\d{1,2}-\d{1,2}',  # 10-4
        r'\d{4}-\d{1,2}-\d{1,2}'  # 2023-10-4
    ]

    # ì¶”ê°€ ë‚ ì§œ íŒ¨í„´ë“¤ (ë…„ë„ í¬í•¨)
    additional_patterns = [
        r'20\d{2}ë…„',  # 2023ë…„, 2022ë…„ ë“±
        r'20\d{2}[.-/]\d{1,2}[.-/]\d{1,2}',  # 2023-10-15, 2023.10.15 ë“±
        r'20\d{2}ë…„\s*\d{1,2}ì›”',  # 2023ë…„ 10ì›”
    ]

    date_patterns.extend(additional_patterns)
    has_specific_date = any(re.search(pattern, query_lower) for pattern in date_patterns)

    return (has_historical or has_specific_date) and has_weather

def get_historical_weather_info(region_name, date_str):
    """ê¸°ìƒì²­ APIë¡œ ê³¼ê±° ë‚ ì”¨ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì§€ìƒê´€ì¸¡ ì¼ìë£Œ)"""
    if not WEATHER_API_KEY:
        return "âŒ ê¸°ìƒì²­ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    try:
        # ì§€ì—­ ì¢Œí‘œ ê°€ì ¸ì˜¤ê¸°
        coords = get_coordinates_for_region(region_name)
        if not coords:
            return f"âŒ {region_name}ì˜ ì¢Œí‘œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ë‚ ì§œ í˜•ì‹ ë³€í™˜ (YYYYMMDD)
        try:
            if len(date_str) == 8 and date_str.isdigit():
                formatted_date = date_str
            else:
                # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ íŒŒì‹±
                import re
                # YYYY-MM-DD, YYYY/MM/DD ë“±ì˜ í˜•ì‹ì„ YYYYMMDDë¡œ ë³€í™˜
                date_clean = re.sub(r'[^\d]', '', date_str)
                if len(date_clean) == 8:
                    formatted_date = date_clean
                else:
                    return "âŒ ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì˜ˆ: 20231015, 2023-10-15)"
        except:
            return "âŒ ë‚ ì§œ í˜•ì‹ì„ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ê¸°ìƒì²­ ì§€ìƒê´€ì¸¡ ì¼ìë£Œ API URL
        url = 'http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList'

        params = {
            'serviceKey': WEATHER_API_KEY,
            'pageNo': '1',
            'numOfRows': '1',
            'dataType': 'JSON',
            'dataCd': 'ASOS',
            'dateCd': 'DAY',
            'startDt': formatted_date,
            'endDt': formatted_date,
            'stnIds': get_station_id_for_region(region_name)  # ì§€ì—­ë³„ ê´€ì¸¡ì†Œ ID
        }

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        print(f"ğŸ“… ê³¼ê±° ë‚ ì”¨ ì¡°íšŒ: {region_name} ({formatted_date})")

        response = requests.get(url, params=params, headers=headers, timeout=30)

        if response.status_code == 200:
            try:
                data = response.json()
            except Exception as json_error:
                return f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {json_error}, ì‘ë‹µ: {response.text[:200]}"

            if data['response']['header']['resultCode'] == '00':
                items = data['response']['body']['items']

                if 'item' in items and len(items['item']) > 0:
                    item = items['item'][0]
                    return format_historical_weather_data(item, region_name, formatted_date)
                else:
                    return f"âŒ {formatted_date}ì˜ {region_name} ê´€ì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            else:
                return f"âŒ ê¸°ìƒì²­ API ì˜¤ë¥˜: {data['response']['header']['resultMsg']}"
        else:
            return f"âŒ API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}"

    except Exception as e:
        return f"âŒ ê³¼ê±° ë‚ ì”¨ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {e}"

def get_station_id_for_region(region_name):
    """ì§€ì—­ëª…ì— í•´ë‹¹í•˜ëŠ” ê¸°ìƒê´€ì¸¡ì†Œ ID ë°˜í™˜"""
    station_mapping = {
        # ì£¼ìš” ë„ì‹œë³„ ê´€ì¸¡ì†Œ ID (ASOS)
        'ì„œìš¸': '108',
        'ì„œìš¸íŠ¹ë³„ì‹œ': '108',
        'ë¶€ì‚°': '159',
        'ë¶€ì‚°ê´‘ì—­ì‹œ': '159',
        'ëŒ€êµ¬': '143',
        'ëŒ€êµ¬ê´‘ì—­ì‹œ': '143',
        'ì¸ì²œ': '112',
        'ì¸ì²œê´‘ì—­ì‹œ': '112',
        'ê´‘ì£¼': '156',
        'ê´‘ì£¼ê´‘ì—­ì‹œ': '156',
        'ëŒ€ì „': '133',
        'ëŒ€ì „ê´‘ì—­ì‹œ': '133',
        'ìš¸ì‚°': '152',
        'ìš¸ì‚°ê´‘ì—­ì‹œ': '152',
        'ì œì£¼': '184',
        'ì œì£¼ë„': '184',
        'ì œì£¼íŠ¹ë³„ìì¹˜ë„': '184',
        'ê°•ë¦‰': '105',
        'ê°•ì›': '105',
        'ê°•ì›ë„': '105',
        'ê°•ì›íŠ¹ë³„ìì¹˜ë„': '105',
        'ì¶˜ì²œ': '101',
        'ì›ì£¼': '114',
        'ìˆ˜ì›': '119',
        'ê²½ê¸°': '119',
        'ê²½ê¸°ë„': '119',
        'ì²­ì£¼': '131',
        'ì¶©ë¶': '131',
        'ì¶©ì²­ë¶ë„': '131',
        'ì²œì•ˆ': '232',
        'ì¶©ë‚¨': '232',
        'ì¶©ì²­ë‚¨ë„': '232',
        'ì „ì£¼': '146',
        'ì „ë¶': '146',
        'ì „ë¼ë¶ë„': '146',
        'ì „ë¼ë¶ë„íŠ¹ë³„ìì¹˜ë„': '146',
        'ê´‘ì£¼': '156',
        'ì „ë‚¨': '156',
        'ì „ë¼ë‚¨ë„': '156',
        'ì•ˆë™': '136',
        'ê²½ë¶': '136',
        'ê²½ìƒë¶ë„': '136',
        'ì°½ì›': '155',
        'ê²½ë‚¨': '155',
        'ê²½ìƒë‚¨ë„': '155'
    }

    return station_mapping.get(region_name, '108')  # ê¸°ë³¸ê°’: ì„œìš¸

def format_historical_weather_data(data, region_name, date_str):
    """ê³¼ê±° ë‚ ì”¨ ë°ì´í„° í¬ë§·íŒ…"""
    try:
        # ë‚ ì§œ í¬ë§·íŒ…
        year = date_str[:4]
        month = date_str[4:6]
        day = date_str[6:8]
        formatted_date = f"{year}ë…„ {month}ì›” {day}ì¼"

        weather_text = f"ğŸ“… <strong>{region_name} {formatted_date} ë‚ ì”¨ ê¸°ë¡</strong>\n\n"

        # ê¸°ì˜¨ ì •ë³´
        if 'avgTa' in data and data['avgTa']:
            weather_text += f"ğŸŒ¡ï¸ <strong>í‰ê· ê¸°ì˜¨</strong>: {data['avgTa']}Â°C\n"
        if 'maxTa' in data and data['maxTa']:
            weather_text += f"ğŸ”¥ <strong>ìµœê³ ê¸°ì˜¨</strong>: {data['maxTa']}Â°C\n"
        if 'minTa' in data and data['minTa']:
            weather_text += f"â„ï¸ <strong>ìµœì €ê¸°ì˜¨</strong>: {data['minTa']}Â°C\n"

        # ê°•ìˆ˜ëŸ‰
        if 'sumRn' in data and data['sumRn'] and data['sumRn'].strip():
            rain_amount = float(data['sumRn'])
            if rain_amount > 0:
                weather_text += f"ğŸŒ§ï¸ <strong>ê°•ìˆ˜ëŸ‰</strong>: {data['sumRn']}mm\n"
            else:
                weather_text += f"â˜€ï¸ <strong>ê°•ìˆ˜ëŸ‰</strong>: 0mm (ë§‘ìŒ)\n"
        else:
            weather_text += f"â˜€ï¸ <strong>ê°•ìˆ˜ëŸ‰</strong>: 0mm (ë§‘ìŒ)\n"

        # ë°”ëŒ
        if 'avgWs' in data and data['avgWs']:
            weather_text += f"ğŸ’¨ <strong>í‰ê· í’ì†</strong>: {data['avgWs']}m/s\n"
        if 'maxWs' in data and data['maxWs']:
            weather_text += f"ğŸŒªï¸ <strong>ìµœëŒ€í’ì†</strong>: {data['maxWs']}m/s\n"

        # ìŠµë„
        if 'avgRhm' in data and data['avgRhm']:
            weather_text += f"ğŸ’§ <strong>í‰ê· ìŠµë„</strong>: {data['avgRhm']}%\n"

        # ì¼ì¡°ì‹œê°„
        if 'sumSs' in data and data['sumSs']:
            weather_text += f"â˜€ï¸ <strong>ì¼ì¡°ì‹œê°„</strong>: {data['sumSs']}ì‹œê°„\n"

        return weather_text

    except Exception as e:
        return f"âŒ ê³¼ê±° ë‚ ì”¨ ë°ì´í„° í¬ë§·íŒ… ì˜¤ë¥˜: {e}"

def simplify_historical_weather(historical_weather_text, region_name, date_str):
    """ê³¼ê±° ë‚ ì”¨ ë°ì´í„°ì—ì„œ í‰ê·  ê¸°ì˜¨ë§Œ ì¶”ì¶œí•˜ì—¬ ë‹¨ìˆœí™”"""
    try:
        import re

        # í‰ê· ê¸°ì˜¨ ì •ë³´ ì¶”ì¶œ
        avg_temp_match = re.search(r'ğŸŒ¡ï¸ <strong>í‰ê· ê¸°ì˜¨</strong>: ([^Â°]+)Â°C', historical_weather_text)

        if avg_temp_match:
            avg_temp = avg_temp_match.group(1)
            return f"ğŸŒ¡ï¸ <strong>í‰ê· ê¸°ì˜¨</strong>: {avg_temp}Â°C"
        else:
            # í‰ê· ê¸°ì˜¨ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° ëŒ€ì²´ ì²˜ë¦¬
            return "ğŸŒ¡ï¸ <strong>ê¸°ì˜¨ ì •ë³´</strong>: ë°ì´í„° ì—†ìŒ"

    except Exception as e:
        return f"ğŸŒ¡ï¸ <strong>ê¸°ì˜¨ ì •ë³´</strong>: ì²˜ë¦¬ ì˜¤ë¥˜ ({e})"

def extract_date_from_query(query):
    """ì¿¼ë¦¬ì—ì„œ ë‚ ì§œ ì¶”ì¶œ"""
    import re
    import datetime

    query_lower = query.lower()

    # ìƒëŒ€ì  ë‚ ì§œ íŒ¨í„´
    if 'ì–´ì œ' in query_lower:
        yesterday = datetime.datetime.now() - datetime.timedelta(days=1)
        return yesterday.strftime('%Y%m%d')
    elif 'ì§€ë‚œì£¼' in query_lower:
        last_week = datetime.datetime.now() - datetime.timedelta(days=7)
        return last_week.strftime('%Y%m%d')
    elif 'ì§€ë‚œë‹¬' in query_lower:
        last_month = datetime.datetime.now() - datetime.timedelta(days=30)
        return last_month.strftime('%Y%m%d')
    elif 'ì‘ë…„' in query_lower or 'ì§€ë‚œí•´' in query_lower:
        last_year = datetime.datetime.now() - datetime.timedelta(days=365)
        return last_year.strftime('%Y%m%d')

    # ì ˆëŒ€ì  ë‚ ì§œ íŒ¨í„´ (YYYY-MM-DD, YYYY/MM/DD ë“±)
    date_patterns = [
        r'(\d{4})[.-/](\d{1,2})[.-/](\d{1,2})',  # 2023-10-15, 2023.10.15, 2023/10/15
        r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼',  # 2023ë…„ 10ì›” 15ì¼
        r'(\d{1,2})ì›”\s*(\d{1,2})ì¼',              # 10ì›” 15ì¼ (ì˜¬í•´)
        r'(\d{8})',                                # 20231015
    ]

    for pattern in date_patterns:
        match = re.search(pattern, query)
        if match:
            groups = match.groups()
            try:
                if len(groups) == 3:
                    year, month, day = groups
                    if len(year) == 4:
                        return f"{year}{month.zfill(2)}{day.zfill(2)}"
                elif len(groups) == 2:  # ì›”ì¼ë§Œ ìˆëŠ” ê²½ìš° ì˜¬í•´ë¡œ ê°€ì •
                    month, day = groups
                    current_year = datetime.datetime.now().year
                    return f"{current_year}{month.zfill(2)}{day.zfill(2)}"
                elif len(groups) == 1 and len(groups[0]) == 8:  # YYYYMMDD
                    return groups[0]
            except:
                continue

    return None

def interactive_mode():
    """ëŒ€í™”í˜• ëª¨ë“œ"""
    print("\n" + "="*60)
    print("ğŸŒŸ í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™” ì—¬í–‰ ì¶”ì²œ RAG ì‹œìŠ¤í…œ (Amazon Bedrock)")
    print("="*60)
    print("ì‚¬ìš©ë²•: ì—¬í–‰ ì§€ì—­ê³¼ ê¸°ê°„ì„ ì…ë ¥í•˜ì„¸ìš”")
    print("ì˜ˆì‹œ: 'ë¶€ì‚° 2ë°• 3ì¼ ì—¬í–‰ ì¶”ì²œ', 'ì œì£¼ë„ ë§›ì§‘ ì¶”ì²œ'")
    print("íŠ¹ì§•: SQL í•„í„°ë§ + ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²°í•©í•œ ê³ ì† ê²€ìƒ‰")
    print("AI ëª¨ë¸: Amazon Bedrock Claude")
    print("ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit' ì…ë ¥")
    print("-"*60)
    
    while True:
        try:
            user_input = input("\nğŸ’¬ ì—¬í–‰ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                print("ğŸ‘‹ ì—¬í–‰ ì¶”ì²œ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤!")
                break
                
            if not user_input:
                print("âš ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            
            print("\n" + "-"*40)
            get_travel_recommendation(user_input, stream=True)
            print("-"*40)
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì—¬í–‰ ì¶”ì²œ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤!")
            break
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

# # LangGraph ì—¬í–‰ ëŒ€í™” ì‹œìŠ¤í…œ

# LangGraph ì˜ì¡´ì„± ì„í¬íŠ¸ (ì„ íƒì )
try:
    from langgraph.graph import StateGraph, START, END
    from langgraph.graph.message import add_messages
    LANGGRAPH_AVAILABLE = True
except ImportError:
    print("âš ï¸ LangGraphê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. ê¸°ë³¸ RAG ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
    LANGGRAPH_AVAILABLE = False

class TravelState(TypedDict):
    """ì—¬í–‰ ëŒ€í™” ìƒíƒœ ê´€ë¦¬ë¥¼ ìœ„í•œ TypedDict"""
    messages: List[str]
    query_type: str
    need_rag: bool
    need_search: bool
    need_tool: bool
    need_confirmation: bool  # ì¼ì • í™•ì • ì—¬ë¶€
    history: str
    rag_results: List
    search_results: List
    tool_results: dict
    travel_plan: dict  # êµ¬ì¡°í™”ëœ ì—¬í–‰ ì¼ì •
    user_preferences: dict
    conversation_context: str
    formatted_ui_response: dict  # UIìš© êµ¬ì¡°í™”ëœ ì‘ë‹µ

def classify_query(state: TravelState) -> TravelState:
    """í–¥ìƒëœ ì¿¼ë¦¬ ë¶„ë¥˜ - ì—¬ëŸ¬ ê²½ë¡œ ë™ì‹œ íŒë‹¨ (2ë‹¨ê³„ í”Œë¡œìš° ì§€ì›)"""
    if not state.get("messages"):
        return state

    user_input = state["messages"][-1] if state["messages"] else ""
    user_input_lower = user_input.lower()

    print(f"ğŸ” ì¿¼ë¦¬ ë¶„ë¥˜ ì¤‘: '{user_input}'")

    # ìƒˆë¡œìš´ ì—¬í–‰ ìš”ì²­ ê°ì§€ (ê¸°ì¡´ ì¼ì •ì´ ìˆì„ ë•Œ)
    if state.get("travel_plan"):
        is_new_travel_request = any(keyword in user_input_lower for keyword in [
            "ìƒˆë¡œìš´", "ë‹¤ë¥¸", "ìƒˆë¡œ", "ë‹¤ì‹œ", "ë˜ ë‹¤ë¥¸", "ìƒˆë¡­ê²Œ", "ë‹¤ìŒ",
            "ë°•", "ì¼", "ì—¬í–‰", "ì¶”ì²œ", "ì¼ì •", "ê³„íš"
        ]) and not any(confirm_keyword in user_input_lower for confirm_keyword in [
            "í™•ì •", "ê²°ì •", "ì¢‹ì•„", "ë§ˆìŒì—", "ì´ê±¸ë¡œ"
        ])

        if is_new_travel_request:
            print("ğŸ”„ ìƒˆë¡œìš´ ì—¬í–‰ ì¼ì • ìš”ì²­ ê°ì§€ - ê¸°ì¡´ ìƒíƒœ ì´ˆê¸°í™”")
            # ê¸°ì¡´ ì—¬í–‰ ê³„íš ì´ˆê¸°í™”
            state["travel_plan"] = {}
            state["user_preferences"] = {}
            state["conversation_context"] = ""
            state["formatted_ui_response"] = {}
    
    # ì—¬í–‰ ì¼ì • ì¶”ì²œ ê´€ë ¨ í‚¤ì›Œë“œ
    travel_keywords = ["ì¶”ì²œ", "ì—¬í–‰", "ì¼ì •", "ê³„íš", "ì½”ìŠ¤", "ê°€ë³¼ë§Œí•œ", "ì—¬í–‰ì§€", "ê´€ê´‘"]
    location_keywords = ["ì„œìš¸", "ë¶€ì‚°", "ì œì£¼", "ê²½ê¸°", "ê°•ì›", "ì¥ì†Œ", "ìœ„ì¹˜", "ì–´ë””"]
    food_keywords = ["ë§›ì§‘", "ìŒì‹", "ì‹ë‹¹", "ë¨¹ì„", "ì¹´í˜", "ë ˆìŠ¤í† ë‘"]
    booking_keywords = ["ì˜ˆì•½", "ë“±ë¡", "ì‹ ì²­", "ê²°ì œ", "ì˜ˆë§¤"]
    
    # í™•ì • í‚¤ì›Œë“œ (ê°œì„ ëœ íŒ¨í„´ ë§¤ì¹­)
    strong_confirmation_keywords = ["í™•ì •", "ê²°ì •", "í™•ì¸", "ì´ê±¸ë¡œ", "ì¢‹ì•„", "ë§ì•„", "ê·¸ë˜", "ëì–´", "ì™„ë£Œ", "ok", "ì˜¤ì¼€ì´"]
    weak_confirmation_keywords = ["ì§„í–‰", "ê°€ì", "ì´ê±°ì•¼", "ë„¤", "ì˜ˆ", "ì‘", "ë§ë„¤", "ì¢‹ë„¤"]

    # ë‹¨ì¼ í™•ì • í‚¤ì›Œë“œ (ì§§ì€ ë‹µë³€)
    single_word_confirmations = ["í™•ì •", "ê²°ì •", "ì¢‹ì•„", "ok", "ì˜¤ì¼€ì´", "ë„¤", "ì˜ˆ", "ì‘", "ê·¸ë˜"]

    # ë‚ ì”¨ ìš”ì²­ì¸ì§€ ë¨¼ì € í™•ì¸ (í˜„ì¬/ë¯¸ë˜ + ê³¼ê±° ë‚ ì”¨ ëª¨ë‘ í¬í•¨)
    is_weather_request = is_weather_query(user_input) or is_historical_weather_query(user_input)

    # ë³µí•©ì  ë¶„ë¥˜ ë¡œì§
    need_rag = any(keyword in user_input for keyword in travel_keywords) or is_weather_request
    need_search = any(keyword in user_input for keyword in location_keywords) and not is_weather_request
    need_tool = any(keyword in user_input for keyword in booking_keywords)

    # ìŒì‹ ê´€ë ¨ ì§ˆì˜ë„ RAGë¡œ ì²˜ë¦¬
    if any(keyword in user_input for keyword in food_keywords):
        need_rag = True

    # ê°œì„ ëœ í™•ì • íŒë‹¨ ë¡œì§
    has_strong_confirmation = any(keyword in user_input_lower for keyword in strong_confirmation_keywords)
    has_weak_confirmation = any(keyword in user_input_lower for keyword in weak_confirmation_keywords)

    # ì§§ì€ ë‹¨ì–´ í™•ì • (5ê¸€ì ì´í•˜ì´ë©´ì„œ í™•ì • í‚¤ì›Œë“œë§Œ ìˆëŠ” ê²½ìš°)
    is_short_confirmation = (len(user_input_lower.strip()) <= 5 and
                            any(keyword == user_input_lower.strip() for keyword in single_word_confirmations))

    # í˜„ì¬ ìƒíƒœì— ì—¬í–‰ ì¼ì •ì´ ìˆëŠ”ì§€ í™•ì¸
    has_travel_plan = bool(state.get("travel_plan"))

    print(f"   ğŸ” í™•ì • ë¶„ì„: ê°•í•œí™•ì •={has_strong_confirmation}, ì•½í•œí™•ì •={has_weak_confirmation}, ì§§ì€í™•ì •={is_short_confirmation}")
    print(f"   ğŸ“‹ ì—¬í–‰ê³„íšì¡´ì¬={has_travel_plan}, RAGí•„ìš”={need_rag}")

    # í™•ì • íŒë‹¨ ìš°ì„ ìˆœìœ„:
    # 1. ì—¬í–‰ ì¼ì •ì´ ìˆê³  ê°•í•œ í™•ì • í‚¤ì›Œë“œ â†’ í™•ì •
    # 2. ì—¬í–‰ ì¼ì •ì´ ìˆê³  ì§§ì€ í™•ì • ì‘ë‹µ â†’ í™•ì •
    # 3. ì—¬í–‰ ì¼ì •ì´ ìˆê³  ì•½í•œ í™•ì • í‚¤ì›Œë“œ (RAGê°€ ì•„ë‹ ë•Œ) â†’ í™•ì •
    need_confirmation = False
    if has_travel_plan:
        if has_strong_confirmation or is_short_confirmation:
            need_confirmation = True
            print(f"   âœ… í™•ì • íŒë‹¨: ê°•í•œ í™•ì • ë˜ëŠ” ì§§ì€ í™•ì •")
        elif has_weak_confirmation and not need_rag:
            need_confirmation = True
            print(f"   âœ… í™•ì • íŒë‹¨: ì•½í•œ í™•ì • (RAG ì•„ë‹˜)")
        else:
            print(f"   âŒ í™•ì • ë¶ˆê°€: ì¡°ê±´ ë¶ˆì¶©ì¡±")
    else:
        print(f"   âŒ í™•ì • ë¶ˆê°€: ì—¬í–‰ ì¼ì • ì—†ìŒ")
    
    query_type = "complex" if sum([need_rag, need_search, need_tool]) > 1 else "simple"
    
    print(f"   ë¶„ë¥˜ ê²°ê³¼ - RAG: {need_rag}, Search: {need_search}, Tool: {need_tool}, í™•ì •: {need_confirmation}")
    print(f"   ì—¬í–‰ ì¼ì • ì¡´ì¬: {has_travel_plan}")
    
    return {
        **state,
        "need_rag": need_rag,
        "need_search": need_search,
        "need_tool": need_tool,
        "need_confirmation": need_confirmation,
        "query_type": query_type
    }

def rag_processing_node(state: TravelState) -> TravelState:
    """RAG ê¸°ë°˜ ì—¬í–‰ì§€ ì¶”ì²œ ì²˜ë¦¬ ë…¸ë“œ (ê°œì„ ëœ êµ¬ì¡°í™” ë°ì´í„° í¬í•¨)"""
    if not state.get("messages"):
        return {
            **state,
            "conversation_context": "ì²˜ë¦¬í•  ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤."
        }

    user_query = state["messages"][-1]
    print(f"ğŸ§  RAG ì²˜ë¦¬ ì‹œì‘: '{user_query}'")

    # ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸
    if is_weather_query(user_query):
        # ê³¼ê±° ë‚ ì”¨ ìš”ì²­ì¸ì§€ í™•ì¸
        if is_historical_weather_query(user_query):
            print("ğŸ“… ê³¼ê±° ë‚ ì”¨ ìš”ì²­ ê°ì§€ë¨")

            # ì¿¼ë¦¬ì—ì„œ ì§€ì—­ëª…ê³¼ ë‚ ì§œ ì¶”ì¶œ (ì»¨í…ìŠ¤íŠ¸ ìš°ì„ )
            region = extract_region_from_query(user_query)
            if not region:
                region = extract_region_from_context(state)
            date_str = extract_date_from_query(user_query)

            print(f"ğŸ” ë””ë²„ê¹…: region='{region}', date_str='{date_str}'")

            if region and date_str:
                print(f"ğŸ“ ê°ì§€ëœ ì§€ì—­: {region}, ë‚ ì§œ: {date_str}")
                weather_info = get_historical_weather_info(region, date_str)

                return {
                    **state,
                    "conversation_context": weather_info
                }
            elif region and not date_str:
                return {
                    **state,
                    "conversation_context": f"ğŸ¤” {region}ì˜ ê³¼ê±° ë‚ ì”¨ë¥¼ ì¡°íšŒí•˜ë ¤ë©´ êµ¬ì²´ì ì¸ ë‚ ì§œë¥¼ í•¨ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”.\nì˜ˆ: 'ì„œìš¸ ì–´ì œ ë‚ ì”¨', 'ë¶€ì‚° 2023ë…„ 10ì›” 15ì¼ ë‚ ì”¨'"
                }
            elif not region and date_str:
                # ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§€ì—­ ì°¾ê¸° ì‹œë„
                context_region = extract_region_from_context(state)

                # ê¸€ë¡œë²Œ ìƒíƒœì—ì„œë„ ì°¾ê¸° ì‹œë„
                if not context_region:
                    global current_travel_state
                    if current_travel_state.get("travel_plan", {}).get("region"):
                        context_region = current_travel_state["travel_plan"]["region"]

                if context_region:
                    print(f"ğŸ“ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë°œê²¬ëœ ì§€ì—­: {context_region}")
                    weather_info = get_historical_weather_info(context_region, date_str)
                    return {
                        **state,
                        "conversation_context": f"ğŸ“ <strong>{context_region}</strong>ì˜ ê³¼ê±° ë‚ ì”¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\n\n{weather_info}"
                    }

                return {
                    **state,
                    "conversation_context": f"ğŸ¤” ê³¼ê±° ë‚ ì”¨ë¥¼ ì¡°íšŒí•˜ë ¤ë©´ ì§€ì—­ëª…ì„ í•¨ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”.\nì˜ˆ: 'ì„œìš¸ ì–´ì œ ë‚ ì”¨', 'ë¶€ì‚° ì§€ë‚œì£¼ ë‚ ì”¨'"
                }
            else:
                return {
                    **state,
                    "conversation_context": "ğŸ¤” ê³¼ê±° ë‚ ì”¨ ì •ë³´ë¥¼ ì œê³µí•˜ë ¤ë©´ ì§€ì—­ëª…ê³¼ ë‚ ì§œë¥¼ í•¨ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”.\nì˜ˆ: 'ì„œìš¸ ì–´ì œ ë‚ ì”¨', 'ë¶€ì‚° 2023ë…„ 10ì›” 15ì¼ ë‚ ì”¨'"
                }
        else:
            # í˜„ì¬/ë¯¸ë˜ ë‚ ì”¨ ìš”ì²­
            print("ğŸŒ¤ï¸ í˜„ì¬/ë¯¸ë˜ ë‚ ì”¨ ìš”ì²­ ê°ì§€ë¨")

            # ì¿¼ë¦¬ì—ì„œ ì§€ì—­ëª… ì¶”ì¶œ (ì»¨í…ìŠ¤íŠ¸ ìš°ì„ )
            region = extract_region_from_query(user_query)
            if not region:
                region = extract_region_from_context(state)

            if region:
                print(f"ğŸ“ ê°ì§€ëœ ì§€ì—­: {region}")
                weather_info = get_weather_info(region)

                return {
                    **state,
                    "conversation_context": weather_info
                }
            else:
                # ì§€ì—­ëª…ì´ ì—†ìœ¼ë©´ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§€ì—­ ì°¾ê¸° ì‹œë„
                context_region = extract_region_from_context(state)

                if context_region:
                    print(f"ğŸ“ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë°œê²¬ëœ ì§€ì—­: {context_region}")
                    weather_info = get_weather_info(context_region)
                    return {
                        **state,
                        "conversation_context": f"ğŸ“ <strong>{context_region}</strong>ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.\n\n{weather_info}"
                    }

                return {
                    **state,
                    "conversation_context": "ğŸ¤” ë‚ ì”¨ ì •ë³´ë¥¼ ì œê³µí•˜ë ¤ë©´ ì§€ì—­ëª…ì„ í•¨ê»˜ ë§ì”€í•´ì£¼ì„¸ìš”. (ì˜ˆ: 'ì„œìš¸ ë‚ ì”¨', 'ë¶€ì‚° ë‚ ì”¨')"
                }

    try:
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ ì‹¤ì œ ì¥ì†Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        docs = retriever._get_relevant_documents(user_query)
        
        # ì§€ì—­ í•„í„°ë§ ê°•í™” - ì¿¼ë¦¬ì—ì„œ ì§€ì—­ëª… ì¶”ì¶œí•˜ì—¬ í•´ë‹¹ ì§€ì—­ ê²°ê³¼ë§Œ ìš°ì„ 
        region_keywords = {
            'ë¶€ì‚°': ['ë¶€ì‚°', 'busan', 'í•´ìš´ëŒ€', 'ê´‘ì•ˆë¦¬', 'ë‚¨í¬ë™', 'ì„œë©´', 'ê¸°ì¥', 'ë™ë˜', 'ì‚¬í•˜', 'ë¶êµ¬', 'ë™êµ¬', 'ì„œêµ¬', 'ì¤‘êµ¬', 'ì˜ë„', 'ë¶€ì‚°ì§„', 'ì—°ì œ', 'ìˆ˜ì˜', 'ì‚¬ìƒ', 'ê¸ˆì •', 'ê°•ì„œ', 'í•´ìš´ëŒ€êµ¬', 'ì‚¬í•˜êµ¬'],
            'ì„œìš¸': ['ì„œìš¸', 'seoul', 'ê°•ë‚¨', 'í™ëŒ€', 'ëª…ë™', 'ì´íƒœì›', 'ì¸ì‚¬ë™', 'ì¢…ë¡œ'],
            'ì œì£¼ë„': ['ì œì£¼ë„', 'ì œì£¼', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„', 'ì„œê·€í¬', 'í•œë¼ì‚°', 'ì„±ì‚°', 'ìš°ë„'],
            'ê²½ì£¼': ['ê²½ì£¼', 'ë¶ˆêµ­ì‚¬', 'ì„êµ´ì•”', 'ì²¨ì„±ëŒ€'],
            'ì „ì£¼': ['ì „ì£¼', 'í•œì˜¥ë§ˆì„', 'ì „ë¼ë¶ë„'],
            'ëŒ€êµ¬': ['ëŒ€êµ¬', 'daegu', 'ë™ì„±ë¡œ'],
            'ê´‘ì£¼': ['ê´‘ì£¼', 'ë¬´ë“±ì‚°'],
            'ì¶˜ì²œ': ['ì¶˜ì²œ', 'ë‚¨ì´ì„¬', 'ì†Œì–‘ê°•', 'ê°•ì›ë„'],
            'ê°•ë¦‰': ['ê°•ë¦‰', 'ê²½í¬ëŒ€', 'ì •ë™ì§„', 'ê°•ë¦‰ì‹œ', 'ì‚¬ì²œí•´ë³€', 'ë‚¨í•­ì§„', 'ê²½í¬í•´ë³€', 'ì•ˆëª©í•´ë³€', 'ì£¼ë¬¸ì§„', 'ì˜¤ì£½í—Œ', 'ì°¸ì†Œë¦¬ë°•ë¬¼ê´€'],
            'ì—¬ìˆ˜': ['ì—¬ìˆ˜', 'ì˜¤ë™ë„', 'ì „ë¼ë‚¨ë„'],
            'ì¸ì²œ': ['ì¸ì²œ', 'ì°¨ì´ë‚˜íƒ€ìš´', 'ì›”ë¯¸ë„']
        }
        
        query_regions = []
        target_keywords = []
        
        for region, keywords in region_keywords.items():
            for keyword in keywords:
                if keyword in user_query.lower():
                    query_regions.append(region)
                    target_keywords.extend(keywords)
                    break
        
        # ì§€ì—­ í•„í„°ë§ ê°œì„  (ë” í¬ê´„ì ìœ¼ë¡œ)
        if query_regions:
            print(f"ğŸ¯ ì§€ì—­ í•„í„°ë§: {query_regions}")
            region_docs = []
            
            for doc in docs:
                doc_region = doc.metadata.get('region', '').lower()
                doc_city = doc.metadata.get('city', '').lower()
                
                # í¬ê´„ì ì¸ ì§€ì—­ ë§¤ì¹­
                is_relevant = False
                for region in query_regions:
                    region_lower = region.lower()
                    
                    # 1. ì •í™•í•œ ì§€ì—­ëª… ë§¤ì¹­
                    if region_lower in doc_region:
                        is_relevant = True
                        break
                    
                    # 2. íŠ¹ì • ì§€ì—­ ìš”ì²­ ì‹œ í•´ë‹¹ ê´‘ì—­ì‹œ/ë„ ì „ì²´ í¬í•¨
                    elif 'ê°•ë¦‰' in region_lower and 'ê°•ì›' in doc_region:
                        is_relevant = True  # ê°•ë¦‰ ìš”ì²­ ì‹œ ê°•ì›ë„ ì „ì²´ í¬í•¨
                        break
                    elif 'ë¶€ì‚°' in region_lower and ('ë¶€ì‚°' in doc_region or 'ë¶€ì‚°' in doc_city):
                        is_relevant = True  # ë¶€ì‚° ìš”ì²­ ì‹œ ë¶€ì‚° ì „ì²´ í¬í•¨
                        break  
                    elif 'ì„œìš¸' in region_lower and ('ì„œìš¸' in doc_region or 'ì„œìš¸' in doc_city):
                        is_relevant = True  # ì„œìš¸ ìš”ì²­ ì‹œ ì„œìš¸ ì „ì²´ í¬í•¨
                        break
                    elif 'ì œì£¼' in region_lower and 'ì œì£¼' in doc_region:
                        is_relevant = True  # ì œì£¼ ìš”ì²­ ì‹œ ì œì£¼ë„ ì „ì²´ í¬í•¨
                        break
                
                if is_relevant:
                    region_docs.append(doc)
            
            if region_docs:
                docs = region_docs[:50]  # ë” ë§ì€ ê²°ê³¼ í—ˆìš©
                print(f"ğŸ“ ì§€ì—­ í•„í„°ë§ ê²°ê³¼: {len(docs)}ê°œ ë¬¸ì„œ ì„ ë³„")
            else:
                print(f"âš ï¸ ì§€ì—­ í•„í„°ë§ ê²°ê³¼ ì—†ìŒ, ì „ì²´ ê²°ê³¼ ì‚¬ìš©")
                docs = docs[:50]
        
        # êµ¬ì¡°í™”ëœ ì¥ì†Œ ë°ì´í„° ì¶”ì¶œ
        structured_places = extract_structured_places(docs)
        
        # ê°œì„ ëœ ì—¬í–‰ ì¼ì • ìƒì„± í”„ë¡¬í”„íŠ¸
        # ì§€ì—­ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        region_context = f" ë°˜ë“œì‹œ {', '.join(query_regions)} ì§€ì—­ ë‚´ì˜ ì¥ì†Œë§Œ ì¶”ì²œí•˜ì„¸ìš”." if query_regions else ""
        
        enhanced_prompt = ChatPromptTemplate.from_template(f"""
ë‹¹ì‹ ì€ ì—¬í–‰ ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì—¬í–‰ì§€ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¹”ë”í•˜ê³  êµ¬ì¡°í™”ëœ ì—¬í–‰ ì¼ì •ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.{region_context}

ì—¬í–‰ì§€ ì •ë³´:
{{context}}

ì‚¬ìš©ì ì§ˆë¬¸: {{question}}

ì¤‘ìš”í•œ ì œì•½ì‚¬í•­:
- ì£¼ì–´ì§„ ì—¬í–‰ì§€ ì •ë³´ì— í¬í•¨ëœ ì¥ì†Œë“¤ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
- ê° ì¼ì°¨ë³„ë¡œ ì‹œê°„ëŒ€ì— ë§ëŠ” ì ì ˆí•œ ì¥ì†Œë¥¼ ë°°ì¹˜í•˜ì„¸ìš”
- ê°™ì€ ì§€ì—­ ë‚´ì—ì„œë§Œ ì¼ì •ì„ êµ¬ì„±í•˜ì„¸ìš”

ì¶œë ¥ í˜•ì‹ì„ ë‹¤ìŒê³¼ ê°™ì´ ë§ì¶°ì£¼ì„¸ìš”:

ğŸï¸ <strong>ì§€ì—­ëª… ì—¬í–‰ ì¼ì •</strong>

<strong>[1ì¼ì°¨]</strong>
â€¢ 09:00-12:00 <strong>ì¥ì†Œëª…</strong> - ê°„ë‹¨í•œ ì„¤ëª… (1ì¤„)
â€¢ 12:00-13:00 <strong>ì‹ë‹¹ëª…</strong> - ìŒì‹ ì¢…ë¥˜ ì ì‹¬
â€¢ 14:00-17:00 <strong>ì¥ì†Œëª…</strong> - ê°„ë‹¨í•œ ì„¤ëª… (1ì¤„)
â€¢ 18:00-19:00 <strong>ì‹ë‹¹ëª…</strong> - ìŒì‹ ì¢…ë¥˜ ì €ë…

<strong>[2ì¼ì°¨]</strong> (ê¸°ê°„ì— ë”°ë¼ ì¶”ê°€)
...

ğŸ’¡ <strong>ì—¬í–‰ íŒ</strong>: ì§€ì—­ íŠ¹ìƒ‰ì´ë‚˜ ì£¼ì˜ì‚¬í•­

ì´ ì¼ì •ìœ¼ë¡œ í™•ì •í•˜ì‹œê² ì–´ìš”?

ë‹µë³€:
        """)
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = format_docs(docs)
        
        # LLMìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„±
        prompt_value = enhanced_prompt.invoke({"context": context, "question": user_query})
        raw_response = llm.invoke(prompt_value).content
        
        # ê°€ë…ì„±ì„ ìœ„í•œ ê°œí–‰ ì²˜ë¦¬
        formatted_response = format_travel_response_with_linebreaks(raw_response)
        
        # ìƒì„¸í•œ ì—¬í–‰ ì¼ì • íŒŒì‹± (ì‹¤ì œ ì¥ì†Œ ë°ì´í„° í¬í•¨)
        travel_plan = parse_enhanced_travel_plan(formatted_response, user_query, structured_places)
        
        # UIìš© êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„±
        formatted_ui_response = create_formatted_ui_response(travel_plan, formatted_response)
        
        # ì—¬í–‰ ì¼ì • ìƒì„± ì™„ë£Œ - ì‚¬ìš©ì í™•ì¸ ëŒ€ê¸° ìƒíƒœ
        # ìë™ í™•ì •í•˜ì§€ ì•Šê³  ì‚¬ìš©ìì˜ í™•ì • ì˜ì‚¬ë¥¼ ê¸°ë‹¤ë¦¼

        # ğŸŒ¤ï¸ ì—¬í–‰ì§€ ë‚ ì”¨ ì •ë³´ ìë™ ì¶”ê°€
        region_for_weather = travel_plan.get('region', '') or extract_region_from_query(user_query)
        if region_for_weather:
            print(f"ğŸŒ¤ï¸ {region_for_weather} ë‚ ì”¨ ì •ë³´ ì¡°íšŒ ì¤‘...")
            weather_info = get_smart_weather_info(region_for_weather)

            # ì—¬í–‰ ì¼ì •ì— ë‚ ì”¨ ì •ë³´ í†µí•© (ì—¬í–‰ íŒ ì•ì— ì‚½ì…)
            if weather_info and not weather_info.startswith("âŒ"):
                # "ğŸ’¡ ì—¬í–‰ íŒ" ì•ì— ë‚ ì”¨ ì •ë³´ ì‚½ì…
                if "ğŸ’¡" in formatted_response:
                    parts = formatted_response.split("ğŸ’¡", 1)
                    formatted_response_with_weather = f"""{parts[0]}

{weather_info}

ğŸ’¡{parts[1]}"""
                else:
                    # ì—¬í–‰ íŒì´ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ì— ì¶”ê°€
                    formatted_response_with_weather = f"""{formatted_response}

{weather_info}"""
            else:
                formatted_response_with_weather = formatted_response
        else:
            formatted_response_with_weather = formatted_response

        print(f"âœ… RAG ì²˜ë¦¬ ì™„ë£Œ. ê²°ê³¼ ê¸¸ì´: {len(formatted_response_with_weather)}")
        print(f"   ì¶”ì¶œëœ ì¥ì†Œ ìˆ˜: {len(structured_places)}")

        return {
            **state,
            "rag_results": docs,
            "travel_plan": travel_plan,
            "conversation_context": formatted_response_with_weather,
            "formatted_ui_response": formatted_ui_response
        }
        
    except Exception as e:
        print(f"âŒ RAG ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {
            **state,
            "rag_results": [],
            "conversation_context": f"ì—¬í–‰ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }

def search_processing_node(state: TravelState) -> TravelState:
    """ì¥ì†Œ ê²€ìƒ‰ ì²˜ë¦¬ ë…¸ë“œ"""
    if not state.get("messages"):
        return {
            **state,
            "conversation_context": "ê²€ìƒ‰í•  ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤."
        }
    
    user_query = state["messages"][-1]
    print(f"ğŸ“ ì¥ì†Œ ê²€ìƒ‰ ì²˜ë¦¬: '{user_query}'")
    
    try:
        # ê¸°ì¡´ search_places í•¨ìˆ˜ ì‚¬ìš©
        docs = search_places(user_query)

        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°„ë‹¨í•˜ê²Œ í¬ë§·íŒ…
        if docs:
            search_summary = ""  # ë¶ˆí•„ìš”í•œ "Nê°œ ì°¾ì•˜ìŠµë‹ˆë‹¤" ë©”ì‹œì§€ ì œê±°
        else:
            search_summary = "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        return {
            **state,
            "search_results": docs,
            "conversation_context": search_summary
        }
        
    except Exception as e:
        print(f"âŒ ì¥ì†Œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {
            **state,
            "search_results": [],
            "conversation_context": f"ì¥ì†Œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }

def tool_execution_node(state: TravelState) -> TravelState:
    """ì˜ˆì•½/ë“±ë¡ ì²˜ë¦¬ ë…¸ë“œ"""
    if not state.get("messages"):
        return state
    
    user_query = state["messages"][-1]
    print(f"ğŸ”§ ë„êµ¬ ì‹¤í–‰: '{user_query}'")
    
    # ì‹¤ì œ ì˜ˆì•½ ì‹œìŠ¤í…œ ì—°ë™ì€ í–¥í›„ êµ¬í˜„
    # í˜„ì¬ëŠ” ëª¨ì˜ ì‘ë‹µ ì œê³µ
    mock_result = {
        "status": "pending",
        "message": "ì˜ˆì•½ ê¸°ëŠ¥ì€ í˜„ì¬ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. ê³ ê°ì„¼í„°ë¡œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.",
        "action_required": "manual_booking"
    }
    
    return {
        **state,
        "tool_results": mock_result
    }

def general_chat_node(state: TravelState) -> TravelState:
    """ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬ ë…¸ë“œ"""
    if not state.get("messages"):
        return state
    
    user_query = state["messages"][-1]
    print(f"ğŸ’¬ ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬: '{user_query}'")
    
    # ê°„ë‹¨í•œ ì¼ë°˜ ëŒ€í™” ì‘ë‹µ
    general_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì¹œê·¼í•œ ì—¬í–‰ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë©° ì—¬í–‰ ê´€ë ¨ ë„ì›€ì„ ì œê³µí•˜ì„¸ìš”.

ì‚¬ìš©ì ë©”ì‹œì§€: {question}

ë‹µë³€ ì§€ì¹¨:
- ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- ì—¬í–‰ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì´ë©´ êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ìš”ì²­í•˜ì„¸ìš”
- ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”

ë‹µë³€:
    """)
    
    try:
        prompt_value = general_prompt.invoke({"question": user_query})
        response = llm.invoke(prompt_value).content
        
        return {
            **state,
            "conversation_context": response
        }
        
    except Exception as e:
        print(f"âŒ ì¼ë°˜ ëŒ€í™” ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {
            **state,
            "conversation_context": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        }

def normalize_place_name(place_name: str) -> str:
    """ì¥ì†Œëª… ì •ê·œí™” (ë§¤ì¹­ ì •í™•ë„ í–¥ìƒ)"""
    if not place_name:
        return ""

    # ì ‘ë‘ì–´ ì œê±°
    name = place_name.strip()
    if name.startswith("ì´ë¦„: "):
        name = name[3:].strip()
    if name.startswith("<strong>"):
        name = name[8:].strip()
    if name.endswith("</strong>"):
        name = name[:-9].strip()

    # ê³µë°± ì •ë¦¬
    name = ' '.join(name.split())

    return name.lower()

def find_place_in_itinerary(place_name: str, itinerary: list) -> int:
    """ì¼ì •ì—ì„œ ì¥ì†Œê°€ ì†í•œ ì¼ì°¨ ì°¾ê¸° (ê°œì„ ëœ ë§¤ì¹­)"""
    normalized_place = normalize_place_name(place_name)

    for day_info in itinerary:
        day_num = day_info.get("day", 1)

        for schedule in day_info.get("schedule", []):
            schedule_place = normalize_place_name(schedule.get("place_name", ""))

            # ì •í™•í•œ ë§¤ì¹­
            if normalized_place == schedule_place:
                return day_num

            # í¬í•¨ ê´€ê³„ ë§¤ì¹­ (ë” ê¸´ ì´ë¦„ì´ ì§§ì€ ì´ë¦„ì„ í¬í•¨)
            if len(normalized_place) >= 2 and len(schedule_place) >= 2:
                if (normalized_place in schedule_place and len(normalized_place) >= len(schedule_place) * 0.5) or \
                   (schedule_place in normalized_place and len(schedule_place) >= len(normalized_place) * 0.5):
                    return day_num

    return 0  # ë§¤ì¹­ë˜ì§€ ì•ŠìŒ

def extract_places_by_day(itinerary: list) -> dict:
    """ì¼ì°¨ë³„ë¡œ ì¥ì†Œ ëª©ë¡ ì¶”ì¶œ"""
    places_by_day = {}

    for day_info in itinerary:
        day_num = day_info.get("day", 1)
        places_by_day[day_num] = []

        for schedule in day_info.get("schedule", []):
            place_name = normalize_place_name(schedule.get("place_name", ""))
            if place_name and place_name not in places_by_day[day_num]:
                places_by_day[day_num].append(place_name)

    return places_by_day

def confirmation_processing_node(state: TravelState) -> TravelState:
    """ì¼ì • í™•ì • ì²˜ë¦¬ ë…¸ë“œ (2ë‹¨ê³„ í”Œë¡œìš°)"""
    print(f"ğŸ¯ í™•ì • ì²˜ë¦¬ ìš”ì²­")

    # ë””ë²„ê¹… ì •ë³´
    current_travel_plan = state.get("travel_plan", {})
    global_travel_plan = current_travel_state.get("travel_plan", {})
    print(f"   ğŸ“‹ State travel_plan: {bool(current_travel_plan)}")
    print(f"   ğŸŒ Global travel_plan: {bool(global_travel_plan)}")

    # í˜„ì¬ ìƒíƒœì— ì—¬í–‰ ì¼ì •ì´ ì—†ìœ¼ë©´ ì „ì—­ ìƒíƒœ í™•ì¸
    if not current_travel_plan:
        if global_travel_plan:
            print(f"   ğŸ”„ ì „ì—­ ìƒíƒœì—ì„œ ì—¬í–‰ ê³„íš ë³µì›")
            state["travel_plan"] = global_travel_plan
            current_travel_plan = global_travel_plan

    # ì—¬ì „íˆ ì—¬í–‰ ì¼ì •ì´ ì—†ìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€
    if not current_travel_plan:
        response = """
ğŸ¤” <strong>í™•ì •í•˜ê³  ì‹¶ìœ¼ì‹  ì—¬í–‰ ì¼ì •ì´ ì—†ëŠ” ê²ƒ ê°™ì•„ìš”!</strong>

ğŸ“ <strong>í™•ì • ì ˆì°¨</strong>:
1. ë¨¼ì € ì—¬í–‰ ì¼ì •ì„ ìš”ì²­í•´ì£¼ì„¸ìš”
   ì˜ˆ: "ë¶€ì‚° 3ë°• 4ì¼ ì—¬í–‰ ì¶”ì²œí•´ì¤˜"
2. ìƒì„±ëœ ì¼ì •ì„ í™•ì¸í•˜ì‹  í›„
3. "í™•ì •", "ì¢‹ì•„", "ì´ê±¸ë¡œ í•´ì¤˜" ë“±ìœ¼ë¡œ í™•ì • ì˜ì‚¬ë¥¼ í‘œí˜„í•´ì£¼ì„¸ìš”

âœˆï¸ ê·¸ëŸ¬ë©´ ë°”ë¡œ ì§€ë„ì—ì„œ ì—¬í–‰ì§€ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”!

ğŸ’¡ ì§€ê¸ˆ ë°”ë¡œ ì–´ë–¤ ì—¬í–‰ ì¼ì •ì„ ì›í•˜ì‹œëŠ”ì§€ ë§ì”€í•´ì£¼ì„¸ìš”!
        """.strip()
        
        return {
            **state,
            "conversation_context": response,
            "tool_results": {
                "action": "request_travel_plan",
                "message": "ì—¬í–‰ ì¼ì • ë¨¼ì € ìš”ì²­ í•„ìš”"
            }
        }
    
    print(f"âœ… ì—¬í–‰ ì¼ì • í™•ì • ì²˜ë¦¬")
    
    travel_plan = state["travel_plan"]
    
    # ì¼ì • í™•ì • ì²˜ë¦¬
    from datetime import datetime
    confirmed_plan = {
        **travel_plan,
        "status": "confirmed",
        "confirmed_at": datetime.now().isoformat(),
        "ready_for_booking": True,
        "plan_id": generate_plan_id()  # ê³ ìœ  ID ìƒì„±
    }
    
    # í™•ì • ì‘ë‹µ ìƒì„±
    itinerary_summary = ""
    if confirmed_plan.get("duration"):
        # durationì—ì„œ ì¼ìˆ˜ ì •ë³´ ì¶”ì¶œí•˜ì—¬ í‘œì‹œ
        duration_str = confirmed_plan["duration"]
        itinerary_summary = f"{duration_str} ì¼ì •"
    elif "itinerary" in confirmed_plan and confirmed_plan["itinerary"]:
        itinerary_summary = f"ì´ {len(confirmed_plan['itinerary'])}ì¼ ì¼ì •"
    
    places_summary = ""
    if "places" in confirmed_plan and confirmed_plan["places"]:
        place_names = [place["name"] for place in confirmed_plan["places"][:3] if place["name"]]
        if place_names:
            places_summary = f"ì£¼ìš” ë°©ë¬¸ì§€: {', '.join(place_names)}"
            if len(confirmed_plan["places"]) > 3:
                places_summary += f" ì™¸ {len(confirmed_plan['places']) - 3}ê³³"
    
    # ì§€ë„ í‘œì‹œë¥¼ ìœ„í•œ ì¥ì†Œ íŒŒë¼ë¯¸í„° êµ¬ì„± (ë©”íƒ€ë°ì´í„° í™œìš©)
    places_list = []
    day_numbers_list = []
    source_tables_list = []

    if "places" in confirmed_plan and confirmed_plan["places"]:
        total_days = len(confirmed_plan.get("itinerary", []))
        if total_days == 0:
            total_days = 1

        # ì¥ì†Œë¥¼ ì¼ì°¨ë³„ë¡œ ì •í™•í•˜ê²Œ ë°°ì¹˜ (ê°œì„ ëœ ë§¤ì¹­)
        places_to_process = confirmed_plan["places"]  # ëª¨ë“  ì¥ì†Œ í¬í•¨

        # ì¼ì°¨ë³„ ì¥ì†Œ ëª©ë¡ ì¶”ì¶œ (ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´)
        itinerary = confirmed_plan.get("itinerary", [])
        places_by_day = extract_places_by_day(itinerary)

        print(f"ğŸ—“ï¸ ì¼ì°¨ë³„ ì¥ì†Œ ë¶„ì„: {places_by_day}")

        for idx, place in enumerate(places_to_process):
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì§ì ‘ ì •ë³´ ì¶”ì¶œ (ë²¡í„° ì—…ë°ì´íŠ¸ í›„)
            table_name = place.get("table_name", "nature")
            place_id = place.get("place_id")

            # place_idê°€ ì—†ê±°ë‚˜ "1"ì´ë©´ ìŠ¤í‚µ (ë¬´ë“±ì‚° ì£¼ìƒì ˆë¦¬ëŒ€ ë°©ì§€)
            if not place_id or place_id == "1":
                print(f"âš ï¸ place_id ì—†ìŒ - ì¥ì†Œ '{place.get('name', 'Unknown')}' ìŠ¤í‚µ")
                continue

            # ì¥ì†Œ ID ìƒì„± (table_name_place_id í˜•íƒœ)
            place_identifier = f"{table_name}_{place_id}"

            places_list.append(place_identifier)
            source_tables_list.append(table_name)

            # ê°œì„ ëœ ì¼ì°¨ ë§¤ì¹­
            place_name = place.get("name", "")
            day_num = find_place_in_itinerary(place_name, itinerary)

            # ë§¤ì¹­ë˜ì§€ ì•Šì€ ê²½ìš° ì²˜ë¦¬
            if day_num == 0:
                print(f"âš ï¸ '{place_name}' ë§¤ì¹­ ì‹¤íŒ¨, ëŒ€ì•ˆ ë°©ë²• ì‹œë„")

                # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì ì ˆí•œ ì¼ì°¨ì— ë°°ì¹˜
                category = place.get("category", "")

                if "ì‹ë‹¹" in category or "ë§›ì§‘" in category or "ìŒì‹" in category:
                    # ì‹ì‚¬ ì¥ì†ŒëŠ” ê¸°ì¡´ ì‹ì‚¬ ì‹œê°„ëŒ€ê°€ ìˆëŠ” ì¼ì°¨ì— ë°°ì¹˜
                    for day_info in itinerary:
                        for schedule in day_info.get("schedule", []):
                            if any(keyword in schedule.get("description", "") for keyword in ["ì ì‹¬", "ì €ë…", "ì‹ì‚¬"]):
                                day_num = day_info.get("day", 1)
                                break
                        if day_num > 0:
                            break

                # ì—¬ì „íˆ ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ ê°€ì¥ ì ì€ ì¥ì†Œê°€ ìˆëŠ” ì¼ì°¨ì— ë°°ì¹˜
                if day_num == 0:
                    if places_by_day:
                        min_places_day = min(places_by_day.keys(), key=lambda x: len(places_by_day[x]))
                        day_num = min_places_day
                    else:
                        # ìµœí›„ì˜ ìˆ˜ë‹¨: ìˆœì„œëŒ€ë¡œ ê· ë“± ë¶„ë°°
                        day_num = (idx % max(total_days, 1)) + 1

                print(f"ğŸ“ '{place_name}' -> {day_num}ì¼ì°¨ ë°°ì¹˜")

            day_numbers_list.append(str(day_num))

        print(f"ğŸ—ºï¸ ì§€ë„ í‘œì‹œìš© ì¥ì†Œ êµ¬ì„± ì™„ë£Œ:")
        print(f"   ì¥ì†Œ ëª©ë¡: {places_list[:5]}{'...' if len(places_list) > 5 else ''}")
        print(f"   ì¼ì°¨ ë°°ì •: {day_numbers_list[:5]}{'...' if len(day_numbers_list) > 5 else ''}")
        print(f"   í…Œì´ë¸” ëª©ë¡: {source_tables_list[:5]}{'...' if len(source_tables_list) > 5 else ''}")

    # ë‚ ì§œ ê³„ì‚° (durationì—ì„œ ë°•ìˆ˜ ì¶”ì¶œ)
    from datetime import datetime, timedelta

    duration_str = confirmed_plan.get('duration', '2ë°• 3ì¼')
    days_match = re.search(r'(\d+)ì¼', duration_str)
    days = int(days_match.group(1)) if days_match else 2

    # ì‹œì‘ì¼ì„ ì˜¤ëŠ˜ë¡œ ì„¤ì •
    start_date = datetime.now().strftime('%Y-%m-%d')
    end_date = (datetime.now() + timedelta(days=days-1)).strftime('%Y-%m-%d')

    # URL íŒŒë¼ë¯¸í„° ìƒì„±
    import urllib.parse
    places_param = ','.join(places_list)
    day_numbers_param = ','.join(day_numbers_list)
    source_tables_param = ','.join(source_tables_list)

    map_url = f"/map?places={urllib.parse.quote(places_param)}&dayNumbers={urllib.parse.quote(day_numbers_param)}&sourceTables={urllib.parse.quote(source_tables_param)}&startDate={start_date}&endDate={end_date}&days={days}&baseAttraction=general"

    print(f"ğŸ”— ìƒì„±ëœ ì§€ë„ URL: {map_url[:100]}{'...' if len(map_url) > 100 else ''}")
    
    # ì§€ë„ í‘œì‹œìš© ì¥ì†Œ ì •ë³´ (DBì—ì„œ ì •í™•í•œ ì •ë³´ ì¡°íšŒ)
    map_places = []
    if "places" in confirmed_plan and confirmed_plan["places"]:
        for place in confirmed_plan["places"]:
            place_id = place.get("place_id", place.get("id", ""))
            table_name = place.get("table_name", "")

            # DBì—ì„œ ì •í™•í•œ ì •ë³´ ì¡°íšŒ
            if place_id and table_name and place_id != "unknown":
                db_place = get_place_from_recommendations(place_id, table_name)
                if db_place:
                    place_info = {
                        "name": db_place.get("name", ""),
                        "category": db_place.get("category", ""),
                        "table_name": db_place.get("table_name", ""),
                        "place_id": db_place.get("place_id", ""),
                        "city": db_place.get("city", ""),
                        "region": db_place.get("region", "")
                    }
                    # ìœ„ì¹˜ ì •ë³´ ì¶”ê°€
                    if db_place.get("latitude") and db_place.get("longitude"):
                        place_info["lat"] = db_place["latitude"]
                        place_info["lng"] = db_place["longitude"]
                    map_places.append(place_info)
                    continue

            # DB ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ì •ë³´ ì‚¬ìš© (fallback)
            place_info = {
                "name": place.get("name", ""),
                "category": place.get("category", ""),
                "table_name": table_name,
                "place_id": place_id,
                "city": place.get("city", ""),
                "region": place.get("region", "")
            }
            # ìœ„ì¹˜ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if place.get("latitude") and place.get("longitude"):
                place_info["lat"] = place["latitude"]
                place_info["lng"] = place["longitude"]
            map_places.append(place_info)
    
    response = f"""
ğŸ‰ <strong>ì—¬í–‰ ì¼ì •ì´ í™•ì •ë˜ì—ˆìŠµë‹ˆë‹¤!</strong>

ğŸ“‹ <strong>í™•ì •ëœ ì¼ì • ì •ë³´:</strong>
â€¢ <strong>ì§€ì—­</strong>: {confirmed_plan.get('region', 'N/A')}
â€¢ <strong>ê¸°ê°„</strong>: {confirmed_plan.get('duration', 'N/A')}
â€¢ <strong>ì¼ì •</strong>: {itinerary_summary}
â€¢ <strong>ì¥ì†Œ</strong>: {places_summary}

ğŸ—ºï¸ <strong>ì§€ë„ì—ì„œ ì—¬í–‰ì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”!</strong>
í™•ì •ëœ ì—¬í–‰ì§€ë“¤ì´ ì§€ë„ì— í‘œì‹œë©ë‹ˆë‹¤.

ğŸ”„ <strong>ì§€ë„ í˜ì´ì§€ë¡œ ì´ë™ ì¤‘...</strong>
    """
    
    return {
        **state,
        "travel_plan": confirmed_plan,
        "conversation_context": response,
        "tool_results": {
            "action": "redirect_to_map",
            "data": confirmed_plan,
            "redirect_url": map_url,
            "places": map_places
        }
    }

def generate_plan_id() -> str:
    """ì—¬í–‰ ê³„íš ê³ ìœ  ID ìƒì„±"""
    import uuid
    import time
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ + UUID ì¡°í•©ìœ¼ë¡œ ê³ ìœ  ID ìƒì„±
    timestamp = str(int(time.time()))[-6:]  # ë§ˆì§€ë§‰ 6ìë¦¬
    unique_id = str(uuid.uuid4())[:8]  # UUID ì²« 8ìë¦¬
    
    return f"plan_{timestamp}_{unique_id}"

def create_formatted_ui_response(travel_plan: dict, raw_response: str) -> dict:
    """í”„ë¡ íŠ¸ì—”ë“œ UIìš© êµ¬ì¡°í™”ëœ ì‘ë‹µ ìƒì„±"""
    
    # ì‘ë‹µì—ì„œ ì—¬í–‰ íŒ ì¶”ì¶œ
    travel_tips = ""
    if "ğŸ’¡" in raw_response:
        tips_section = raw_response.split("ğŸ’¡")[1] if "ğŸ’¡" in raw_response else ""
        if tips_section:
            travel_tips = tips_section.split("ì´ ì¼ì •ìœ¼ë¡œ í™•ì •í•˜ì‹œê² ì–´ìš”?")[0].strip()
    
    formatted_response = {
        "type": "travel_plan",
        "title": f"{travel_plan.get('region', 'ì—¬í–‰ì§€')} {travel_plan.get('duration', '')} ì—¬í–‰ ì¼ì •",
        "region": travel_plan.get('region', ''),
        "duration": travel_plan.get('duration', ''),
        "total_days": len(travel_plan.get('itinerary', [])),
        "total_places": len(travel_plan.get('places', [])),
        "confidence_score": travel_plan.get('confidence_score', 0),
        "itinerary": [],
        "travel_tips": travel_tips,
        "has_confirmation": True,
        "confirmation_message": "ì´ ì¼ì •ìœ¼ë¡œ í™•ì •í•˜ì‹œê² ì–´ìš”?",
        "plan_id": travel_plan.get('plan_id')
    }
    
    # ì¼ì°¨ë³„ ì¼ì • êµ¬ì¡°í™”
    for day_info in travel_plan.get('itinerary', []):
        day_data = {
            "day": day_info.get('day', 1),
            "title": f"{day_info.get('day', 1)}ì¼ì°¨",
            "activities": []
        }
        
        for schedule_item in day_info.get('schedule', []):
            activity = {
                "time": schedule_item.get('time', ''),
                "place_name": schedule_item.get('place_name', ''),
                "description": schedule_item.get('description', ''),
                "category": schedule_item.get('category', ''),
                "is_meal": is_meal_activity(schedule_item.get('description', '')),
                "place_info": schedule_item.get('place_info')
            }
            day_data["activities"].append(activity)
        
        formatted_response["itinerary"].append(day_data)
    
    # ì£¼ìš” ì¥ì†Œ ì •ë³´
    formatted_response["places"] = [
        {
            "name": place.get('name', ''),
            "category": place.get('category', ''),
            "description": place.get('description', ''),
            "similarity_score": place.get('similarity_score', 0)
        }
        for place in travel_plan.get('places', [])[:5]  # ìƒìœ„ 5ê°œ
    ]
    
    return formatted_response

def is_meal_activity(description: str) -> bool:
    """ì‹ì‚¬ ê´€ë ¨ í™œë™ì¸ì§€ íŒë‹¨"""
    meal_keywords = ['ì ì‹¬', 'ì €ë…', 'ì•„ì¹¨', 'ì‹ì‚¬', 'ë§›ì§‘', 'ì¹´í˜', 'ì‹ë‹¹', 'ë ˆìŠ¤í† ë‘']
    return any(keyword in description for keyword in meal_keywords)

def format_travel_response_with_linebreaks(response: str) -> str:
    """ì—¬í–‰ ì‘ë‹µì— ì ì ˆí•œ ê°œí–‰ ë¬¸ìë¥¼ ì¶”ê°€í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ"""
    
    # ê¸°ë³¸ì ì¸ ê°œí–‰ ì²˜ë¦¬
    formatted = response
    
    # ì¼ì°¨ë³„ ì œëª© ì•ì— ê°œí–‰ ì¶”ê°€
    formatted = formatted.replace("<strong>[", "\n\n<strong>[")
    
    # ê° ì¼ì • í•­ëª© ì•ì— ê°œí–‰ ì¶”ê°€ (â€¢ ê¸°í˜¸ ê¸°ì¤€)
    formatted = formatted.replace("â€¢ ", "\nâ€¢ ")
    
    # ì—¬í–‰ íŒ ì„¹ì…˜ ì•ì— ê°œí–‰ ì¶”ê°€
    formatted = formatted.replace("ğŸ’¡ <strong>ì—¬í–‰ íŒ</strong>", "\n\nğŸ’¡ <strong>ì—¬í–‰ íŒ</strong>")
    
    # í™•ì • ì•ˆë‚´ ì•ì— ê°œí–‰ ì¶”ê°€
    formatted = formatted.replace("ì´ ì¼ì •ìœ¼ë¡œ í™•ì •", "\n\nì´ ì¼ì •ìœ¼ë¡œ í™•ì •")
    
    # ì œëª© ì• ë¶ˆí•„ìš”í•œ ê°œí–‰ ì œê±°
    if formatted.startswith("\n\n"):
        formatted = formatted[2:]
    
    # ì—°ì†ëœ ê°œí–‰ ì •ë¦¬ (3ê°œ ì´ìƒ -> 2ê°œ)
    formatted = re.sub(r'\n{3,}', '\n\n', formatted)
    
    return formatted.strip()

def integrate_response_node(state: TravelState) -> TravelState:
    """ì—¬ëŸ¬ ë…¸ë“œì˜ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ìµœì¢… ì‘ë‹µ ìƒì„±"""
    print(f"ğŸ”„ ì‘ë‹µ í†µí•© ì¤‘...")
    
    response_parts = []
    
    # í™•ì • ì²˜ë¦¬ê°€ í•„ìš”í•œ ê²½ìš° í™•ì • ë…¸ë“œë¡œ ì²˜ë¦¬
    if state.get("need_confirmation") and state.get("travel_plan"):
        print("ğŸ¯ í™•ì • ì²˜ë¦¬ í•„ìš” - confirmation_processing_nodeë¡œ ì´ë™")
        return confirmation_processing_node(state)
    
    # RAG ê²°ê³¼ ìš°ì„ 
    if state.get("conversation_context"):
        response_parts.append(state["conversation_context"])
    
    # Search ê²°ê³¼ ì¶”ê°€
    if state.get("search_results"):
        search_summary = f"ê²€ìƒ‰ëœ ì¥ì†Œ: {len(state['search_results'])}ê³³"
        response_parts.append(search_summary)
    
    # Tool ê²°ê³¼ ì¶”ê°€
    if state.get("tool_results") and state["tool_results"].get("message"):
        response_parts.append(f"ğŸ”§ {state['tool_results']['message']}")
    
    # ì‘ë‹µì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µ
    if not response_parts:
        response_parts.append("ì•ˆë…•í•˜ì„¸ìš”! ì—¬í–‰ ê´€ë ¨ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”. ğŸ˜Š")
    
    integrated_response = "\n\n".join(response_parts)
    
    return {
        **state,
        "conversation_context": integrated_response
    }

def get_place_from_recommendations(place_id: str, table_name: str) -> dict:
    """place_recommendations í…Œì´ë¸”ì—ì„œ place_idì™€ table_nameìœ¼ë¡œ ì •í™•í•œ ì •ë³´ ì¡°íšŒ"""
    try:
        from sqlalchemy import text

        # DB ì—°ê²°
        engine = shared_engine

        with engine.connect() as conn:
            # place_idì™€ table_nameìœ¼ë¡œ ì •í™•í•œ ì¡°íšŒ
            search_query = """
            SELECT place_id, table_name, name, region, city, category,
                   latitude, longitude, overview
            FROM place_recommendations
            WHERE place_id = :place_id AND table_name = :table_name
            LIMIT 1
            """

            result = conn.execute(text(search_query), {
                "place_id": place_id,
                "table_name": table_name
            })
            row = result.fetchone()

            if row:
                return {
                    "place_id": str(row.place_id),
                    "table_name": row.table_name,
                    "name": row.name,
                    "region": row.region,
                    "city": row.city,
                    "category": row.category,
                    "latitude": row.latitude if hasattr(row, 'latitude') else None,
                    "longitude": row.longitude if hasattr(row, 'longitude') else None,
                    "overview": row.overview if hasattr(row, 'overview') else "",
                    "description": f"ì¥ì†Œ: {row.name}"
                }
            else:
                print(f"âŒ place_recommendationsì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ: place_id={place_id}, table_name={table_name}")
                return None

    except Exception as e:
        print(f"place_recommendations ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return None

def find_place_in_recommendations(place_name: str) -> dict:
    """place_recommendations í…Œì´ë¸”ì—ì„œ ì¥ì†Œëª…ìœ¼ë¡œ ì‹¤ì œ ë°ì´í„° ê²€ìƒ‰ (ë²¡í„° ì—…ë°ì´íŠ¸ í›„ ë¶ˆí•„ìš”)"""
    # ë²¡í„° ì—…ë°ì´íŠ¸ í›„ì—ëŠ” ë©”íƒ€ë°ì´í„°ì— place_id, table_nameì´ í¬í•¨ë˜ë¯€ë¡œ
    # ì´ í•¨ìˆ˜ëŠ” í˜¸í™˜ì„±ì„ ìœ„í•´ì„œë§Œ ìœ ì§€
    try:
        from sqlalchemy import text

        # DB ì—°ê²°
        engine = shared_engine

        with engine.connect() as conn:
            # ìœ ì‚¬í•œ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´) - psycopg3 ìŠ¤íƒ€ì¼
            search_query = """
            SELECT place_id, table_name, name, region, city, category
            FROM place_recommendations
            WHERE name ILIKE :search_term
            LIMIT 1
            """

            result = conn.execute(text(search_query), {'search_term': f"%{place_name}%"})
            row = result.fetchone()

            if row:
                return {
                    'name': row.name,
                    'place_id': str(row.place_id) if row.place_id else "1",
                    'table_name': row.table_name or 'nature',
                    'region': row.region or 'ê°•ì›íŠ¹ë³„ìì¹˜ë„',
                    'city': row.city or 'ë¯¸ì§€ì •',
                    'category': row.category or 'ê´€ê´‘',
                    'description': f'ì¥ì†Œ: {row.name}',
                    'similarity_score': 0.9
                }

        return None

    except Exception as e:
        print(f"place_recommendations ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return None

def find_real_place_id(place_name: str, table_name: str, region: str = "") -> str:
    """ì¥ì†Œëª…ìœ¼ë¡œ ì‹¤ì œ DBì—ì„œ place_id ì¡°íšŒ"""
    try:
        from sqlalchemy import create_engine
        from sqlalchemy.orm import sessionmaker
        from models_attractions import Nature, Restaurant, Shopping, Accommodation, Humanities, LeisureSports
        
        # í…Œì´ë¸” ë§¤í•‘
        table_models = {
            "nature": Nature,
            "restaurants": Restaurant,
            "shopping": Shopping,
            "accommodation": Accommodation,
            "humanities": Humanities,
            "leisure_sports": LeisureSports
        }
        
        if table_name not in table_models:
            print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” table_name: {table_name}")
            return None  # ê¸°ë³¸ê°’ "1" ëŒ€ì‹  None ë°˜í™˜
            
        # DB ì—°ê²°
        import os
        DATABASE_URL = os.getenv('DATABASE_URL', 'postgresql://postgres:1234@localhost:5432/witple')
        engine = create_engine(DATABASE_URL)
        Session = sessionmaker(bind=engine)
        session = Session()
        
        try:
            table_model = table_models[table_name]
            
            # ì¥ì†Œëª…ìœ¼ë¡œ ê²€ìƒ‰ (ì •í™•í•œ ë§¤ì¹­ ìš°ì„ )
            query = session.query(table_model).filter(table_model.name.ilike(f"%{place_name}%"))
            
            # ì§€ì—­ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€ í•„í„°ë§
            if region:
                query = query.filter(table_model.region.ilike(f"%{region}%"))
            
            place = query.first()
            
            if place:
                return str(place.id)
            else:
                # ë§¤ì¹­ë˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜ (ë¬´ë“±ì‚° ì£¼ìƒì ˆë¦¬ëŒ€ fallback ë°©ì§€)
                print(f"âŒ ì¥ì†Œëª… '{place_name}'ì´ {table_name} í…Œì´ë¸”ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None
                
        finally:
            session.close()
            
    except Exception as e:
        print(f"place_id ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ "1" ëŒ€ì‹  None ë°˜í™˜

def extract_structured_places(docs: List[Document]) -> List[dict]:
    """RAG ê²€ìƒ‰ ê²°ê³¼ì—ì„œ êµ¬ì¡°í™”ëœ ì¥ì†Œ ì •ë³´ ì¶”ì¶œ (ì—…ë°ì´íŠ¸ëœ ë©”íƒ€ë°ì´í„° í™œìš©)"""
    structured_places = []

    for doc in docs[:20]:  # ìƒìœ„ 20ê°œë§Œ ì²˜ë¦¬
        try:
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì§ì ‘ ì •ë³´ ì¶”ì¶œ (ë²¡í„° ì—…ë°ì´íŠ¸ í›„)
            metadata = doc.metadata or {}

            # ë©”íƒ€ë°ì´í„°ì—ì„œ place_idì™€ table_name ì¶”ì¶œ
            place_id = metadata.get("place_id")
            table_name = metadata.get("table_name")

            # place_idì™€ table_nameì´ ìˆìœ¼ë©´ DBì—ì„œ ì •í™•í•œ ì •ë³´ ì¡°íšŒ
            if place_id and table_name and place_id != "1":
                db_place = get_place_from_recommendations(place_id, table_name)
                if db_place:
                    place_info = {
                        **db_place,  # DBì—ì„œ ê°€ì ¸ì˜¨ ì •í™•í•œ ì •ë³´ ì‚¬ìš©
                        "description": doc.page_content[:200],  # ì²« 200ì
                        "similarity_score": metadata.get('similarity_score', 0)
                    }
                else:
                    # DB ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ë©”íƒ€ë°ì´í„° ì‚¬ìš© (fallback)
                    place_info = {
                        "name": metadata.get("name", "ì¥ì†Œëª… ë¯¸ìƒ"),
                        "category": metadata.get("category", ""),
                        "region": metadata.get("region", ""),
                        "city": metadata.get("city", ""),
                        "table_name": table_name,
                        "place_id": place_id,
                        "description": doc.page_content[:200],
                        "similarity_score": metadata.get('similarity_score', 0)
                    }
            else:
                # ë©”íƒ€ë°ì´í„°ê°€ ë¶ˆì™„ì „í•œ ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
                place_info = {
                    "name": metadata.get("name", ""),
                    "category": metadata.get("category", ""),
                    "region": metadata.get("region", ""),
                    "city": metadata.get("city", ""),
                    "table_name": metadata.get("table_name", "nature"),
                    "place_id": place_id or "unknown",  # "1" ëŒ€ì‹  "unknown" ì‚¬ìš©
                    "description": doc.page_content[:200],
                    "similarity_score": metadata.get('similarity_score', 0)
                }

            # ë©”íƒ€ë°ì´í„°ì— nameì´ ì—†ìœ¼ë©´ ë¬¸ì„œ ë‚´ìš©ì—ì„œ ì¶”ì¶œ (í˜¸í™˜ì„± ë³´ì¥)
            if not place_info["name"]:
                content = doc.page_content
                first_line = content.split('\n')[0] if content else ""
                if first_line and len(first_line) < 50:
                    # "ì´ë¦„: " ì ‘ë‘ì–´ ì œê±°
                    name = first_line.strip()
                    if name.startswith("ì´ë¦„: "):
                        name = name[3:].strip()
                    place_info["name"] = name
                else:
                    # íŒ¨í„´ìœ¼ë¡œ ì¥ì†Œëª… ì¶”ì¶œ
                    import re
                    name_patterns = [
                        r'([ê°€-í£]{2,20}(?:ê³µì›|ë°•ë¬¼ê´€|ë§›ì§‘|ì¹´í˜|ì‹œì¥|ê¶|ì ˆ|íƒ€ì›Œ|ì„¼í„°|ëª°|í•´ìˆ˜ìš•ì¥|ì‚°|ì„¬))',
                        r'([ê°€-í£]{2,20}(?:ì‹ë‹¹|ë ˆìŠ¤í† ë‘))',
                    ]

                    for pattern in name_patterns:
                        match = re.search(pattern, content)
                        if match:
                            place_info["name"] = match.group(1)
                            break

                    if not place_info["name"]:
                        words = content.split()[:3]
                        place_info["name"] = " ".join(words) if words else "ì¥ì†Œëª… ë¯¸ìƒ"

            # table_nameì´ ì—†ìœ¼ë©´ ì¹´í…Œê³ ë¦¬ë¡œ ë§¤í•‘ (í˜¸í™˜ì„± ë³´ì¥)
            if not place_info["table_name"] or place_info["table_name"] == "nature":
                category_to_table = {
                    "í•œì‹": "restaurants", "ì¤‘ì‹": "restaurants", "ì–‘ì‹": "restaurants",
                    "ì¼ì‹": "restaurants", "ì¹´í˜": "restaurants", "ì‹ë‹¹": "restaurants",
                    "ë§›ì§‘": "restaurants", "ìì—°": "nature", "ê´€ê´‘": "nature",
                    "ë¬¸í™”": "humanities", "ì‡¼í•‘": "shopping",
                    "ë ˆí¬ì¸ ": "leisure_sports", "ìŠ¤í¬ì¸ ": "leisure_sports",
                    "ìˆ™ë°•": "accommodation", "íœì…˜": "accommodation", "í˜¸í…”": "accommodation"
                }
                place_info["table_name"] = category_to_table.get(place_info["category"], "nature")

            # ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ
            place_info["latitude"] = metadata.get("latitude")
            place_info["longitude"] = metadata.get("longitude")

            structured_places.append(place_info)

        except Exception as e:
            print(f"ì¥ì†Œ ì •ë³´ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            continue

    return structured_places

def extract_places_from_response(response: str, structured_places: List[dict]) -> List[dict]:
    """LLM ì‘ë‹µì—ì„œ ì‹¤ì œ ì–¸ê¸‰ëœ ì¥ì†Œë“¤ë§Œ ì¶”ì¶œí•˜ì—¬ ë§¤ì¹­"""
    
    # ì‘ë‹µì—ì„œ <strong>ì¥ì†Œëª…</strong> íŒ¨í„´ìœ¼ë¡œ ì¥ì†Œ ì¶”ì¶œ
    place_pattern = r'<strong>([^<]+)</strong>'
    mentioned_places = re.findall(place_pattern, response)
    
    # ë§¤ì¹­ëœ ì¥ì†Œë“¤ ì €ì¥
    matched_places = []
    
    # ì¼ì • ê´€ë ¨ í‚¤ì›Œë“œ í•„í„°ë§ (ë” ì •ë°€í•˜ê²Œ)
    ignore_keywords = ['ì¼ì°¨', 'ì—¬í–‰', 'ì¼ì •', 'íŒ', 'ì •ë³´', 'í™•ì •', '[', ']']
    # ì§€ì—­ëª…ë§Œ í¬í•¨í•˜ëŠ” ê²½ìš°ëŠ” ì œì™¸ (ì˜ˆ: "ë¶€ì‚°", "ì„œìš¸")
    region_only_keywords = ['ë¶€ì‚°', 'ì„œìš¸', 'ì œì£¼', 'ê°•ë¦‰', 'ëŒ€êµ¬', 'ê´‘ì£¼', 'ì „ì£¼', 'ê²½ì£¼']
    
    for mentioned_place in mentioned_places:
        mentioned_place = mentioned_place.strip()
    
        # ì¼ì • ê´€ë ¨ í‚¤ì›Œë“œ ì œì™¸
        if any(keyword in mentioned_place for keyword in ignore_keywords):
            continue
            
        # ì§€ì—­ëª…ë§Œ ë‹¨ë…ìœ¼ë¡œ ë‚˜ì˜¤ëŠ” ê²½ìš° ì œì™¸ (ì˜ˆ: "ë¶€ì‚°", "ì„œìš¸")
        if mentioned_place.strip() in region_only_keywords:
            continue
        
        # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ì¥ì†Œëª… ì œì™¸
        if len(mentioned_place) < 2 or len(mentioned_place) > 30:
            continue
            
        # structured_placesì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ì¥ì†Œ ì°¾ê¸°
        best_match = None
        best_score = 0
        
        for place in structured_places:
            place_name = place.get("name", "").strip()

            # LLMì´ ìƒì„±í•œ ì¥ì†ŒëŠ” ëª¨ë‘ í¬í•¨ (ì§€ì—­ í•„í„°ë§ ì œê±°)
            # LLMì´ ì´ë¯¸ ì ì ˆí•œ íŒë‹¨ì„ í–ˆë‹¤ê³  ì‹ ë¢°
            
            # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
            if mentioned_place == place_name:
                best_match = place
                best_score = 1.0
                break
            
            # ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­
            if mentioned_place in place_name or place_name in mentioned_place:
                # ë” ê¸´ ë§¤ì¹­ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
                score = min(len(mentioned_place), len(place_name)) / max(len(mentioned_place), len(place_name))
                if score > best_score:
                    best_score = score
                    best_match = place
        
        # ë§¤ì¹­ ì ìˆ˜ê°€ 0.2 ì´ìƒì´ë©´ ì¶”ê°€ (ë” ê´€ëŒ€í•˜ê²Œ)
        if best_match and best_score >= 0.2:
            if best_match not in matched_places:
                matched_places.append(best_match)
        elif not best_match and len(mentioned_place) >= 3:
            # ì‹¤ì œ place_recommendations í…Œì´ë¸”ì—ì„œ í•´ë‹¹ ì¥ì†Œ ê²€ìƒ‰
            actual_place = find_place_in_recommendations(mentioned_place)
            if actual_place:
                matched_places.append(actual_place)
            else:
                # ì •ë§ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°ë§Œ ê°€ìƒ ì¥ì†Œ ìƒì„±
                virtual_place = {
                    'name': mentioned_place,
                    'category': 'ê´€ê´‘',
                    'region': 'ê°•ì›íŠ¹ë³„ìì¹˜ë„',
                    'city': 'ê°•ë¦‰ì‹œ' if 'ê°•ë¦‰' in mentioned_place else 'ë¯¸ì§€ì •',
                    'table_name': 'nature',
                    'place_id': "1",  # ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ID
                    'description': f'LLM ì¶”ì²œ ì¥ì†Œ: {mentioned_place}',
                    'similarity_score': 0.8
                }
                matched_places.append(virtual_place)
    
    return matched_places

def parse_enhanced_travel_plan(response: str, user_query: str, structured_places: List[dict]) -> dict:
    """í–¥ìƒëœ ì—¬í–‰ ì¼ì • íŒŒì‹± (ì‹¤ì œ ì¥ì†Œ ë°ì´í„° í¬í•¨)"""

    # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
    regions, cities, categories = extract_location_and_category(user_query)
    duration = extract_duration(user_query)

    # ì¼ì°¨ë³„ êµ¬ì¡° íŒŒì‹± (ë” ìœ ì—°í•œ íŒ¨í„´)
    day_patterns = [
        r'<strong>\[(\d+)ì¼ì°¨\]</strong>',  # <strong>[1ì¼ì°¨]</strong>
        r'\[(\d+)ì¼ì°¨\]',                    # [1ì¼ì°¨]
        r'(\d+)ì¼ì°¨',                        # 1ì¼ì°¨
        r'<strong>(\d+)ì¼ì°¨</strong>'         # <strong>1ì¼ì°¨</strong>
    ]

    # ê°€ì¥ ë§ì´ ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ ì‚¬ìš©
    best_pattern = None
    best_matches = []

    for pattern in day_patterns:
        matches = re.findall(pattern, response)
        if len(matches) > len(best_matches):
            best_matches = matches
            best_pattern = pattern

    itinerary = []

    if best_pattern and best_matches:
        print(f"ğŸ—“ï¸ ì¼ì°¨ íŒ¨í„´ ì¸ì‹: {len(best_matches)}ê°œ ì¼ì°¨ ë°œê²¬")

        # ì‘ë‹µì„ ì¼ì°¨ë³„ë¡œ ë¶„í• 
        day_sections = re.split(best_pattern, response)

        for i in range(1, len(day_sections), 2):  # í™€ìˆ˜ ì¸ë±ìŠ¤ê°€ ì¼ì°¨ ë²ˆí˜¸, ì§ìˆ˜ê°€ ë‚´ìš©
            if i + 1 < len(day_sections):
                day_num_str = day_sections[i]
                day_content = day_sections[i + 1]

                try:
                    day_num = int(day_num_str)
                except ValueError:
                    continue

                # í•´ë‹¹ ì¼ì°¨ì˜ ì¼ì • íŒŒì‹±
                day_schedule = parse_day_schedule(day_content, structured_places)

                if day_schedule:  # ì¼ì •ì´ ìˆì„ ë•Œë§Œ ì¶”ê°€
                    itinerary.append({
                        "day": day_num,
                        "schedule": day_schedule
                    })
    else:
        print(f"âš ï¸ ì¼ì°¨ íŒ¨í„´ ì¸ì‹ ì‹¤íŒ¨, ë‹¨ì¼ ì¼ì •ìœ¼ë¡œ ì²˜ë¦¬")
        # ì¼ì°¨ êµ¬ë¶„ ì—†ì´ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì¼ì •ìœ¼ë¡œ ì²˜ë¦¬
        single_day_schedule = parse_day_schedule(response, structured_places)
        if single_day_schedule:
            itinerary.append({
                "day": 1,
                "schedule": single_day_schedule
            })

    # ì‹¤ì œ ì‘ë‹µì— í¬í•¨ëœ ì¥ì†Œë“¤ë§Œ ì¶”ì¶œ (LLM íŒë‹¨ ì‹ ë¢°)
    response_places = extract_places_from_response(response, structured_places)

    # ìƒì„¸ ì—¬í–‰ ê³„íš êµ¬ì¡°
    enhanced_plan = {
        "region": regions[0] if regions else "ë¯¸ì§€ì •",
        "cities": cities,
        "duration": duration,
        "categories": list(set(categories + [place["category"] for place in response_places if place.get("category")])),
        "itinerary": itinerary,
        "places": response_places,  # ì‹¤ì œ ì‘ë‹µì— í¬í•¨ëœ ì¥ì†Œë“¤ë§Œ
        "raw_response": response,
        "status": "draft",
        "created_at": "2025-09-13T00:00:00Z",  # ì‹¤ì œë¡œëŠ” datetime.now()
        "total_places": len(structured_places),
        "confidence_score": calculate_plan_confidence(structured_places, response)
    }

    print(f"âœ¨ ì¼ì • íŒŒì‹± ì™„ë£Œ: {len(itinerary)}ì¼ì°¨, ì´ {sum(len(day.get('schedule', [])) for day in itinerary)}ê°œ ì¼ì •")

    return enhanced_plan

def parse_day_schedule(day_content: str, structured_places: List[dict]) -> List[dict]:
    """í•˜ë£¨ ì¼ì • íŒŒì‹± (ê°œì„ ëœ íŒ¨í„´ ì¸ì‹)"""

    schedule = []

    # ë” ìœ ì—°í•œ íŒ¨í„´ë“¤ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
    patterns = [
        # â€¢ 09:00-12:00 <strong>ì¥ì†Œëª…</strong> - ì„¤ëª…
        r'â€¢\s*(\d{1,2}:\d{2}(?:-\d{1,2}:\d{2})?)\s*<strong>([^<\n]+)</strong>\s*-\s*([^\n]+)',
        # â€¢ 09:00 <strong>ì¥ì†Œëª…</strong> - ì„¤ëª… (ë‹¨ì¼ ì‹œê°„)
        r'â€¢\s*(\d{1,2}:\d{2})\s*<strong>([^<\n]+)</strong>\s*-\s*([^\n]+)',
        # â€¢ <strong>ì¥ì†Œëª…</strong> (09:00-12:00) - ì„¤ëª…
        r'â€¢\s*<strong>([^<\n]+)</strong>\s*\((\d{1,2}:\d{2}(?:-\d{1,2}:\d{2})?)\)\s*-\s*([^\n]+)',
        # ì‹œê°„ ì—†ì´: â€¢ <strong>ì¥ì†Œëª…</strong> - ì„¤ëª…
        r'â€¢\s*<strong>([^<\n]+)</strong>\s*-\s*([^\n]+)'
    ]

    for pattern in patterns:
        matches = re.findall(pattern, day_content)

        for match in matches:
            if len(match) == 3:
                if pattern == patterns[2]:  # 3ë²ˆì§¸ íŒ¨í„´ (ì¥ì†Œëª…ì´ ì²« ë²ˆì§¸)
                    place_name, time_range, description = match
                else:
                    time_range, place_name, description = match
            elif len(match) == 2:  # ì‹œê°„ ì—†ëŠ” ê²½ìš°
                place_name, description = match
                time_range = ""
            else:
                continue

            # ì¥ì†Œëª… ì •ë¦¬
            place_name_clean = normalize_place_name(place_name)

            # êµ¬ì¡°í™”ëœ ì¥ì†Œì—ì„œ ë§¤ì¹­ë˜ëŠ” ì •ë³´ ì°¾ê¸° (ê°œì„ ëœ ë§¤ì¹­)
            matched_place = None
            best_score = 0

            for place in structured_places:
                place_name_normalized = normalize_place_name(place.get("name", ""))

                # ì •í™•í•œ ë§¤ì¹­
                if place_name_clean == place_name_normalized:
                    matched_place = place
                    break

                # ë¶€ë¶„ ë§¤ì¹­
                if place_name_clean and place_name_normalized:
                    if place_name_clean in place_name_normalized or place_name_normalized in place_name_clean:
                        score = min(len(place_name_clean), len(place_name_normalized)) / max(len(place_name_clean), len(place_name_normalized))
                        if score > best_score:
                            best_score = score
                            matched_place = place

            schedule_item = {
                "time": time_range.strip() if time_range else "",
                "place_name": place_name.strip(),
                "description": description.strip(),
                "category": matched_place.get("category", "") if matched_place else "",
                "place_info": matched_place
            }
            schedule.append(schedule_item)

    # ì¤‘ë³µ ì œê±° (ê°™ì€ ì¥ì†Œëª…ê³¼ ì‹œê°„)
    seen = set()
    unique_schedule = []
    for item in schedule:
        key = (item["place_name"], item["time"])
        if key not in seen:
            seen.add(key)
            unique_schedule.append(item)

    return unique_schedule

def calculate_plan_confidence(structured_places: List[dict], response: str) -> float:
    """ì—¬í–‰ ê³„íšì˜ ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
    
    score = 0.0
    max_score = 100.0
    
    # ì¥ì†Œ ì •ë³´ í’ˆì§ˆ (40ì )
    if structured_places:
        avg_similarity = sum(place.get("similarity_score", 0) for place in structured_places) / len(structured_places)
        score += avg_similarity * 40
    
    # ì‘ë‹µ êµ¬ì¡°í™” ì •ë„ (30ì )
    structure_indicators = ["<strong>[", "ì¼ì°¨]", "â€¢", ":**", "ğŸ’¡"]
    structure_score = sum(10 for indicator in structure_indicators if indicator in response)
    score += min(structure_score, 30)
    
    # ì‘ë‹µ ê¸¸ì´ ì ì ˆì„± (20ì )
    response_length = len(response)
    if 200 <= response_length <= 1000:
        score += 20
    elif 100 <= response_length <= 1500:
        score += 15
    else:
        score += 10
    
    # ì‹œê°„ ì •ë³´ í¬í•¨ ì—¬ë¶€ (10ì )
    time_patterns = re.findall(r'\d{2}:\d{2}', response)
    if len(time_patterns) >= 3:
        score += 10
    elif len(time_patterns) >= 1:
        score += 5
    
    return min(score, max_score) / max_score

def parse_travel_plan(response: str, user_query: str) -> dict:
    """ì‘ë‹µì—ì„œ ì—¬í–‰ ì¼ì • êµ¬ì¡° ì¶”ì¶œ"""
    
    # ì§€ì—­ ì¶”ì¶œ
    regions, cities, categories = extract_location_and_category(user_query)
    
    # ì‹œê°„ íŒ¨í„´ ì°¾ê¸° (09:00, 12:00 ë“±)
    time_pattern = r'\d{2}:\d{2}'
    times = re.findall(time_pattern, response)
    
    # ì¥ì†Œëª… ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)
    location_pattern = r'[ê°€-í£]{2,10}(?:ê³µì›|ë°•ë¬¼ê´€|ë§›ì§‘|ì¹´í˜|ì‹œì¥|ê¶|ì ˆ|íƒ€ì›Œ|ì„¼í„°|ëª°)'
    locations = re.findall(location_pattern, response)
    
    return {
        "region": regions[0] if regions else "ë¯¸ì§€ì •",
        "cities": cities,
        "duration": extract_duration(user_query),
        "locations": list(set(locations)),  # ì¤‘ë³µ ì œê±°
        "times": times,
        "categories": categories,
        "raw_response": response,
        "status": "draft"
    }

def extract_duration(query: str) -> str:
    """ì¿¼ë¦¬ì—ì„œ ì—¬í–‰ ê¸°ê°„ ì¶”ì¶œ"""
    duration_patterns = [
        r'(\d+)ë°•\s*(\d+)ì¼',
        r'(\d+)ì¼',
        r'ë‹¹ì¼',
        r'í•˜ë£¨'
    ]
    
    for pattern in duration_patterns:
        match = re.search(pattern, query)
        if match:
            return match.group(0)
    
    return "ë¯¸ì§€ì •"

def route_execution(state: TravelState) -> str:
    """ë‹¨ì¼ ë…¸ë“œ ì‹¤í–‰ì„ ìœ„í•œ ë¼ìš°íŒ… ê²°ì • (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)"""
    
    # í™•ì • ìš”ì²­ì´ ìµœê³  ìš°ì„ ìˆœìœ„
    if state.get("need_confirmation"):
        return "confirmation_processing"
    
    # RAGê°€ ê°€ì¥ ì¤‘ìš”í•œ ê¸°ëŠ¥
    if state.get("need_rag"):
        return "rag_processing"
    
    # ì¥ì†Œ ê²€ìƒ‰
    if state.get("need_search"):
        return "search_processing"
    
    # ë„êµ¬ ì‹¤í–‰
    if state.get("need_tool"):
        return "tool_execution"
    
    # ê¸°ë³¸: ì¼ë°˜ ì±„íŒ…
    return "general_chat"

def check_completion(state: TravelState) -> Literal["continue", "end"]:
    """ëŒ€í™” ì™„ë£Œ ì—¬ë¶€ í™•ì¸"""
    # í™•ì •ëœ ì¼ì •ì´ ìˆê³  ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¢…ë£Œ
    if (state.get("travel_plan", {}).get("status") == "confirmed" and 
        state.get("tool_results", {}).get("action") == "redirect_to_planning_page"):
        return "end"
    
    # ê¸°ë³¸ì ìœ¼ë¡œ ëŒ€í™” ì§€ì†
    return "continue"

# LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
def create_travel_workflow():
    """ì—¬í–‰ ì¶”ì²œ LangGraph ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    if not LANGGRAPH_AVAILABLE:
        return None
    
    workflow = StateGraph(TravelState)
    
    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("classify", classify_query)
    workflow.add_node("rag_processing", rag_processing_node)
    workflow.add_node("search_processing", search_processing_node)
    workflow.add_node("tool_execution", tool_execution_node)
    workflow.add_node("general_chat", general_chat_node)
    workflow.add_node("confirmation_processing", confirmation_processing_node)
    workflow.add_node("integrate_response", integrate_response_node)
    
    # ì—£ì§€ êµ¬ì„±
    workflow.add_edge(START, "classify")
    workflow.add_conditional_edges("classify", route_execution)
    
    # ëª¨ë“  ì²˜ë¦¬ ë…¸ë“œë“¤ì´ í†µí•© ë…¸ë“œë¡œ ìˆ˜ë ´
    workflow.add_edge("rag_processing", "integrate_response")
    workflow.add_edge("search_processing", "integrate_response")
    workflow.add_edge("tool_execution", "integrate_response")
    workflow.add_edge("general_chat", "integrate_response")
    workflow.add_edge("confirmation_processing", "integrate_response")
    
    # ì™„ë£Œ í™•ì¸
    workflow.add_conditional_edges(
        "integrate_response",
        check_completion,
        {
            "continue": END,  # ì¶”ê°€ ëŒ€í™” ì—†ì´ ì¢…ë£Œë¡œ ë³€ê²½
            "end": END
        }
    )
    
    return workflow.compile()

# ì „ì—­ ì›Œí¬í”Œë¡œìš° ì¸ìŠ¤í„´ìŠ¤
travel_workflow = create_travel_workflow() if LANGGRAPH_AVAILABLE else None

# ê°œì„ ëœ ìƒíƒœ ê´€ë¦¬: ì„¸ì…˜ ëŒ€ì‹  ì¸ë©”ëª¨ë¦¬ ìƒíƒœ (ìƒˆ ì¶”ì²œì‹œ ë®ì–´ì“°ê¸°)
current_travel_state = {
    "last_query": "",
    "travel_plan": {},
    "places": [],
    "context": "",
    "timestamp": None
}

def get_current_travel_state_ref():
    """í˜„ì¬ ì—¬í–‰ ìƒíƒœ ë°˜í™˜ (ì°¸ì¡° ë™ê¸°í™”ë¥¼ ìœ„í•œ í•¨ìˆ˜)"""
    global current_travel_state
    return current_travel_state

async def get_travel_recommendation_langgraph_stream(query: str):
    """LangGraph ê¸°ë°˜ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì—¬í–‰ ì¶”ì²œ"""
    global current_travel_state
    import asyncio
    import datetime

    if not travel_workflow:
        # LangGraph ë¯¸ì‚¬ìš© ì‹œ ê¸°ì¡´ í•¨ìˆ˜ë¡œ í´ë°±
        yield {'type': 'status', 'content': 'LangGraph ì‹œìŠ¤í…œ ì¤€ë¹„ ì¤‘...'}
        result = get_travel_recommendation(query, stream=False)

        # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ìŠ¤íŠ¸ë¦¬ë°
        chunks = [result[i:i+10] for i in range(0, len(result), 10)]
        for chunk in chunks:
            yield {'type': 'content', 'content': chunk}
            await asyncio.sleep(0.1)

        yield {'type': 'metadata', 'travel_plan': {}, 'tool_results': {}}
        return

    print(f"ğŸš€ LangGraph ìŠ¤íŠ¸ë¦¬ë° ì›Œí¬í”Œë¡œìš° ì‹¤í–‰: '{query}'")

    try:
        # í™•ì •ì´ ì•„ë‹Œ ìƒˆ ì—¬í–‰ ì¶”ì²œ ìš”ì²­ì‹œì—ë§Œ ê¸°ì¡´ ìƒíƒœ ì´ˆê¸°í™”
        is_confirmation = any(keyword in query.lower() for keyword in ["í™•ì •", "ê²°ì •", "ì¢‹ì•„", "ì´ê±¸ë¡œ", "ok", "ì˜¤ì¼€ì´"])
        is_new_travel_request = any(keyword in query.lower() for keyword in ["ì¶”ì²œ", "ì—¬í–‰", "ì¼ì •", "ê³„íš", "ë°•", "ì¼"])

        if is_confirmation and current_travel_state.get("travel_plan"):
            print("ğŸ¯ í™•ì • ìš”ì²­ - ê¸°ì¡´ ìƒíƒœ ìœ ì§€")
            # ê¸°ì¡´ ìƒíƒœ ìœ ì§€í•˜ë©´ì„œ ë§ˆì§€ë§‰ ì¿¼ë¦¬ë§Œ ì—…ë°ì´íŠ¸
            current_travel_state["last_query"] = query
            current_travel_state["timestamp"] = datetime.datetime.now().isoformat()
        elif is_new_travel_request and not is_confirmation:
            print("ğŸ”„ ìƒˆë¡œìš´ ì—¬í–‰ ì¶”ì²œ - ê¸°ì¡´ ìƒíƒœ ì´ˆê¸°í™”")
            current_travel_state = {
                "last_query": query,
                "travel_plan": {},
                "places": [],
                "context": "",
                "timestamp": datetime.datetime.now().isoformat()
            }
        else:
            print("ğŸ” ê¸°íƒ€ ìš”ì²­ - ê¸°ì¡´ ìƒíƒœ ìœ ì§€í•˜ë©° ì¿¼ë¦¬ ì¶”ê°€")
            # ë‚ ì”¨ ì§ˆë¬¸ ë“± ê¸°íƒ€ ìš”ì²­ì‹œ ê¸°ì¡´ ìƒíƒœ ìœ ì§€
            current_travel_state["last_query"] = query
            current_travel_state["timestamp"] = datetime.datetime.now().isoformat()

        # ìƒíƒœ ìƒì„±
        if not conversation_history:
            conversation_history = []

        # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ìƒˆ ì¿¼ë¦¬ ì¶”ê°€
        messages = conversation_history + [query]

        # ì „ì—­ ìƒíƒœì—ì„œ ê¸°ì¡´ ì—¬í–‰ ê³„íš ê°€ì ¸ì˜¤ê¸° (ì»¨í…ìŠ¤íŠ¸ ìœ ì§€)
        existing_travel_plan = current_travel_state.get("travel_plan", {})
        print(f"ğŸ”„ ê¸°ì¡´ ì—¬í–‰ ê³„íš ìƒíƒœ: {bool(existing_travel_plan)}")

        initial_state = {
            "messages": messages,
            "query_type": "unknown",
            "need_rag": False,
            "need_search": False,
            "need_tool": False,
            "need_confirmation": False,
            "history": " ".join(messages),
            "rag_results": [],
            "search_results": [],
            "tool_results": {},
            "travel_plan": existing_travel_plan,  # ê¸°ì¡´ ì—¬í–‰ ê³„íš í¬í•¨
            "user_preferences": {},
            "conversation_context": "",
            "formatted_ui_response": {}
        }

        yield {'type': 'status', 'content': 'ğŸ” ì—¬í–‰ ìš”ì²­ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'}

        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)
        response_text = ""
        final_state = None

        # LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ë‹¨ê³„ë³„ë¡œ ì‹¤í–‰í•˜ë©´ì„œ ìŠ¤íŠ¸ë¦¬ë°
        for step_output in travel_workflow.stream(initial_state):
            print(f"ğŸ”„ ì›Œí¬í”Œë¡œìš° ë‹¨ê³„: {step_output}")

            # ê° ë‹¨ê³„ì˜ ì¶œë ¥ì„ ë¶„ì„í•´ì„œ ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ìƒì„±
            if isinstance(step_output, dict):
                for node_name, node_state in step_output.items():
                    if node_name == "classify_query":
                        yield {'type': 'status', 'content': 'ğŸ“‹ ì§ˆë¬¸ ìœ í˜•ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤...'}
                    elif node_name == "handle_rag":
                        yield {'type': 'status', 'content': 'ğŸ” ê´€ë ¨ ì—¬í–‰ì§€ ì •ë³´ë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤...'}
                    elif node_name == "generate_response":
                        yield {'type': 'status', 'content': 'âœ¨ AIê°€ ì¶”ì²œì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...'}

                        # ì‘ë‹µ í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ìŠ¤íŠ¸ë¦¬ë°
                        if 'conversation_context' in node_state:
                            new_content = node_state['conversation_context']
                            if new_content and new_content != response_text:
                                chunk = new_content[len(response_text):]
                                response_text = new_content

                                # í…ìŠ¤íŠ¸ë¥¼ ì‘ì€ ì²­í¬ë¡œ ìŠ¤íŠ¸ë¦¬ë°
                                for char in chunk:
                                    yield {'type': 'content', 'content': char}
                                    await asyncio.sleep(0.02)

                    final_state = node_state

        # ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸
        if final_state:
            # placesëŠ” tool_resultsê°€ ì•„ë‹Œ travel_planì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
            places = []
            if final_state.get("tool_results", {}).get("places"):
                # í™•ì • ì‹œ tool_resultsì—ì„œ places ê°€ì ¸ì˜¤ê¸°
                places = final_state.get("tool_results", {}).get("places", [])
            elif final_state.get("travel_plan", {}).get("places"):
                # ì¼ë°˜ ì—¬í–‰ ì¶”ì²œ ì‹œ travel_planì—ì„œ places ê°€ì ¸ì˜¤ê¸°
                places = final_state.get("travel_plan", {}).get("places", [])

            current_travel_state.update({
                "travel_plan": final_state.get('travel_plan', {}),
                "places": places,
                "context": final_state.get('conversation_context', ''),
                "last_query": query,
                "timestamp": datetime.datetime.now().isoformat()
            })
            print(f"ğŸ’¾ ìŠ¤íŠ¸ë¦¬ë° ì—¬í–‰ ìƒíƒœ ì €ì¥ ì™„ë£Œ: {len(places)}ê°œ ì¥ì†Œ")

            # ë©”íƒ€ë°ì´í„° ì „ì†¡
            yield {
                'type': 'metadata',
                'travel_plan': final_state.get('travel_plan', {}),
                'action_required': final_state.get('tool_results', {}).get('action_required'),
                'tool_results': final_state.get('tool_results', {})
            }

        print("âœ… LangGraph ìŠ¤íŠ¸ë¦¬ë° ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!")

    except Exception as e:
        print(f"âŒ LangGraph ìŠ¤íŠ¸ë¦¬ë° ì›Œí¬í”Œë¡œìš° ì˜¤ë¥˜: {e}")
        yield {'type': 'status', 'content': f'âš ï¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}

        # ì˜¤ë¥˜ ì‹œ ê¸°ì¡´ ì‹œìŠ¤í…œìœ¼ë¡œ í´ë°±
        result = get_travel_recommendation(query, stream=False)
        yield {'type': 'content', 'content': result}
        yield {'type': 'metadata', 'travel_plan': {}, 'tool_results': {}}

def get_travel_recommendation_langgraph(query: str, conversation_history: List[str] = None, session_id: str = "default") -> dict:
    """LangGraph ê¸°ë°˜ ì—¬í–‰ ì¶”ì²œ (ê°œì„ ëœ ìƒíƒœ ê´€ë¦¬ - ìƒˆ ì¶”ì²œì‹œ ë®ì–´ì“°ê¸°)"""
    import datetime

    if not travel_workflow:
        # LangGraph ë¯¸ì‚¬ìš© ì‹œ ê¸°ì¡´ í•¨ìˆ˜ë¡œ í´ë°±
        response = get_travel_recommendation(query, stream=False)
        return {
            "response": response,
            "travel_plan": {},
            "action_required": None,
            "conversation_context": response
        }
    
    print(f"ğŸš€ LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰: '{query}' (ì„¸ì…˜: {session_id})")
    
    try:
        # ëŒ€í™” ê¸°ë¡ì´ ìˆìœ¼ë©´ í¬í•¨ (í˜„ì¬ëŠ” ë‹¨ì¼ ë©”ì‹œì§€ë§Œ ì²˜ë¦¬)
        messages = [query]
        if conversation_history and isinstance(conversation_history, list):
            messages = conversation_history + [query]
        
        # ì¿¼ë¦¬ íƒ€ì… ë¶„ì„
        is_confirmation = any(keyword in query.lower() for keyword in ["í™•ì •", "ê²°ì •", "ì¢‹ì•„", "ì´ê±¸ë¡œ", "ok", "ì˜¤ì¼€ì´"])
        is_new_travel_request = any(keyword in query.lower() for keyword in ["ì¶”ì²œ", "ì—¬í–‰", "ì¼ì •", "ê³„íš", "ë°•", "ì¼"])
        is_weather_query = any(keyword in query.lower() for keyword in ["ë‚ ì”¨", "ê¸°ì˜¨", "ì˜¨ë„"])

        global current_travel_state

        # ë””ë²„ê¹… ì •ë³´
        print(f"ğŸ” ì¿¼ë¦¬ ë¶„ì„: í™•ì •={is_confirmation}, ìƒˆì—¬í–‰={is_new_travel_request}, ë‚ ì”¨={is_weather_query}")
        print(f"ğŸ” ê¸°ì¡´ ìƒíƒœ: {bool(current_travel_state.get('travel_plan'))}")

        # ìƒˆ ì—¬í–‰ ì¶”ì²œì¼ ë•Œë§Œ ìƒíƒœ ì´ˆê¸°í™” (í™•ì •ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ)
        if is_new_travel_request and not is_confirmation:
            print("ğŸ”„ ìƒˆë¡œìš´ ì—¬í–‰ ì¶”ì²œ - ìƒíƒœ ì´ˆê¸°í™”")
            current_travel_state.clear()
            current_travel_state.update({
                "last_query": query,
                "travel_plan": {},
                "places": [],
                "context": "",
                "timestamp": datetime.datetime.now().isoformat()
            })
        else:
            print("ğŸ’¾ ê¸°ì¡´ ìƒíƒœ ìœ ì§€")
            current_travel_state["last_query"] = query
            current_travel_state["timestamp"] = datetime.datetime.now().isoformat()

        # ì „ì—­ ìƒíƒœì—ì„œ ê¸°ì¡´ ì—¬í–‰ ê³„íš ê°€ì ¸ì˜¤ê¸°
        existing_travel_plan = current_travel_state.get("travel_plan", {})
        print(f"ğŸ”„ ì‚¬ìš©í•  ì—¬í–‰ ê³„íš: {bool(existing_travel_plan)}")

        # ì´ˆê¸° ìƒíƒœ ì„¤ì • (ê°„ì†Œí™”)
        initial_state = {
            "messages": messages,
            "query_type": "",
            "need_rag": False,
            "need_search": False,
            "need_tool": False,
            "need_confirmation": False,
            "history": " ".join(messages),
            "rag_results": [],
            "search_results": [],
            "tool_results": {},
            "travel_plan": existing_travel_plan,  # ê¸°ì¡´ ì—¬í–‰ ê³„íš í¬í•¨
            "user_preferences": {},
            "conversation_context": "",
            "formatted_ui_response": {}
        }

        # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        final_state = travel_workflow.invoke(initial_state)

        # ì „ì—­ ìƒíƒœ ì—…ë°ì´íŠ¸ (ìƒˆ ì¶”ì²œìœ¼ë¡œ ë®ì–´ì“°ê¸°)
        if final_state.get("travel_plan"):
            # placesëŠ” tool_resultsê°€ ì•„ë‹Œ travel_planì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
            places = []
            if final_state.get("tool_results", {}).get("places"):
                # í™•ì • ì‹œ tool_resultsì—ì„œ places ê°€ì ¸ì˜¤ê¸°
                places = final_state.get("tool_results", {}).get("places", [])
            elif final_state.get("travel_plan", {}).get("places"):
                # ì¼ë°˜ ì—¬í–‰ ì¶”ì²œ ì‹œ travel_planì—ì„œ places ê°€ì ¸ì˜¤ê¸°
                places = final_state.get("travel_plan", {}).get("places", [])

            current_travel_state.update({
                "travel_plan": final_state.get("travel_plan", {}),
                "places": places,
                "context": final_state.get("conversation_context", ""),
                "last_query": query,
                "timestamp": datetime.datetime.now().isoformat()
            })
            print(f"ğŸ’¾ ìƒˆë¡œìš´ ì—¬í–‰ ìƒíƒœ ì €ì¥ ì™„ë£Œ: {len(places)}ê°œ ì¥ì†Œ")
        
        # êµ¬ì¡°í™”ëœ ì‘ë‹µ ë°˜í™˜
        tool_results = final_state.get("tool_results", {})
        return {
            "response": final_state.get("conversation_context", "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
            "travel_plan": final_state.get("travel_plan", {}),
            "action_required": tool_results.get("action"),
            "redirect_url": tool_results.get("redirect_url"),
            "places": tool_results.get("places"),
            "raw_state": final_state,
            "success": True
        }
        
    except Exception as e:
        print(f"âŒ LangGraph ì›Œí¬í”Œë¡œìš° ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ì¡´ ì‹œìŠ¤í…œìœ¼ë¡œ í´ë°±
        response = get_travel_recommendation(query, stream=False)
        return {
            "response": response,
            "travel_plan": {},
            "action_required": None,
            "conversation_context": response,
            "success": False,
            "error": str(e)
        }

# =============================================================================
# ë©”ì¸ ì‹¤í–‰ë¶€
# =============================================================================

if __name__ == "__main__":
    # AWS ìê²© ì¦ëª… í™•ì¸
    if not AWS_ACCESS_KEY_ID or not AWS_SECRET_ACCESS_KEY:
        print("âš ï¸ ê²½ê³ : AWS ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("í™˜ê²½ë³€ìˆ˜ AWS_ACCESS_KEY_IDì™€ AWS_SECRET_ACCESS_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜")
        print("AWS CLIë¡œ ìê²© ì¦ëª…ì„ êµ¬ì„±í•´ì£¼ì„¸ìš”.")
        print("ìì„¸í•œ ë‚´ìš©: https://docs.aws.amazon.com/cli/latest/userguide/getting-started-quickstart.html")
        sys.exit(1)
    
    print("\nğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ìµœì í™” RAG ì‹œìŠ¤í…œ (Amazon Bedrock) ì´ˆê¸°í™” ì™„ë£Œ!")
    print("ğŸ“Š íŠ¹ì§•: SQL 1ì°¨ í•„í„°ë§ + ë²¡í„° 2ì°¨ ê²€ìƒ‰ìœ¼ë¡œ ê³ ì† ì •í™• ê²€ìƒ‰")
    print("ğŸ¤– AI ëª¨ë¸: Amazon Bedrock Claude")

    # ë°±ì—”ë“œ ì‹œì‘ ì‹œ ì¸ê¸° ë¬¸ì„œ ì‚¬ì „ ìºì‹±
    print("ğŸ”¥ ì¸ê¸° ë¬¸ì„œ ì‚¬ì „ ìºì‹± ì‹œì‘...")
    if llm_cache.preload_popular_documents():
        print("âœ… ì¸ê¸° ë¬¸ì„œ ìºì‹± ì™„ë£Œ")

    # ì£¼ìš” ì§€ì—­ ë¬¸ì„œ ì‚¬ì „ ìºì‹±
    print("ğŸ—ï¸ ì£¼ìš” ì§€ì—­ ë¬¸ì„œ ì‚¬ì „ ìºì‹± ì‹œì‘...")
    major_regions = ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'ì œì£¼íŠ¹ë³„ìì¹˜ë„', 'ê²½ê¸°ë„']
    for region in major_regions:
        if llm_cache.preload_region_documents(region):
            print(f"âœ… {region} ìºì‹± ì™„ë£Œ")

    print("ğŸ¯ Redis ë¬¸ì„œ ìºì‹œ í”„ë¦¬ë¡œë”© ì™„ë£Œ!")

    try:
        interactive_mode()
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")